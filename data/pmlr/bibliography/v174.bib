@proceedings{CHIL2022,
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Gerardo Flores and George H Chen and Tom Pollard and Joyce C Ho and Tristan Naumann},
 openalex = {W4205098185},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Proceedings of the Conference on Health, Inference, and Learning},
 volume = {174}
}

@inproceedings{pmlr-v174-chu22a,
 abstract = {Estimating treatment effects from observational data provides insights about causality guiding many real-world applications such as different clinical study designs, which are the formulations of trials, experiments, and observational studies in medical, clinical, and other types of research. In this paper, we describe causal inference for application in a novel clinical design called basket trial that tests how well a new drug works in patients who have different types of cancer that all have the same mutation. We propose a multi-task adversarial learning (MTAL) method, which incorporates feature selection multi-task representation learning and adversarial learning to estimate potential outcomes across different tumor types for patients sharing the same genetic mutation but having different tumor types. In our paper, the basket trial is employed as an intuitive example to present this new causal inference setting. This new causal inference setting includes, but is not limited to basket trials. This setting has the same challenges as the traditional causal inference problem, i.e., missing counterfactual outcomes under different subgroups and treatment selection bias due to confounders. We present the practical advantages of our MTAL method for the analysis of synthetic basket trial data and evaluate the proposed estimator on two benchmarks, IHDP and News. The results demonstrate the superiority of our MTAL method over the competing state-of-the-art methods.},
 author = {Chu, Zhixuan and Rathbun, Stephen L and Li, Sheng},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4226369498},
 pages = {79--91},
 pdf = {https://proceedings.mlr.press/v174/chu22a/chu22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Multi-Task Adversarial Learning for Treatment Effect Estimation in Basket Trials},
 url = {https://proceedings.mlr.press/v174/chu22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-el-hay22a,
 abstract = {Methods that address data shifts usually assume full access to multiple datasets. In the healthcare domain, however, privacy-preserving regulations as well as commercial interests limit data availability and, as a result, researchers can typically study only a small number of datasets. In contrast, limited statistical characteristics of specific patient samples are much easier to share and may be available from previously published literature or focused collaborative efforts. Here, we propose a method that estimates model performance in external samples from their limited statistical characteristics. We search for weights that induce internal statistics that are similar to the external ones; and that are closest to uniform. We then use model performance on the weighted internal sample as an estimation for the external counterpart. We evaluate the proposed algorithm on simulated data as well as electronic medical record data for two risk models, predicting complications in ulcerative colitis patients and stroke in women diagnosed with atrial fibrillation. In the vast majority of cases, the estimated external performance is much closer to the actual one than the internal performance. Our proposed method may be an important building block in training robust models and detecting potential model failures in external environments.},
 author = {El-Hay, Tal and Yanover, Chen},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4221147934},
 pages = {48--62},
 pdf = {https://proceedings.mlr.press/v174/el-hay22a/el-hay22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Estimating Model Performance on External Samples from Their Limited Statistical Characteristics},
 url = {https://proceedings.mlr.press/v174/el-hay22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-fatemi22a,
 abstract = {Reinforcement learning (RL) tasks are typically framed as Markov Decision Processes (MDPs), assuming that decisions are made at fixed time intervals. However, many applications of great importance, including healthcare, do not satisfy this assumption, yet they are commonly modelled as MDPs after an artificial reshaping of the data. In addition, most healthcare (and similar) problems are offline by nature, allowing for only retrospective studies. To address both challenges, we begin by discussing the Semi-MDP (SMDP) framework, which formally handles actions of variable timings. We next present a formal way to apply SMDP modifications to nearly any given value-based offline RL method. We use this theory to introduce three SMDP-based offline RL algorithms, namely, SDQN, SDDQN, and SBCQ. We then experimentally demonstrate that only these SMDP-based algorithms learn the optimal policy in variable-time environments, whereas their MDP counterparts do not. Finally, we apply our new algorithms to a real-world offline dataset pertaining to warfarin dosing for stroke prevention and demonstrate similar results.},
 author = {Fatemi, Mehdi and Wu, Mary and Petch, Jeremy and Nelson, Walter and Connolly, Stuart J and Benz, Alexander and Carnicelli, Anthony and Ghassemi, Marzyeh},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4221161853},
 pages = {119--137},
 pdf = {https://proceedings.mlr.press/v174/fatemi22a/fatemi22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Semi-Markov Offline Reinforcement Learning for Healthcare},
 url = {https://proceedings.mlr.press/v174/fatemi22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-flores22a,
 author = {Flores, Gerardo and Chen, George H and Pollard, Tom and Zirikly, Ayah and Hughes, Michael C and Sarker, Tasmie and Ho, Joyce C and Naumann, Tristan},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 pages = {1--4},
 pdf = {https://proceedings.mlr.press/v174/flores22a/flores22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Conference on Health, Inference, and Learning (CHIL) 2022},
 url = {https://proceedings.mlr.press/v174/flores22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-huang22a,
 abstract = {Clinical notes in Electronic Health Records (EHR) present rich documented information of patients to inference phenotype for disease diagnosis and study patient characteristics for cohort selection. Unsupervised user embedding aims to encode patients into fixed-length vectors without human supervisions. Medical concepts extracted from the clinical notes contain rich connections between patients and their clinical categories. However, existing unsupervised approaches of user embeddings from clinical notes do not explicitly incorporate medical concepts. In this study, we propose a concept-aware unsupervised user embedding that jointly leverages text documents and medical concepts from two clinical corpora, MIMIC-III and Diabetes. We evaluate user embeddings on both extrinsic and intrinsic tasks, including phenotype classification, in-hospital mortality prediction, patient retrieval, and patient relatedness. Experiments on the two clinical corpora show our approach exceeds unsupervised baselines, and incorporating medical concepts can significantly improve the baseline performance.},
 author = {Huang, Xiaolei and Dernoncourt, Franck and Dredze, Mark},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4221147697},
 pages = {63--78},
 pdf = {https://proceedings.mlr.press/v174/huang22a/huang22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Enriching Unsupervised User Embedding via Medical Concepts},
 url = {https://proceedings.mlr.press/v174/huang22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-hur22a,
 abstract = {EHR systems lack a unified code system forrepresenting medical concepts, which acts asa barrier for the deployment of deep learningmodels in large scale to multiple clinics and hos-pitals. To overcome this problem, we introduceDescription-based Embedding,DescEmb, a code-agnostic representation learning framework forEHR. DescEmb takes advantage of the flexibil-ity of neural language understanding models toembed clinical events using their textual descrip-tions rather than directly mapping each event toa dedicated embedding. DescEmb outperformedtraditional code-based embedding in extensiveexperiments, especially in a zero-shot transfertask (one hospital to another), and was able totrain a single unified model for heterogeneousEHR datasets.},
 author = {Hur, Kyunghoon and Lee, Jiyoung and Oh, Jungwoo and Price, Wesley and Kim, Younghak and Choi, Edward},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4297576764},
 pages = {183--203},
 pdf = {https://proceedings.mlr.press/v174/hur22a/hur22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Unifying Heterogeneous Electronic Health Records Systems via Text-Based Code Embedding},
 url = {https://proceedings.mlr.press/v174/hur22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-jeanselme22a,
 abstract = {Survival analysis involves the modelling of the times to event. Proposed neural network approaches maximise the predictive performance of traditional survival models at the cost of their interpretability. This impairs their applicability in high stake domains such as medicine. Providing insights into the survival distributions would tackle this issue and advance the medical understanding of diseases. This paper approaches survival analysis as a mixture of neural baselines whereby different baseline cumulative hazard functions are modelled using positive and monotone neural networks. The efficiency of the solution is demonstrated on three datasets while enabling the discovery of new survival phenotypes.},
 author = {Jeanselme, Vincent and Tom, Brian and Barrett, Jessica},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4226381683},
 pages = {92--102},
 pdf = {https://proceedings.mlr.press/v174/jeanselme22a/jeanselme22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Neural Survival Clustering: Non-parametric mixture of neural networks for survival clustering.},
 url = {https://proceedings.mlr.press/v174/jeanselme22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-keramati22a,
 abstract = {Off-policy policy evaluation methods for sequential decision making can be used to help identify if a proposed decision policy is better than a current baseline policy. However, a new decision policy may be better than a baseline policy for some individuals but not others. This has motivated a push towards personalization and accurate per-state estimates of heterogeneous treatment effects (HTEs). Given the limited data present in many important applications, individual predictions can come at a cost to accuracy and confidence in such predictions. We develop a method to balance the need for personalization with confident predictions by identifying subgroups where it is possible to confidently estimate the expected difference in a new decision policy relative to a baseline. We propose a novel loss function that accounts for uncertainty during the subgroup partitioning phase. In experiments, we show that our method can be used to form accurate predictions of HTEs where other methods struggle.},
 author = {Keramati, Ramtin and Gottesman, Omer and Celi, Leo Anthony and Doshi-Velez, Finale and Brunskill, Emma},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4286850046},
 pages = {397--410},
 pdf = {https://proceedings.mlr.press/v174/keramati22a/keramati22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Identification of Subgroups With Similar Benefits in Off-Policy Policy Evaluation},
 url = {https://proceedings.mlr.press/v174/keramati22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-killian22a,
 abstract = {Reliably transferring treatment policies learned in one clinical environment to another is currently limited by challenges related to domain shift. In this paper we address off-policy learning for sequential decision making under domain shift -- a scenario susceptible to catastrophic overconfidence -- which is highly relevant to a high-stakes clinical settings where the target domain may also be data-scarce. We propose a two-fold counterfactual regularization procedure to improve off-policy learning, addressing domain shift and data scarcity. First, we utilize an informative prior derived from a data-rich source environment to indirectly improve drawing counterfactual example observations. Then, these samples are then used to learn a policy for the target domain, regularized by the source policy through KL-divergence. In simulated sepsis treatment, our counterfactual policy transfer procedure significantly improves the performance of a learned treatment policy.},
 author = {Killian, Taylor W. and Ghassemi, Marzyeh and Joshi, Shalmali},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W3036936775},
 pages = {5--31},
 pdf = {https://proceedings.mlr.press/v174/killian22a/killian22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Counterfactually Guided Policy Transfer in Clinical Settings},
 url = {https://proceedings.mlr.press/v174/killian22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-kim22a,
 abstract = {Question Answering on Electronic Health Records (EHR-QA) has a significant impact on the healthcare domain, and it is being actively studied. Previous research on structured EHR-QA focuses on converting natural language queries into query language such as SQL or SPARQL (NLQ2Query), so the problem scope is limited to pre-defined data types by the specific query language. In order to expand the EHR-QA task beyond this limitation to handle multi-modal medical data and solve complex inference in the future, more primitive systemic language is needed. In this paper, we design the program-based model (NLQ2Program) for EHR-QA as the first step towards the future direction. We tackle MIMICSPARQL*, the graph-based EHR-QA dataset, via a program-based approach in a semi-supervised manner in order to overcome the absence of gold programs. Without the gold program, our proposed model shows comparable performance to the previous state-of-the-art model, which is an NLQ2Query model (0.9% gain). In addition, for a reliable EHR-QA model, we apply the uncertainty decomposition method to measure the ambiguity in the input question. We empirically confirmed data uncertainty is most indicative of the ambiguity in the input question.},
 author = {Kim, Daeyoung and Bae, Seongsu and Kim, Seungho and Choi, Edward},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4223982245},
 pages = {138--151},
 pdf = {https://proceedings.mlr.press/v174/kim22a/kim22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Uncertainty-Aware Text-to-Program for Question Answering on Structured Electronic Health Records},
 url = {https://proceedings.mlr.press/v174/kim22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-kim22b,
 abstract = {Spelling correction is a particularly important problem in clinical natural language processing because of the abundant occurrence of misspellings in medical records. However, the scarcity of labeled datasets in a clinical context makes it hard to build a machine learning system for such clinical spelling correction. In this work, we present a probabilistic model of correcting misspellings based on a simple conditional independence assumption, which leads to a modular decomposition into a language model and a corruption model. With a deep character-level language model trained on a large clinical corpus, and a simple edit-based corruption model, we can build a spelling correction model with small or no real data. Experimental results show that our model significantly outperforms baselines on two healthcare spelling correction datasets.},
 author = {Kim, Juyong and Weiss, Jeremy C and Ravikumar, Pradeep},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4395677977},
 pages = {234--247},
 pdf = {https://proceedings.mlr.press/v174/kim22b/kim22b.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Context-Sensitive Spelling Correction of Clinical Text via Conditional Independence.},
 url = {https://proceedings.mlr.press/v174/kim22b.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-kinyanjui22a,
 abstract = {Simulators make unique benchmarks for causal effect estimation as they do not rely on unverifiable assumptions or the ability to intervene on real-world systems. This is especially important for estimators targeting healthcare applications as possibilities for experimentation are limited with good reason. We develop a simulator of clinical variables associated with Alzheimerâs disease, aimed to serve as a benchmark for causal effect estimation while modeling intricacies of healthcare data. We fit the system to the Alzheimerâs Disease Neuroimaging Initiative (ADNI) dataset and ground hand-crafted components in results from comparative treatment trials and observational treatment patterns. The simulator includes parameters which alter the nature and difficulty of the causal inference tasks, such as latent variables, effect heterogeneity, length of observed subject history, behavior policy and sample size. We use the simulator to compare standard estimators of average and conditional treatment effects.},
 author = {Kinyanjui, Newton Mwai and Johansson, Fredrik D},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 pages = {103--118},
 pdf = {https://proceedings.mlr.press/v174/kinyanjui22a/kinyanjui22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {ADCB: An Alzheimerâs disease simulator for benchmarking observational estimators of causal effects},
 url = {https://proceedings.mlr.press/v174/kinyanjui22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-lee22a,
 abstract = {Electroencephalogram (EEG) is an important diagnostic test that physicians use to record brain activity and detect seizures by monitoring the signals. There have been several attempts to detect seizures and abnormalities in EEG signals with modern deep learning models to reduce the clinical burden. However, they cannot be fairly compared against each other as they were tested in distinct experimental settings. Also, some of them are not trained in real-time seizure detection tasks, making it hard for on-device applications. Therefore in this work, for the first time, we extensively compare multiple state-of-the-art models and signal feature extractors in a real-time seizure detection framework suitable for real-world application, using various evaluation metrics including a new one we propose to evaluate more practical aspects of seizure detection models. Our code is available at https://github.com/AITRICS/EEG_real_time_seizure_detection.},
 author = {Lee, Kwanhyung and Jeong, Hyewon and Kim, Seyun and Yang, Donghwa and Kang, Hoon-Chul and Choi, Edward},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4221160191},
 pages = {311--337},
 pdf = {https://proceedings.mlr.press/v174/lee22a/lee22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Real-Time Seizure Detection using EEG: A Comprehensive Comparison of Recent Approaches under a Realistic Setting},
 url = {https://proceedings.mlr.press/v174/lee22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-oh22a,
 abstract = {In recent years, self-supervised learning methods have shown significant improvement for pre-training with unlabeled data and have proven helpful for electrocardiogram signals. However, most previous pre-training methods for electrocardiogram focused on capturing only global contextual representations. This inhibits the models from learning fruitful representation of electrocardiogram, which results in poor performance on downstream tasks. Additionally, they cannot fine-tune the model with an arbitrary set of electrocardiogram leads unless the models were pre-trained on the same set of leads. In this work, we propose an ECG pre-training method that learns both local and global contextual representations for better generalizability and performance on downstream tasks. In addition, we propose random lead masking as an ECG-specific augmentation method to make our proposed model robust to an arbitrary set of leads. Experimental results on two downstream tasks, cardiac arrhythmia classification and patient identification, show that our proposed approach outperforms other state-of-the-art methods.},
 author = {Oh, Jungwoo and Chung, Hyunseung and Kwon, Joon-myoung and Hong, Dong-gyun and Choi, Edward},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4225471065},
 pages = {338--353},
 pdf = {https://proceedings.mlr.press/v174/oh22a/oh22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Lead-agnostic Self-supervised Learning for Local and Global Representations of Electrocardiogram},
 url = {https://proceedings.mlr.press/v174/oh22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-pal22a,
 abstract = {This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions. More than 194k high-quality AIIMS \& NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity. Each sample contains a question, correct answer(s), and other options which requires a deeper language understanding as it tests the 10+ reasoning abilities of a model across a wide range of medical subjects \& topics. A detailed explanation of the solution, along with the above information, is provided in this study.},
 author = {Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4221154592},
 pages = {248--260},
 pdf = {https://proceedings.mlr.press/v174/pal22a/pal22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering},
 url = {https://proceedings.mlr.press/v174/pal22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-park22a,
 abstract = {As the volume of Electronic Health Records (EHR) sharply grows, there has been emerging interest in learning the representation of EHR for healthcare applications. Representation learning of EHR requires appropriate modeling of the two dominant modalities in EHR: structured data and unstructured text. In this paper, we present MedGTX, a pre-trained model for multi-modal representation learning of the structured and textual EHR data. MedGTX uses a novel graph encoder to exploit the graphical nature of structured EHR data, and a text encoder to handle unstructured text, and a cross-modal encoder to learn a joint representation space. We pre-train our model through four proxy tasks on MIMIC-III, an open-source EHR data, and evaluate our model on two clinical benchmarks and three novel downstream tasks which tackle real-world problems in EHR data. The results consistently show the effectiveness of pre-training the model for joint representation of both structured and unstructured information from EHR. Given the promising performance of MedGTX, we believe this work opens a new door to jointly understanding the two fundamental modalities of EHR data.},
 author = {Park, Sungjin and Bae, Seongsu and Kim, Jiho and Kim, Tackeun and Choi, Edward},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4226177336},
 pages = {261--281},
 pdf = {https://proceedings.mlr.press/v174/park22a/park22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Graph-Text Multi-Modal Pre-training for Medical Representation Learning},
 url = {https://proceedings.mlr.press/v174/park22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-pfisterer22a,
 abstract = {Machine learning models are often required to generalize to new populations (domains) unseen during training, which may lead to model underperformance. So far, most research has focused on Domain Generalization methods for image classification tasks, which address the problem by learning domain invariant predictors. In this study, we assess the efficacy of domain generalization methods in survival analysis. The goal is to predict time-to-events such as death or disease progression based on baseline demographic and clinical variables of individuals exposed to medical treatment. We benchmark four domain generalization methods and several conventional/established methods on real world scenarios encountered in clinical practice. This includes tasks such as generalizing between randomized controlled trials to real world data, identification of prognostic models regardless of treatment or disease subtypes. We find that the generalization issue is often not as severe as reported in synthetic scenarios. Furthermore, our results corroborate previous findings that domain generalization often does not consistently outperform classical empirical risk minimization baselines also on low-dimensional data. Finally, to better understand when domain generalization methods can lead to performance gains and thus better outcomes for patients, we quantify the influence of different types of shifts occurring in the data.},
 author = {Pfisterer, Florian and Harbron, Chris and Jansen, Gunther and Xu, Tao},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 pages = {32--47},
 pdf = {https://proceedings.mlr.press/v174/pfisterer22a/pfisterer22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Evaluating Domain Generalization for Survival Analysis in Clinical Studies},
 url = {https://proceedings.mlr.press/v174/pfisterer22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-raghu22a,
 abstract = {Neural network models have demonstrated impressive performance in predicting pathologies and outcomes from the 12-lead electrocardiogram (ECG). However, these models often need to be trained with large, labelled datasets, which are not available for many predictive tasks of interest. In this work, we perform an empirical study examining whether training time data augmentation methods can be used to improve performance on such data-scarce ECG prediction problems. We investigate how data augmentation strategies impact model performance when detecting cardiac abnormalities from the ECG. Motivated by our finding that the effectiveness of existing augmentation strategies is highly task-dependent, we introduce a new method, TaskAug, which defines a flexible augmentation policy that is optimized on a per-task basis. We outline an efficient learning algorithm to do so that leverages recent work in nested optimization and implicit differentiation. In experiments, considering three datasets and eight predictive tasks, we find that TaskAug is competitive with or improves on prior work, and the learned policies shed light on what transformations are most effective for different tasks. We distill key insights from our experimental evaluation, generating a set of best practices for applying data augmentation to ECG prediction problems.},
 author = {Raghu, Aniruddh and Shanmugam, Divya and Pomerantsev, Eugene and Guttag, John and Stultz, Collin M},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4224903924},
 pages = {282--310},
 pdf = {https://proceedings.mlr.press/v174/raghu22a/raghu22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Data Augmentation for Electrocardiograms},
 url = {https://proceedings.mlr.press/v174/raghu22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-rahimian22a,
 abstract = {Survival analysis or time-to-event analysis aims to model and predict the time it takes for an event of interest to happen in a population or an individual. In the medical context this event might be the time of dying, metastasis, recurrence of cancer, etc. Recently, the use of neural networks that are specifically designed for survival analysis has become more popular and an attractive alternative to more traditional methods. In this paper, we take advantage of the inherent properties of neural networks to federate the process of training of these models. This is crucial in the medical domain since data is scarce and collaboration of multiple health centers is essential to make a conclusive decision about the properties of a treatment or a disease. To ensure the privacy of the datasets, it is common to utilize differential privacy on top of federated learning. Differential privacy acts by introducing random noise to different stages of training, thus making it harder for an adversary to extract details about the data. However, in the realistic setting of small medical datasets and only a few data centers, this noise makes it harder for the models to converge. To address this problem, we propose DPFed-post which adds a post-processing stage to the private federated learning scheme. This extra step helps to regulate the magnitude of the noisy average parameter update and easier convergence of the model. For our experiments, we choose 3 real-world datasets in the realistic setting when each health center has only a few hundred records, and we show that DPFed-post successfully increases the performance of the models by an average of up to $17\%$ compared to the standard differentially private federated learning scheme.},
 author = {Rahimian, Shadi and Kerkouche, Raouf and Kurth, Ina and Fritz, Mario},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4226204583},
 pages = {411--425},
 pdf = {https://proceedings.mlr.press/v174/rahimian22a/rahimian22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Practical Challenges in Differentially-Private Federated Survival Analysis of Medical Data},
 url = {https://proceedings.mlr.press/v174/rahimian22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-roy22a,
 abstract = {Literature on machine learning for multiple sclerosis has primarily focused on the use of neuroimaging data such as magnetic resonance imaging and clinical laboratory tests for disease identification. However, studies have shown that these modalities are not consistent with disease activity such as symptoms or disease progression. Furthermore, the cost of collecting data from these modalities is high, leading to scarce evaluations. In this work, we used multi-dimensional, affordable, physical and smartphone-based performance outcome measures (POM) in conjunction with demographic data to predict multiple sclerosis disease progression. We performed a rigorous benchmarking exercise on two datasets and present results across 13 clinically actionable prediction endpoints and 6 machine learning models. To the best of our knowledge, our results are the first to show that it is possible to predict disease progression using POMs and demographic data in the context of both clinical trials and smartphone-base studies by using two datasets. Moreover, we investigate our models to understand the impact of different POMs and demographics on model performance through feature ablation studies. We also show that model performance is similar across different demographic subgroups (based on age and sex). To enable this work, we developed an end-to-end reusable pre-processing and machine learning framework which allows quicker experimentation over disparate MS datasets.},
 author = {Roy, Subhrajit and Mincu, Diana and Proleev, Lev and Rostamzadeh, Negar and Ghate, Chintan and Harris, Natalie and Chen, Christina and Schrouff, Jessica and Toma\v{s}ev, Nenad and Hartsell, Fletcher Lee and Heller, Katherine},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4224547498},
 pages = {375--396},
 pdf = {https://proceedings.mlr.press/v174/roy22a/roy22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Disability prediction in multiple sclerosis using performance outcome measures and demographic data},
 url = {https://proceedings.mlr.press/v174/roy22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-tonekaboni22a,
 abstract = {Rigorous evaluation of ML models prior to deployment in hospital settings is critical to ensure utility, performance, and safety. In addition, a guarantee of the usability of such tools requires careful user-centred design and evaluation. Such evaluations can be extra challenging for models that measure unquantified and complex clinical phenomena like the risk of deterioration. This paper introduces a silent trial protocol for evaluating models in real-time in the ICU setting. The trial is designed following principles of formative testing with the goal of evaluating model performance and gathering information that can be used to refine the model to best fit within the intended environment of deployment. We highlight the considerations for a systematic evaluation and explain the design and deployment of the components that enable this trial. We hope that the principles and considerations introduced in this paper can help other researchers validate ML models in their clinical settings.},
 author = {Tonekaboni, Sana and Morgenshtern, Gabriela and Assadi, Azadeh and Pokhrel, Aslesha and Huang, Xi and Jayarajan, Anand and Greer, Robert and Pekhimenko, Gennady and McCradden, Melissa and Chevalier, Fanny and Mazwi, Mjaye and Goldenberg, Anna},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 pages = {169--182},
 pdf = {https://proceedings.mlr.press/v174/tonekaboni22a/tonekaboni22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {How to validate Machine Learning Models Prior to Deployment: Silent trial protocol for evaluation of real-time models at ICU},
 url = {https://proceedings.mlr.press/v174/tonekaboni22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-weatherhead22a,
 abstract = {Medical time series like physiological signals provide a rich source of information about patientsâ underlying clinical states. Learning such states is a challenging problem for ML but has great utility for clinical applications. It allows us to identify patients with similar underlying conditions, track disease progression over time, and much more. The challenge with medical time series however, is the lack of well-defined labels for a given patientâs state for extended periods of time. Collecting such labels is expensive and often requires substantial effort. In this work, we propose an unsupervised representation learning method, called TRACE, that allows us to learn meaningful patient representations from time series collected in the Intensive Care Unit (ICU). We show the utility and generalizability of these representations in identifying different downstream clinical conditions and also show how the trajectory of representations over time exhibits progression toward critical conditions such as cardiopulmonary arrest or circulatory failure.},
 author = {Weatherhead, Addison and Greer, Robert and Moga, Michael-Alice and Mazwi, Mjaye and Eytan, Danny and Goldenberg, Anna and Tonekaboni, Sana},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 pages = {152--168},
 pdf = {https://proceedings.mlr.press/v174/weatherhead22a/weatherhead22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning Unsupervised Representations for ICU Timeseries},
 url = {https://proceedings.mlr.press/v174/weatherhead22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-zhang22a,
 abstract = {Deep learning models have reached or surpassed human-level performance in the field of medical imaging, especially in disease diagnosis using chest x-rays. However, prior work has found that such classifiers can exhibit biases in the form of gaps in predictive performance across protected groups. In this paper, we question whether striving to achieve zero disparities in predictive performance (i.e. group fairness) is the appropriate fairness definition in the clinical setting, over minimax fairness, which focuses on maximizing the performance of the worst-case group. We benchmark the performance of nine methods in improving classifier fairness across these two definitions. We find, consistent with prior work on non-clinical data, that methods which strive to achieve better worst-group performance do not outperform simple data balancing. We also find that methods which achieve group fairness do so by worsening performance for all groups. In light of these results, we discuss the utility of fairness definitions in the clinical setting, advocating for an investigation of the bias-inducing mechanisms in the underlying data generating process whenever possible.},
 author = {Zhang, Haoran and Dullerud, Natalie and Roth, Karsten and Oakden-Rayner, Lauren and Pfohl, Stephen and Ghassemi, Marzyeh},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4225961394},
 pages = {204--233},
 pdf = {https://proceedings.mlr.press/v174/zhang22a/zhang22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Improving the Fairness of Chest X-ray Classifiers},
 url = {https://proceedings.mlr.press/v174/zhang22a.html},
 volume = {174},
 year = {2022}
}

@inproceedings{pmlr-v174-zhu22a,
 abstract = {Heart rate variability (HRV) is a practical and noninvasive measure of autonomic nervous system activity, which plays an essential role in cardiovascular health. However, using HRV to assess physiology status is challenging. Even in clinical settings, HRV is sensitive to acute stressors such as physical activity, mental stress, hydration, alcohol, and sleep. Wearable devices provide convenient HRV measurements, but the irregularity of measurements and uncaptured stressors can bias conventional analytical methods. To better interpret HRV measurements for downstream healthcare applications, we learn a personalized diurnal rhythm as an accurate physiological indicator for each individual. We develop Physiological Multitask-Learning (PhysioMTL) by harnessing Optimal Transport theory within a Multitask-learning (MTL) framework. The proposed method learns an individual-specific predictive model from heterogeneous observations, and enables estimation of an optimal transport map that yields a push forward operation onto the demographic features for each task. Our model outperforms competing MTL methodologies on unobserved predictive tasks for synthetic and two real-world datasets. Specifically, our method provides remarkable prediction results on unseen held-out subjects given only $20\%$ of the subjects in real-world observational studies. Furthermore, our model enables a counterfactual engine that generates the effect of acute stressors and chronic conditions on HRV rhythms.},
 author = {Zhu, Jiacheng and Darnell, Gregory and Kumar, Agni and Zhao, Ding and Li, Bo and Nguyen, Xuanlong and Ren, Shirley You},
 booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
 editor = {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
 month = {07--08 Apr},
 openalex = {W4226470252},
 pages = {354--374},
 pdf = {https://proceedings.mlr.press/v174/zhu22a/zhu22a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {PhysioMTL: Personalizing Physiological Patterns using Optimal Transport Multi-Task Regression},
 url = {https://proceedings.mlr.press/v174/zhu22a.html},
 volume = {174},
 year = {2022}
}
