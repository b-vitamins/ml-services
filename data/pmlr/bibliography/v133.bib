
@Proceedings{NeurIPSCDT2021,
  title =     {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  booktitle = {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  editor =    {Hugo Jair Escalante and Katja Hofmann},
  publisher = {PMLR},
  series =    {Proceedings of Machine Learning Research},
  volume =    133
}
@InProceedings{pmlr-v133-escalante21a,
  title = 	 {{NeurIPS 2020} Competition and Demonstration Track: Revised selected papers},
  author =       {Escalante, Hugo Jair and Hofmann, Katja},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {1--2},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/escalante21a/escalante21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/escalante21a.html},
  abstract = 	 {This volume compiles a selection of papers associated with the fourth edition of the Demonstration and Competition Track at NeurIPS 2020. The track comprised  16 competitions and 20 demonstrations. Competition and demonstration proposals were subject to a strict reviewing process to ensure the quality of the accepted events. After a selective process, the accepted  competitions and demonstrations were featured at the NeurIPS 2020 main conference. A wide diversity of machine learning topics were covered with competitions and demonstrations. The latter included innovative ways of interacting with participants due to the virtual format of NeurIPS2020. }
}
@InProceedings{pmlr-v133-turner21a,
  title = 	 {Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020},
  author =       {Turner, Ryan and Eriksson, David and McCourt, Michael and Kiili, Juha and Laaksonen, Eero and Xu, Zhen and Guyon, Isabelle},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {3--26},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/turner21a/turner21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/turner21a.html},
  abstract = 	 {This paper presents the results and insights from the black-box optimization (BBO) challenge at NeurIPS2020 which ran from JulyâOctober, 2020. The challenge emphasized the importance of evaluating derivative-free optimizers for tuning the hyperparameters of machine learning models. This was the first black-box optimization challenge with a machine learning emphasis. It was based on tuning (validation set) performance of standard machine learning models on real datasets. This competition has widespread impact as black-box optimization (e.g., Bayesian optimization) is relevant for hyperparameter tuning in almost every machine learning project as well as many applications outside of machine learning. The final leaderboard was determined using the optimization performance on held-out (hidden) objective functions, where the optimizers ran without human intervention. Baselines were set using the default settings of several open source black-box optimization packages as well as random search.}
}
@InProceedings{pmlr-v133-agarwal21a,
  title = 	 {tspDB: Time Series Predict DB},
  author =       {Agarwal, Anish and Alomar, Abdullah and Shah, Devavrat},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {27--56},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/agarwal21a/agarwal21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/agarwal21a.html},
  abstract = 	 {A major bottleneck of the current Machine Learning (ML) workflow is the time consuming, error prone engineering required to get data from a datastore or a database (DB) to the point an ML algorithm can be applied to it.  This is further exacerbated since ML algorithms are now trained on large volumes of data, yet we need predictions in real-time, especially in a variety of time-series applications such as finance and real-time control systems.  Hence, we explore the feasibility of directly integrating prediction functionality on top of a data store or DB.  Such a system ideally:  (i) provides an intuitive prediction query interface which alleviates the unwieldy data engineering;  (ii) provides state-of-the-art statistical accuracy while ensuring incremental model update, low model training time  and low latency for making predictions.  As the main contribution we explicitly instantiate a proof-of-concept, tspDB which directly integrates with PostgreSQL.  We rigorously test tspDBâs statistical and computational performance against the state-of-the-art time series algorithms, including a Long-Short-Term-Memory (LSTM) neural network and DeepAR (industry standard deep learning library by Amazon).  Statistically, on standard time series benchmarks, tspDB outperforms LSTM and DeepAR with 1.1-1.3x higher relative accuracy.  Computationally, tspDB is 59-62x and 94-95x faster compared to LSTM and DeepAR in terms of median ML model training time and prediction query latency, respectively.  Further, compared to PostgreSQLâs bulk insert time and its SELECT query latency, tspDB is slower only by 1.3x and 2.6x respectively.  That is, tspDB is a real-time prediction system in that its model training / prediction query time is similar to just inserting, reading data from a DB. As an algorithmic contribution, we introduce an incremental multivariate matrix factorization based time series method, which tspDB is built off. We show this method also allows one to produce reliable prediction intervals by accurately estimating the time-varying variance of a time series, thereby addressing an important problem in time series analysis.}
}
@InProceedings{pmlr-v133-madadi21a,
  title = 	 {Learning Cloth Dynamics: 3D+Texture Garment Reconstruction Benchmark},
  author =       {Madadi, Meysam and Bertiche, Hugo and Bouzouita, Wafa and Guyon, Isabelle and Escalera, Sergio},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {57--76},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/madadi21a/madadi21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/madadi21a.html},
  abstract = 	 {Human avatars are important targets in many computer applications. Accurately tracking, capturing, reconstructing and animating the human body, face and garments in 3D are critical for human-computer interaction, gaming, special effects and virtual reality. In the past, this has required extensive manual animation. Regardless of the advances in human body and face reconstruction, still modeling, learning and analyzing human dynamics need further attention. In this paper we plan to push the research in this direction, e.g. understanding human dynamics in 2D and 3D, with special attention to garments. We provide a large-scale dataset (more than 2M frames) of animated garments with variable topology and type, calledCLOTH3D++. The dataset contains RGBA video sequences paired with its corresponding 3D data. We pay special care to garment dynamics and realistic rendering of RGB data, including lighting, fabric type and texture. With this dataset, we hold a competition at NeurIPS2020. We design three tracks so participants can compete to develop the best method to perform 3D garment reconstruction in a sequence from (1) 3D-to-3D garments, (2) RGB-to-3D garments, and (3) RGB-to-3D garments plus texture. We also provide a baseline method, based on graph convolutional networks, for each track. Baseline results show that there is a lot of room for improvements. However, due to the challenging nature of the problem, no participant could outperform the baselines.}
}
@InProceedings{pmlr-v133-sazanovich21a,
  title = 	 {Solving Black-Box Optimization Challenge via Learning Search Space Partition for Local Bayesian Optimization},
  author =       {Sazanovich, Mikita and Nikolskaya, Anastasiya and Belousov, Yury and Shpilman, Aleksei},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {77--85},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/sazanovich21a/sazanovich21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/sazanovich21a.html},
  abstract = 	 {Black-box optimization is one of the vital tasks in machine learning, since it approximates real-world conditions, in that we do not always know all the properties of a given system, up to knowing almost nothing but the results. This paper describes our approach to solving the black-box optimization challenge at NeurIPS 2020 through learning search space partition for local Bayesian optimization. We describe the task of the challenge as well as our algorithm for low budget optimization that we named SPBOpt. We optimize the hyper-parameters of our algorithm for the competition finals using multi-task Bayesian optimization on results from the first two evaluation settings. Our approach has ranked third in the competition finals.}
}
@InProceedings{pmlr-v133-min21a,
  title = 	 {NeurIPS 2020 EfficientQA Competition: Systems, Analyses and Lessons Learned},
  author =       {Min, Sewon and Boyd-Graber, Jordan and Alberti, Chris and Chen, Danqi and Choi, Eunsol and Collins, Michael and Guu, Kelvin and Hajishirzi, Hannaneh and Lee, Kenton and Palomaki, Jennimaria and Raffel, Colin and Roberts, Adam and Kwiatkowski, Tom and Lewis, Patrick and Wu, Yuxiang and K\"uttler, Heinrich and Liu, Linqing and Minervini, Pasquale and Stenetorp, Pontus and Riedel, Sebastian and Yang, Sohee and Seo, Minjoon and Izacard, Gautier and Petroni, Fabio and Hosseini, Lucas and Cao, Nicola De and Grave, Edouard and Yamada, Ikuya and Shimaoka, Sonse and Suzuki, Masatoshi and Miyawaki, Shumpei and Sato, Shun and Takahashi, Ryo and Suzuki, Jun and Fajcik, Martin and Docekal, Martin and Ondrej, Karel and Smrz, Pavel and Cheng, Hao and Shen, Yelong and Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng and Oguz, Barlas and Chen, Xilun and Karpukhin, Vladimir and Peshterliev, Stan and Okhonko, Dmytro and Schlichtkrull, Michael and Gupta, Sonal and Mehdad, Yashar and Yih, Wen-tau},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {86--111},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/min21a/min21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/min21a.html},
  abstract = 	 {We review the EfficientQA competition from NeurIPS 2020. The competition focused on open-domain question answering (QA), where systems take natural language questions as input and return natural language answers.  The aim of the competition was to build systems that can predict correct answers while also satisfying strict on-disk memory budgets. These memory budgets were designed to encourage contestants to  explore  the  trade-off between storing retrieval corpora or the parameters of learned models. In this report, we describe the motivation and organization of the competition, review the best submissions, and analyze system predictions to inform a discussion of evaluation for open-domain QA. }
}
@InProceedings{pmlr-v133-marot21a,
  title = 	 {Learning to run a Power Network Challenge: a Retrospective Analysis},
  author =       {Marot, Antoine and Donnot, Benjamin and Dulac-Arnold, Gabriel and Kelly, Adrian and O'Sullivan, Aidan and Viebahn, Jan and Awad, Mariette and Guyon, Isabelle and Panciatici, Patrick and Romero, Camilo},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {112--132},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/marot21a/marot21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/marot21a.html},
  abstract = 	 {Power networks, responsible for transporting electricity across large geographical regions, are complex infrastructures on which modern life critically depend. Variations in demand and production profiles, with increasing renewable energy integration, as well as the high voltage network technology, constitute a real challenge for human operators when optimizing electricity transportation while avoiding blackouts. Motivated to  investigate the potential of Artificial Intelligence methods in enabling adaptability in power network operation, we have designed a L2RPN challenge to encourage the development of reinforcement learning solutions to key problems present in the next-generation power networks. The NeurIPS 2020 competition was well received by the international community attracting over 300 participants worldwide.   The main contribution of this challenge is our proposed comprehensive âGrid2Opâ framework, and associated benchmark, which plays realistic sequential network operations scenarios. The Grid2Op framework, which is open-source and easily re-usable, allows users  to define new environments with its companion GridAlive ecosystem. Grid2Op relies on existing non-linear physical power network simulators and let users create a series of perturbations and challenges that are representative of two important problems: a) the uncertainty resulting from the increased use of unpredictable renewable energy sources, and b) the robustness required with contingent line disconnections.  In this paper, we give the highlights of the NeurIPS 2020 competition. We present the benchmark suite and analyse the winning solutions, including one super-human performance demonstration. We propose our organizational insights for a successful competition and conclude on open research avenues. Given the challenge success, we expect our work will foster research to create more sustainable solutions for power network operations. }
}
@InProceedings{pmlr-v133-hamilton21a,
  title = 	 {MosAIc: Finding Artistic Connections across Culture with Conditional Image Retrieval},
  author =       {Hamilton, Mark and Fu, Stephanie and Lu, Mindren and Bui, Johnny and Bopp, Darius and Chen, Zhenbang and Tran, Felix and Wang, Margaret and Rogers, Marina and Zhang, Lei and Hoder, Chris and Freeman, William T.},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {133--155},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/hamilton21a/hamilton21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/hamilton21a.html},
  abstract = 	 {We introduce MosAIc, an interactive web app that allows users to find pairs of semantically related artworks that span different cultures, media, and millennia. To create this application, we introduce Conditional Image Retrieval (CIR) which combines visual similarity search with user supplied filters or âconditionsâ. This technique allows one to find pairs of similar images that span distinct subsets of the image corpus. We provide a generic way to adapt existing image retrieval data-structures to this new domain and provide theoretical bounds on our approachâs efficiency. To quantify the performance of CIR systems, we introduce new datasets for evaluating CIR methods and show that CIR performs non-parametric style transfer. Finally, we demonstrate that our CIR data-structures can identify âblind spotsâ in Generative Adversarial Networks (GAN) where they fail to properly model the true data distribution.}
}
@InProceedings{pmlr-v133-desmond21a,
  title = 	 {Semi-Automated Data Labeling},
  author =       {Desmond, Michael and Duesterwald, Evelyn and Brimijoin, Kristina and Brachman, Michelle and Pan, Qian},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {156--169},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/desmond21a/desmond21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/desmond21a.html},
  abstract = 	 {Labeling data is often a tedious and error-prone activity. However, organizing the labeling experience as a human-machine collaboration has the potential to improve label quality and reduce human effort. In this paper we describe a semi-automated data labeling system which employs a predictive model to guide and assist the human labeler. The model learns by observing labeling decisions, and is used to recommend labels and automate basic functions in the labeling interface. Agreement between the labeler and the model is tracked and presented via a system of checkpoints. At each checkpoint the labeler has the opportunity to delegate the remainder of the labeling task to the model. }
}
@InProceedings{pmlr-v133-jiang21a,
  title = 	 {Methods and Analysis of The First Competition in Predicting Generalization of Deep Learning},
  author =       {Jiang, Yiding and Natekar, Parth and Sharma, Manik and Aithal, Sumukh K. and Kashyap, Dhruva and Subramanyam, Natarajan and Lassance, Carlos and Roy, Daniel M. and Dziugaite, Gintare Karolina and Gunasekar, Suriya and Guyon, Isabelle and Foret, Pierre and Yak, Scott and Mobahi, Hossein and Neyshabur, Behnam and Bengio, Samy},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {170--190},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/jiang21a/jiang21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/jiang21a.html},
  abstract = 	 {Deep learning has been recently successfully applied to an ever larger number of problems, ranging from pattern recognition to complex decision making. However, several concerns have been raised, including guarantees of good generalization, which is of foremost importance. Despite numerous attempts, conventional statistical learning approaches fall short of providing a satisfactory explanation on why deep learning works. In a competition hosted at the Thirty-Fourth Conference on Neural Information Processing Systems (NeurIPS 2020), we invited the community to design robust and general complexity measures that can accurately predict the generalization of models. In this paper, we describe the competition design, the protocols, and the solutions of the top-three teams at the competition in details. In addition, we discuss the outcomes, common failure modes, and potential future directions for the competition.}
}
@InProceedings{pmlr-v133-wang21a,
  title = 	 {Results and Insights from Diagnostic Questions: The NeurIPS 2020 Education Challenge},
  author =       {Wang, Zichao and Lamb, Angus and Saveliev, Evgeny and Cameron, Pashmina and Zaykov, Jordan and Hernandez-Lobato, Jose Miguel and Turner, Richard E. and Baraniuk, Richard G. and Craig Barton, Eedi and Peyton Jones, Simon and Woodhead, Simon and Zhang, Cheng},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {191--205},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/wang21a/wang21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/wang21a.html},
  abstract = 	 {This competition concerns educational diagnostic questions, which are pedagogically effective, multiple-choice questions (MCQs) whose distractors embody misconceptions. With a large and ever-increasing number of such questions, it becomes overwhelming for teachers to know which questions are the best ones to use for their students. We thus seek to answer the following question: how can we use data on hundreds of millions of answers to MCQs to drive automatic personalized learning in large-scale learning scenarios where manual personalization is infeasible?  Success in using MCQ data at scale helps build more intelligent, personalized learning platforms that ultimately improve the quality of education en masse. To this end, we introduce a new, large-scale, real-world dataset and formulate 4 data mining tasks on MCQs that mimic real learning scenarios and target various aspects of the above question in a competition setting at NeurIPS 2020. We report on our NeurIPS competition in which nearly 400 teams submitted approximately 4000 submissions, with encouragingly diverse and effective approaches to each of our tasks.}
}
@InProceedings{pmlr-v133-jordon21a,
  title = 	 {Hide-and-Seek Privacy Challenge: Synthetic Data Generation vs. Patient Re-identification},
  author =       {Jordon, James and Jarrett, Daniel and Saveliev, Evgeny and Yoon, Jinsung and Elbers, Paul and Thoral, Patrick and Ercole, Ari and Zhang, Cheng and Belgrave, Danielle and van der Schaar, Mihaela},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {206--215},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/jordon21a/jordon21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/jordon21a.html},
  abstract = 	 {The clinical  time-series setting  poses  a  unique  combination  of  challenges  to  data  modelling  and  sharing.   Due  to  the  high  dimensionality  of  clinical  time  series,  adequate  de-identification to preserve privacy while retaining data utility is difficult to achieve using common de-identification techniques.  An innovative approach to this problem is synthetic data  generation.   From  a  technical  perspective,  a  good  generative  model  for  time-series data should preserve temporal dynamics; new sequences should respect the original relationships between high-dimensional variables across time.  From the privacy perspective, the model should prevent patient re-identification.  The NeurIPS 2020 Hide-and-Seek Privacy Challenge was a novel two-tracked competition to simultaneously accelerate progress in tackling both problems.  In our head-to-head format, participants in the generation track (?hiders?) and the patient re-identification track (?seekers?) were directly pitted against each other by way of a new, high-quality intensive care time-series dataset:  the AmsterdamUMCdb dataset.  In this paper we present an overview of the competition design, as well as highlighting areas we feel should be changed for future iterations of this competition.}
}
@InProceedings{pmlr-v133-etten21a,
  title = 	 {The SpaceNet Multi-Temporal Urban Development Challenge},
  author =       {Etten, Adam Van and Hogan, Daniel},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {216--232},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/etten21a/etten21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/etten21a.html},
  abstract = 	 {Building footprints provide a useful proxy for a great many humanitarian applications.  For example, building footprints are useful for high fidelity population estimates, and quantifying population statistics is fundamental to Â 1/4 of the United Nations Sustainable Development Goals Indicators.  In this paper we (the SpaceNet Partners) discuss efforts to develop techniques for precise building footprint localization, tracking, and change detection via the SpaceNet Multi-Temporal Urban Development Challenge (also known as SpaceNet 7).  In this NeurIPS 2020 competition, participants were asked identify and track buildings in satellite imagery time series collected over rapidly urbanizing areas. The competition centered around a brand new open source dataset of Planet Labs satellite imagery mosaics at 4m resolution, which includes 24 images (one per month) covering Â 100 unique geographies. Tracking individual buildings at this resolution is quite challenging, yet the winning participants demonstrated impressive performance with the newly developed SpaceNet Change and Object Tracking (SCOT) metric.  This paper details the top-5 winning approaches, as well as analysis of results that yielded a handful of interesting anecdotes such as decreasing performance with latitude.}
}
@InProceedings{pmlr-v133-guss21a,
  title = 	 {Towards robust and domain agnostic reinforcement learning competitions: MineRL 2020},
  author =       {Guss, William Hebgen and Milani, Stephanie and Topin, Nicholay and Houghton, Brandon and Mohanty, Sharada and Melnik, Andrew and Harter, Augustin and Buschmaas, Benoit and Jaster, Bjarne and Berganski, Christoph and Heitkamp, Dennis and Henning, Marko and Ritter, Helge and Wu, Chengjie and Hao, Xiaotian and Lu, Yiming and Mao, Hangyu and Mao, Yihuan and Wang, Chao and Opanowicz, Michal and Kanervisto, Anssi and Schraner, Yanick and Scheller, Christian and Zhou, Xiren and Liu, Lu and Nishio, Daichi and Tsuneda, Toi and Ramanauskas, Karolis and Juceviciute, Gabija},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {233--252},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/guss21a/guss21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/guss21a.html},
  abstract = 	 {Reinforcement learning competitions have formed the basis for standard research benchmarks, galvanized advances in the state-of-the-art, and shaped the direction of the field. Despite this, a majority of challenges suffer from the same fundamental problems: participant solutions to the posed challenge are usually domain-specific, biased to maximally exploit compute resources, and not guaranteed to be reproducible. In this paper, we present a new framework of competition design that promotes the development of algorithms that overcome these barriers. We propose four central mechanisms for achieving this end: submission retraining, domain randomization, desemantization through domain obfuscation, and the limitation of competition compute and environment-sample budget. To demonstrate the efficacy of this design, we proposed, organized, and ran the MineRL 2020 Competition on Sample-Efficient Reinforcement Learning. In this work, we describe the organizational outcomes of the competition and show that the resulting participant submissions are reproducible, non-specific to the competition environment, and sample/resource efficient, despite the difficult competition task.}
}
@InProceedings{pmlr-v133-d-eon21a,
  title = 	 {Musical Speech: A Transformer-based Composition Tool},
  author =       {d'Eon, Jason and Dumpla, Sri Harsha and Sastry, Chandramouli Shama and Oore, Daniel and Oore, Sageev},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {253--274},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/d-eon21a/d-eon21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/d-eon21a.html},
  abstract = 	 {In this paper, we propose a new compositional tool that will generate a musical outline of speech recorded/provided by the user for use as a musical building block in their compositions. The tool allows any user to use their own speech to generate musical material, while still being able to hear the direct connection between their recorded speech and the resulting music. The tool is built on our proposed pipeline. This pipeline begins with speech-based signal processing, after which some simple musical heuristics are applied, and finally these pre-processed signals are passed through Transformer models trained on new musical tasks. We illustrate the effectiveness of our pipeline â which does not require a paired dataset for training â through examples of music created by musicians making use of our tool.}
}
@InProceedings{pmlr-v133-laurent21a,
  title = 	 {Flatland Competition 2020: MAPF and MARL for Efficient Train Coordination on a Grid World},
  author =       {Laurent, Florian and Schneider, Manuel and Scheller, Christian and Watson, Jeremy and Li, Jiaoyang and Chen, Zhe and Zheng, Yi and Chan, Shao-Hung and Makhnev, Konstantin and Svidchenko, Oleg and Egorov, Vladimir and Ivanov, Dmitry and Shpilman, Aleksei and Spirovska, Evgenija and Tanevski, Oliver and Nikov, Aleksandar and Grunder, Ramon and Galevski, David and Mitrovski, Jakov and Sartoretti, Guillaume and Luo, Zhiyao and Damani, Mehul and Bhattacharya, Nilabha and Agarwal, Shivam and Egli, Adrian and Nygren, Erik and Mohanty, Sharada},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {275--301},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/laurent21a/laurent21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/laurent21a.html},
  abstract = 	 {The Flatland competition aimed at finding novel approaches to solve the vehicle re-scheduling problem (VRSP). The VRSP is concerned with scheduling trips in traffic networks and the re-scheduling of vehicles when disruptions occur, for example the breakdown of a vehicle. While solving the VRSP in various settings has been an active area in operations research (OR) for decades, the ever-growing complexity of modern railway networks makes dynamic real-time scheduling of traffic virtually impossible. Recently, multi-agent reinforcement learning (MARL) has successfully tackled challenging tasks where many agents need to be coordinated, such as multiplayer video games. However, the coordination of hundreds of agents in a real-life setting like a railway network remains challenging and the Flatland environment used for the competition models these real-world properties in a simplified manner. Submissions had to bring as many trains (agents) to their target stations in as little time as possible. While the best submissions were in the OR category, participants found many promising MARL approaches. Using both centralized and decentralized learning based approaches, top submissions used graph representations of the environment to construct tree-based observations. Further, different coordination mechanisms were implemented, such as communication and prioritization between agents. This paper presents the competition setup, four outstanding solutions to the competition, and a cross-comparison between them.	}
}
@InProceedings{pmlr-v133-agarwal21b,
  title = 	 {NeurIPS 2020 NLC2CMD Competition: Translating Natural Language to Bash Commands},
  author =       {Agarwal, Mayank and Chakraborti, Tathagata and Fu, Quchen and Gros, David and Lin, Xi Victoria and Maene, Jaron and Talamadupula, Kartik and Teng, Zhongwei and White, Jules},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {302--324},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/agarwal21b/agarwal21b.pdf},
  url = 	 {https://proceedings.mlr.press/v133/agarwal21b.html},
  abstract = 	 {The NLC2CMD Competition hosted at NeurIPS 2020 aimed to bring the power of natural language processing to the command line. Participants were tasked with building models that can transform descriptions of command line tasks in English to their Bash syntax. This is a report on the competition with details of the task, metrics, data, attempted solutions, and lessons learned.}
}
@InProceedings{pmlr-v133-kopp21a,
  title = 	 {Traffic4cast at NeurIPS 2020 - yet more on the unreasonable effectiveness of gridded geo-spatial processes},
  author =       {Kopp, Michael and Kreil, David and Neun, Moritz and Jonietz, David and Martin, Henry and Herruzo, Pedro and Gruca, Aleksandra and Soleymani, Ali and Wu, Fanyou and Liu, Yang and Xu, Jingwei and Zhang, Jianjin and Santokhi, Jay and Bojesomo, Alabi and Marzouqi, Hasan Al and Liatsis, Panos and Kwok, Pak Hay and Qi, Qi and Hochreiter, Sepp},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {325--343},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/kopp21a/kopp21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/kopp21a.html},
  abstract = 	 {The IARAI Traffic4cast competition at NeurIPS 2019 showed that neural networks can successfully predict future traffic conditions 15 minutes into the future on simply aggregated GPS probe data  in time and space bins, thus interpreting the challenge of forecasting traffic conditions as a movie completion task. U-nets proved to be the winning architecture then, demonstrating an ability  to extract relevant features in the complex, real-world, geo-spatial process that is traffic derived from a large data set. The IARAI Traffic4cast challenge at NeurIPS 2020 build on the insights of the previous year and sought to both challenge some assumptions inherent in our 2019 competition design and explore how far this neural network technique can be pushed. We found that the  prediction horizon can be extended successfully to 60 minutes into the future, that there is further evidence that traffic depends more on recent dynamics than on the additional static or dynamic location specific data provided and that a reasonable starting point when exploring a general aggregated geo-spatial process in time and space is a U-net architecture.}
}
@InProceedings{pmlr-v133-kiela21a,
  title = 	 {The Hateful Memes Challenge: Competition Report},
  author =       {Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Fitzpatrick, Casey A. and Bull, Peter and Lipstein, Greg and Nelli, Tony and Zhu, Ron and Muennighoff, Niklas and Velioglu, Riza and Rose, Jewgeni and Lippe, Phillip and Holla, Nithin and Chandra, Shantanu and Rajamanickam, Santhosh and Antoniou, Georgios and Shutova, Ekaterina and Yannakoudakis, Helen and Sandulescu, Vlad and Ozertem, Umut and Pantel, Patrick and Specia, Lucia and Parikh, Devi},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {344--360},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/kiela21a/kiela21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/kiela21a.html},
  abstract = 	 {Machine learning and artificial intelligence play an ever more crucial role in mitigating important societal problems, such as the prevalence of hate speech. We describe the Hateful Memes Challenge competition, held at NeurIPS 2020, focusing on multimodal hate speech. The aim of the challenge is to facilitate further research into multimodal reasoning and understanding.}
}
@InProceedings{pmlr-v133-mohanty21a,
  title = 	 {Measuring Sample Efficiency and Generalization in Reinforcement Learning Benchmarks: NeurIPS 2020 Procgen Benchmark},
  author =       {Mohanty, Sharada and Poonganam, Jyotish and Gaidon, Adrien and Kolobov, Andrey and Wulfe, Blake and Chakraborty, Dipam and \u{S}emetulskis, Gra\u{z}vydas and Schapke, Jo\~{a}o and Kubilius, Jonas and Pa\"ukonis, Jurgis and Klimas, Linas and Hausknecht, Matthew and MacAlpine, Patrick and Tran, Quang Nhat and Tumiel, Thomas and Tang, Xiaocheng and Chen, Xinwei and Hesse, Christopher and Hilton, Jacob and Guss, William Hebgen and Genc, Sahika and Schulman, John and Cobbe, Karl},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {361--395},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v133/mohanty21a/mohanty21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/mohanty21a.html},
  abstract = 	 {The NeurIPS 2020 Procgen Competition was designed as a centralized benchmark with clearly defined tasks for measuring Sample Efficiency and Generalization in Reinforcement Learning. Generalization remains one of the most fundamental challenges in deep reinforcement learning, and yet we do not have enough benchmarks to measure the progress of the community on Generalization in Reinforcement Learning. We present the design of a centralized benchmark for Reinforcement Learning which can help measure Sample Efficiency and Generalization in Reinforcement Learning by doing end to end evaluation of the training and rollout phases of thousands of user submitted code bases in a scalable way. We designed the benchmark on top of the already existing Procgen Benchmark by defining clear tasks and standardizing the end to end evaluation setups. The design aims to maximize the flexibility available for researchers who wish to design future iterations of such benchmarks, and yet imposes necessary practical constraints to allow for a system like this to scale. This paper presents the competition setup and the details and analysis of the top solutions identified through this setup in context of 2020 iteration of the competition at NeurIPS.}
}



