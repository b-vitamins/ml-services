@proceedings{iwssl2020,
 booktitle = {Proceedings of the First International Workshop on Self-Supervised Learning},
 editor = {Henry Minsky and Paul Robertson and Olivier L. Georgeon and Milan Minsky and Cyrus Shaoul},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Proceedings of the First International Workshop on Self-Supervised Learning},
 volume = {131}
}

@inproceedings{pmlr-v131-georgeon20a,
 abstract = {We present a project to design interactive devices (smart displays, robots, etc.) capable of self-motivated learning through non-goal-directed interactive behaviors (e.g., curious, emotional, playful behaviors). We use and improve algorithms inspired by constructivist epistemology that we have designed previously. These algorithms incrementally learn sequential hierarchies of control loops in a bottom-up and open-ended fashion, and continuously reuse the learned higher-level control loops to generate increasingly complex behaviors that exhibit self-motivation. This project contributes to research in self-supervised learning because the learning is driven by low-level preferences that under-determine the device’s future behaviors, leaving room for individuation, which, in turn, opens the way to autonomy in learning.},
 author = {Georgeon, Olivier L. and Robertson, Paul and Xue, Jianyong},
 booktitle = {Proceedings of the First International Workshop on Self-Supervised Learning},
 editor = {Minsky, Henry and Robertson, Paul and Georgeon, Olivier L. and Minsky, Milan and Shaoul, Cyrus},
 month = {27--28 Feb},
 openalex = {W3083105168},
 pages = {5--14},
 pdf = {http://proceedings.mlr.press/v131/georgeon20a/georgeon20a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Generating Natural Behaviors using Constructivist Algorithms},
 url = {https://proceedings.mlr.press/v131/georgeon20a.html},
 volume = {131},
 year = {2020}
}

@inproceedings{pmlr-v131-kommrusch20a,
 abstract = {Modern machine learning research has explored numerous approaches to solving reinforce- ment learning with multiple goals and sparse rewards as well as learning correct actions from a small number of exploratory samples. We explore the ability of a self-supervised system which automatically creates and tests symbolic hypotheses about the world to ad- dress these same issues. Leela is a system which builds an understanding of the world using constructivist artificial intelligence. For our study, we create an N â N grid world with goals related to proprioceptive or visual positions for exploration. We compare Leela to a DQN which includes hindsight for improving multigoal learning with sparse rewards. Our results show that Leela is able to learn to solve multigoal problems in an N â N world with approximately 160N2 exploratory steps compared to 360N2.7 steps required by the DQN.},
 author = {Kommrusch, Steve},
 booktitle = {Proceedings of the First International Workshop on Self-Supervised Learning},
 editor = {Minsky, Henry and Robertson, Paul and Georgeon, Olivier L. and Minsky, Milan and Shaoul, Cyrus},
 month = {27--28 Feb},
 openalex = {W3116051060},
 pages = {72--88},
 pdf = {http://proceedings.mlr.press/v131/kommrusch20a/kommrusch20a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Self-Supervised Learning for Multi-Goal Grid World: Comparing Leela and Deep Q Network},
 url = {https://proceedings.mlr.press/v131/kommrusch20a.html},
 volume = {131},
 year = {2020}
}

@inproceedings{pmlr-v131-lieberman20a,
 abstract = {There are two ways that systems, human or machine, can get âmotivatedâ to take action in problem solving. One, they can be given goals by some external entity. In some instances, they might have no capability other than to work towards the goals provided by that entity. Two, they can have their own, internal goals, and work towards those goals. If given a goal by an outside entity, they can then try to figure out whether, and how, the external goal might align with their internal goals. In that case, the agent might be said to be acting in a âself-supervisedâ manner. There are, of course, cases where both intrinsic and extrinsic motivation come into play. This paper will argue that many machine learning systems, as well as human organiza- tions, put too much emphasis on extrinsic motivation, and have not fully taken advantage of the potential of intrinsic motivation. Reinforcement learning systems, for example, have a âreward signalâ that is the sole extrinsic motivating factor. It is no wonder then, that even when such systems work well, they are incapable of explaining themselves, because they cannot express an explanation in terms of their own (or their usersâ) goals. In hu- man organizations, relying only on extrinsic motivation (= âincentiveâ) leads to rigid or dictatorial organizations; engaging internal motivation (at some cost to âorganizational efficiencyâ) can lead to creativity and invention.},
 author = {Lieberman, Henry},
 booktitle = {Proceedings of the First International Workshop on Self-Supervised Learning},
 editor = {Minsky, Henry and Robertson, Paul and Georgeon, Olivier L. and Minsky, Milan and Shaoul, Cyrus},
 month = {27--28 Feb},
 openalex = {W3117388390},
 pages = {62--71},
 pdf = {http://proceedings.mlr.press/v131/lieberman20a/lieberman20a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Intrinsic and Extrinsic Motivation in Intelligent Systems},
 url = {https://proceedings.mlr.press/v131/lieberman20a.html},
 volume = {131},
 year = {2020}
}

@inproceedings{pmlr-v131-macbeth20a,
 abstract = {This paper proposes work that applies insights from meaning representation systems for in-depth natural language understanding to representations for self-supervised learning systems, which show promise in developing complex, deeply-nested symbolic structures through self-motivated exploration of their environments. The core of the representation system transforms language inputs into language-free structures that are complex combinations of conceptual primitives, forming a substrate for human-like understanding and common-sense reasoning. We focus on decomposing representations of expectation, intention, planning, and decision-making which are essential to a self-motivated learner. These meaning representations may enhance learning by enabling a rich array of mappings between new experiences and structures stored in short-term and long-term memory. We also argue that learning can be further enhanced when language interaction itself is an integral part of the environment in which the self-supervised learning agent is embedded.},
 author = {Macbeth, Jamie C.},
 booktitle = {Proceedings of the First International Workshop on Self-Supervised Learning},
 editor = {Minsky, Henry and Robertson, Paul and Georgeon, Olivier L. and Minsky, Milan and Shaoul, Cyrus},
 month = {27--28 Feb},
 openalex = {W3115734318},
 pages = {89--98},
 pdf = {http://proceedings.mlr.press/v131/macbeth20a/macbeth20a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Primitive-Decomposed Cognitive Representations Enhancing Learning with Primitive-Decomposed Cognitive Representations.},
 url = {https://proceedings.mlr.press/v131/macbeth20a.html},
 volume = {131},
 year = {2020}
}

@inproceedings{pmlr-v131-robertson20a,
 abstract = {This collection of papers was presented at the first annual international workshop on self- supervised learning (IWSSL2020) held in Cambridge, Massachusetts, between February 27 and February 28, 2020. They represent the state of the art in an expanding field of research that attempts to build systems that can learn without human intervention with little or no hard-wired domain knowledge, as would a new-born child or animal.},
 author = {Robertson, Paul and Minsky, Henry and Shaoul, Cyrus and Minsky, Milan and Georgeon, Olivier},
 booktitle = {Proceedings of the First International Workshop on Self-Supervised Learning},
 editor = {Minsky, Henry and Robertson, Paul and Georgeon, Olivier L. and Minsky, Milan and Shaoul, Cyrus},
 month = {27--28 Feb},
 openalex = {W3093736614},
 pages = {1--4},
 pdf = {http://proceedings.mlr.press/v131/robertson20a/robertson20a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {IWSSL Introduction to this volume},
 url = {https://proceedings.mlr.press/v131/robertson20a.html},
 volume = {131},
 year = {2020}
}

@inproceedings{pmlr-v131-robertson20b,
 abstract = {We present a novel approach to state space discretization for constructivist and reinforcement learning. Constructivist learning and reinforcement learning often operate on a predefined set of states and transitions (state space). AI researchers design algorithms to reach particular goal states in this state space (for example, visualized in the form of goal cells that a robot should reach in a grid). When the size and the dimensionality of the state space increases, however, finding goal states becomes intractable. It is nonetheless assumed that these algorithms can have useful applications in the physical world provided that there is a way to construct a discrete state space of reasonable size and dimensionality. Yet, the manner in which the state space is discretized is the source of many problems for both constructivist and reinforcement learning approaches. The problems can roughly be divided into two categories: (1) wiring too much domain information into the solution, and (2) requiring massive storage to represent the state space (such as Q-tables. The problems relate to (1) the non generality arising from wiring domain information into the solution, and (2) non scalability of the approach to useful domains involving high dimensional state spaces. Another important limitation is that high dimensional state spaces require a massive number of learning trials. We present a new approach that builds upon ideas from place cells and cognitive maps.},
 author = {Robertson, Paul and Georgeon, Olivier},
 booktitle = {Proceedings of the First International Workshop on Self-Supervised Learning},
 editor = {Minsky, Henry and Robertson, Paul and Georgeon, Olivier L. and Minsky, Milan and Shaoul, Cyrus},
 month = {27--28 Feb},
 openalex = {W3113815635},
 pages = {15--31},
 pdf = {http://proceedings.mlr.press/v131/robertson20b/robertson20b.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Continuous Learning of Action and State Spaces (CLASS)},
 url = {https://proceedings.mlr.press/v131/robertson20b.html},
 volume = {131},
 year = {2020}
}

@inproceedings{pmlr-v131-thorisson20a,
 abstract = {The knowledge that a natural learner creates of any new situation will initially not only be partial but very likely be partially incorrect. To improve incomplete and incorrect knowl- edge with increased experience â accumulated evidence â learning processes must bring already-acquired knowledge towards making sense of new situations. For the initial creation of knowledge, and its subsequent usage, expansion, modification, unification, and deletion, knowledge construction mechanisms must be self-guided, capable of self-supervised âsur- gicalâ operation on existing knowledge, involving among other things self-inspection or reflection. Further, the information that makes up an agentâs knowledge set must thus be structured in a way that supports reflective processes including discrimination, compari- son, and manipulation of arbitrary subsets of the knowledge set. Few proposals for how to achieve this in a parsimonious way exist. Here we present a theory of how systems with these properties may work, and how cumulative self-supervised learning mechanisms can reach levels of autonomy like those seen in individuals of many animal species. Our theory rests on the hypotheses that learning is (a) organized around causal relations, (b) boot- strapped from observed correlations, using (c) fine-grain relational models, manipulated by (d) micro-ampliative reasoning processes. We further hypothesize that a machine properly constructed in this way will be (e) capable of seed-programmed autonomous generality: The ability to apply learning to any phenomenon â that is, being domain-independent â provided that (f) the seed reference observable variables at âbirthâ, and that (g) new phenomena and existing knowledge overlap on one or more observables or inferred features. The theory is based on implemented systems that have produced notable results in the direction of increased general machine intelligence.},
 author = {Th\'orisson, Kristinn R.},
 booktitle = {Proceedings of the First International Workshop on Self-Supervised Learning},
 editor = {Minsky, Henry and Robertson, Paul and Georgeon, Olivier L. and Minsky, Milan and Shaoul, Cyrus},
 month = {27--28 Feb},
 openalex = {W3114694254},
 pages = {32--61},
 pdf = {http://proceedings.mlr.press/v131/thorisson20a/thorisson20a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Seed-Programmed Autonomous General Learning.},
 url = {https://proceedings.mlr.press/v131/thorisson20a.html},
 volume = {131},
 year = {2020}
}
