@proceedings{BigMine2015,
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Wei Fan and Albert Bifet and Qiang Yang and Philip S. Yu},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 volume = {41}
}

@inproceedings{pmlr-v41-dutta15,
 abstract = {In this industrial application paper a novel application of salad leaf disease detection has been developed using a combination of big data analytics and on field multi-dimensional sensing. We propose a cloud computing based intelligent big data analysis and interactive visual analytics platform to predict farm hot spots with high probability of potential biosecurity threats and early monitoring system aiming to save the farm from significant economic damage.},
 author = {Dutta, Ritaban and Mueller, Heiko and Smith, Daniel and Das, Aruneema and Aryal, Jagannath},
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 month = {10 Aug},
 openalex = {W2127919418},
 pages = {9--18},
 pdf = {http://proceedings.mlr.press/v41/dutta15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Interactive visual big data analytics for large area farm biosecurity monitoring: i-EKbase system},
 url = {https://proceedings.mlr.press/v41/dutta15.html},
 volume = {41},
 year = {2015}
}

@inproceedings{pmlr-v41-fan15,
 abstract = {Fractional calculus has gained considerable popularity and importance during the past three decades mainly because of its demonstrated applications in numerous seemingly diverse and widespread fields of science and engineering. The chapter presents results, including the existence and uniqueness of solutions for the Cauchy Type and Cauchy problems involving nonlinear ordinary fractional differential equations, explicit solutions of linear differential equations and of the corresponding initial-value problems by their reduction to Volterra integral equations and by using operational and compositional methods; applications of the one-and multidimensional Laplace, Mellin, and Fourier integral transforms in deriving the closed-form solutions of ordinary and partial differential equations; and a theory of the so-called “sequential linear fractional differential equations,” including a generalization of the classical Frobenius method.},
 author = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 month = {10 Aug},
 openalex = {W4240465921},
 pages = {i--xii},
 pdf = {http://proceedings.mlr.press/v41/fan15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Preface},
 url = {https://proceedings.mlr.press/v41/fan15.html},
 volume = {41},
 year = {2015}
}

@inproceedings{pmlr-v41-hassani15,
 abstract = {Challenges for clustering streaming data are getting continuously more sophisticated. This trend is driven by the the emerging requirements of the application where those algorithms are used and the properties of the stream itself. Some of these properties are the continuous data arrival, the time-critical processing of objects, the evolution of the data streams, the presence of outliers and the varying densities of the data. Due to the fact that the stream evolves continuously in the process of its existence, it is crucial that the algorithm autonomously detects clusters of arbitrary shape, with different densities, and varying number of clusters. Recently, the first hierarchical density-based stream clustering algorithm based on cluster stability, called HASTREAM, was proposed. Although the algorithm was able to meet the above mentioned requirements, it inherited the main drawback of density-based hierarchical clustering algorithms, namely the efficiency issues. In this paper we propose I-HASTREAM, a first density-based hierarchical clustering algorithm that has considerably less computational time than HASTREAM. Our proposed method utilizes and introduces techniques from the graph theory domain to devise an incremental update of the underlying model instead of repeatedly performing the expensive calculations of the huge graph. Specifically the Prim's algorithm for constructing the minimal spanning tree is adopted by introducing novel, incremental maintenance of the tree by vertex and edge insertion and deletion. The extensive experimental evaluation study on real world datasets shows that I-HASTREAM is considerably faster than a state-of-the-art hierarchical density-based stream clustering approach while delivering almost the same clustering quality.},
 author = {Hassani, Marwan and Spaus, Pascal and Cuzzocrea, Alfredo and Seidl, Thomas},
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 month = {10 Aug},
 openalex = {W1859302478},
 pages = {49--64},
 pdf = {http://proceedings.mlr.press/v41/hassani15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Adaptive stream clustering using incremental graph maintenance},
 url = {https://proceedings.mlr.press/v41/hassani15.html},
 volume = {41},
 year = {2015}
}

@inproceedings{pmlr-v41-ormandi15,
 abstract = {We consider the problem of estimating occurrence rates of rare events for extremely sparse data using pre-existing hierarchies and selected features to perform inference along multiple dimensions. In particular, we focus on the problem of estimating click rates for {Advertiser, Publisher, User} tuples where both the Advertisers and the Publishers are organized as hierarchies that capture broad contextual information at different levels of granularities. Typically, the click rates are low and the coverage of the hierarchies and dimensions is sparse. To overcome these difficulties, we decompose the joint prior of the three-dimensional Click-Through-Rate (CTR) using tensor decomposition and propose a Multidimensional Hierarchical Bayesian framework (abbreviated as MadHab). We set up a specific framework of each dimension to model dimension-specific characteristics. More specifically, we consider the hierarchical beta process prior for the Advertiser dimension and for the Publisher dimension respectively and a feature-dependent mixture model for the User dimension. Besides the centralized implementation, we propose a distributed algorithm through Spark for inference which make the model highly scalable and suited for large scale data mining applications. We demonstrate that on a real world ads campaign platform our framework can effectively discriminate extremely rare events in terms of their click propensity.},
 author = {Ormandi, Robert and Yang, Hongxia and Lu, Quan},
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 month = {10 Aug},
 openalex = {W1893290116},
 pages = {33--48},
 pdf = {http://proceedings.mlr.press/v41/ormandi15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Scalable Multidimensional Hierarchical Bayesian modeling on Spark},
 url = {https://proceedings.mlr.press/v41/ormandi15.html},
 volume = {41},
 year = {2015}
}

@inproceedings{pmlr-v41-ravindra15,
 abstract = {Clustering is a central problem in non-relational data analysis, with k-means being the most popular clustering technique. In various scenarios, it may be necessary to perform clustering over the same input data multiple times - with different values of k, different clustering attributes, or different initial centroids - before arriving at the final solution. In this paper, we propose algorithms for parallel execution of multiple runs of k-means clustering in a way that achieves substantial savings of IO and processing resources. Proposed algorithms can easily be implemented over Hadoop/MapReduce, Spark, etc., with savings in map and reduce phases. Extensive performance evaluation using real-world datasets show that the proposed algorithms result in up to 40% savings in response times when compared to other optimization techniques proposed in literature as well as open-source implementations. The algorithms scale well with increasing data sizes, values of k, and number of clustering tasks.},
 author = {Ravindra, Padmashree and Gupta, Rajeev and Anyanwu, Kemafor},
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 month = {10 Aug},
 openalex = {W1959993486},
 pages = {81--96},
 pdf = {http://proceedings.mlr.press/v41/ravindra15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Shared execution of clustering tasks},
 url = {https://proceedings.mlr.press/v41/ravindra15.html},
 volume = {41},
 year = {2015}
}

@inproceedings{pmlr-v41-razavi15,
 abstract = {With the advancement of data generation technologies such as sensor networks, multiple data streams are continuously generated. Clustering multiple data streams is challenging as the requirement of clustering at anytime becomes more critical. We aim to cluster multiple data streams concurrently and in this paper we report our work in progress. ClusTree is an anytime clustering algorithm for a single stream. It uses a hierarchical tree structure to index micro-clusters, which are summary statistics for streaming data objects. We design a dynamic, concurrent indexing tree structure that extends the ClusTree structure to achieve more granular micro clusters (summaries) of multiple streams at any time. We devised algorithms to search, expand and update the hierarchical tree structure of storing micro clusters concurrently, along with an algorithm for anytime concurrent clustering of multiple streams. As this is work in progress, we plan to test our proposed algorithms, on sensor data sets, and evaluate the space and time complexity of creating and accessing micro-clusters. We will also evaluate the quality of clustering in terms of number of created clusters and compare our technique with other approaches.},
 author = {Razavi Hesabi, Zhinoos and Sellis, Timos and Zhang, Xiuzhen},
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 month = {10 Aug},
 openalex = {W1936851715},
 pages = {19--32},
 pdf = {http://proceedings.mlr.press/v41/razavi15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Anytime concurrent clustering of multiple streams with an indexing tree},
 url = {https://proceedings.mlr.press/v41/razavi15.html},
 volume = {41},
 year = {2015}
}

@inproceedings{pmlr-v41-reutemann15,
 abstract = {ADAMS is a modular open-source Java framework for developing workflows available for academic research as well as commercial applications. It integrates data mining applications, like MOA, WEKA, MEKA and R, image and video processing and feature generation capabilities, spreadsheet and database access, visualizations, GIS, webservices and fast protoyping of new functionality using scripting languages (Groovy/Jython).},
 author = {Reutemann, Peter and Holmes, Geoff},
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 month = {10 Aug},
 openalex = {W2116289560},
 pages = {5--8},
 pdf = {http://proceedings.mlr.press/v41/reutemann15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Big Data with ADAMS},
 url = {https://proceedings.mlr.press/v41/reutemann15.html},
 volume = {41},
 year = {2015}
}

@inproceedings{pmlr-v41-vanschoren15,
 abstract = {OpenML is an online platform where scientists can automatically log and share machine learning data sets, code, and experiments, organize them online, and build directly on the work of others. It helps to automate many tedious aspects of research, is readily integrated into several machine learning tools, and offers easy-to-use APIs. It also enables large-scale and real-time collaboration, allowing researchers to share their very latest results, while keeping track of their impact and reuse. The combined and linked results provide a wealth of information to speed up research, assist people while analyzing data, or automate the process altogether.},
 author = {Vanschoren, Joaquin and Rijn, Jan N. and Bischl, Bernd},
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 month = {10 Aug},
 openalex = {W2195263870},
 pages = {1--4},
 pdf = {http://proceedings.mlr.press/v41/vanschoren15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Taking machine learning research online with OpenML},
 url = {https://proceedings.mlr.press/v41/vanschoren15.html},
 volume = {41},
 year = {2015}
}

@inproceedings{pmlr-v41-zhang15,
 abstract = {In the era of Big Data, the iterative nature of most traditional learning algorithms renders them increasingly inefficient to address large learning problems. Random decision trees algorithm is an efficient and decent learning algorithm, but the complexity of tree structure makes the algorithm inefficient for the big data problems. Inspired by the theoretical analyses of random decision trees, we propose a randomized algorithm for big data classification tasks based on unsupervised locality sensitive hashing. Our algorithm is essentially non-iterative, very flexible to deploy over clusters of machines, and thus able to handle large datasets efficiently. Experiments on real datasets demonstrate that the proposed algorithm can easily scale up to millions of data samples and features while still achieves at most 17% and 800% improvement in accuracy and efficiency respectively with moderate memory consumption over existing algorithms.},
 author = {Zhang, Xiatian and Fan, Wei and Du, Nan},
 booktitle = {Proceedings of the 4th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
 editor = {Fan, Wei and Bifet, Albert and Yang, Qiang and Yu, Philip S.},
 month = {10 Aug},
 openalex = {W1763174229},
 pages = {65--80},
 pdf = {http://proceedings.mlr.press/v41/zhang15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Random decision hashing for massive data learning},
 url = {https://proceedings.mlr.press/v41/zhang15.html},
 volume = {41},
 year = {2015}
}
