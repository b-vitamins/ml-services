@proceedings{COLT2013,
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shai Shalev-Shwartz and Ingo Steinwart},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Proceedings of the 26th Annual Conference on Learning Theory},
 volume = {30}
}

@inproceedings{pmlr-v30-Abraham13,
 abstract = {Very recently crowdsourcing has become the de facto platform for distributing and collecting human computation for a wide range of tasks and applications such as information retrieval, natural language processing and machine learning. Current crowdsourcing platforms have some limitations in the area of quality control. Most of the effort to ensure good quality has to be done by the experimenter who has to manage the number of workers needed to reach good results. We propose a simple model for adaptive quality control in crowdsourced multiple-choice tasks which we call the bandit survey problem. This model is related to, but technically different from the well-known multi-armed bandit problem. We present several algorithms for this problem, and support them with analysis and simulations. Our approach is based in our experience conducting relevance evaluation for a large commercial search engine.},
 address = {Princeton, NJ, USA},
 author = {Abraham, Ittai and Alonso, Omar and Kandylas, Vasilis and Slivkins, Aleksandrs},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2164215566},
 pages = {882--910},
 pdf = {http://proceedings.mlr.press/v30/Abraham13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Adaptive Crowdsourcing Algorithms for the Bandit Survey Problem},
 url = {https://proceedings.mlr.press/v30/Abraham13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Acharya13,
 abstract = {Via a unied view of probability estimation, classication, and prediction, we derive a uniformly-optimal combined-probability estimator, construct a classier that uniformly approaches the error of the best possible label-invariant classier, and improve existing},
 address = {Princeton, NJ, USA},
 author = {Acharya, Jayadev and Jafarpour, Ashkan and Orlitsky, Alon and Suresh, Ananda Theertha},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2096133806},
 pages = {764--796},
 pdf = {http://proceedings.mlr.press/v30/Acharya13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Optimal Probability Estimation with Applications to Prediction and Classification},
 url = {https://proceedings.mlr.press/v30/Acharya13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Agarwal13,
 abstract = {The area under the ROC curve (AUC) is a widely used performance measure in machine learning, and has been widely studied in recent years particularly in the context of bipartite ranking. A dominant theoretical and algorithmic framework for AUC optimization/bipartite ranking has been to reduce the problem to pairwise classication; in particular, it is well known that the AUC regret can be formulated as a pairwise classication regret, which in turn can be upper bounded using usual regret bounds for binary classication. Recently, Kotlowski et al. (2011) showed AUC regret bounds in terms of the regret associated with ‘balanced’ versions of the standard (non-pairwise) logistic and exponential losses. In this paper, we obtain such (non-pairwise) surrogate regret bounds for the AUC in terms of a broad class of proper (composite) losses that we term strongly proper. Our proof technique is considerably simpler than that of Kotlowski et al. (2011), and relies on properties of proper (composite) losses as elucidated recently by Reid and Williamson (2009, 2010, 2011) and others. Our result yields explicit surrogate bounds (with no hidden balancing terms) in terms of a variety of strongly proper losses, including for example logistic, exponential, squared and squared hinge losses. An important consequence is that standard algorithms minimizing a (non-pairwise) strongly proper loss, such as logistic regression and boosting algorithms (assuming a universal function class and appropriate regularization), are in fact AUC-consistent; moreover, our results allow us to quantify the AUC regret in terms of the corresponding surrogate regret. We also obtain tighter surrogate regret bounds under certain low-noise conditions via a recent result of Cl emen con and Robbiano (2011).},
 address = {Princeton, NJ, USA},
 author = {Agarwal, Shivani},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W9828162},
 pages = {338--353},
 pdf = {http://proceedings.mlr.press/v30/Agarwal13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Surrogate Regret Bounds for the Area Under the ROC Curve via Strongly Proper Losses},
 url = {https://proceedings.mlr.press/v30/Agarwal13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Anandkumar13,
 abstract = {Detecting hidden communities from observed interactions is a classical problem. Theoretical analysis of community detection has so far been mostly limited to models with non-overlapping communities such as the stochastic block model. In this paper, we provide guaranteed community detection for a family of probabilistic network models with overlapping communities, termed as the mixed membership Dirichlet model, first introduced in Airoldi et al. (2008). This model allows for nodes to have fractional memberships in multiple communities and assumes that the community memberships are drawn from a Dirichlet distribution. Moreover, it contains the stochastic block model as a special case. We propose a unified approach to learning communities in these models via a tensor spectral decomposition approach. Our estimator uses low-order moment tensor of the observed network, consisting of 3-star counts. Our learning method is based on simple linear algebraic operations such as singular value decomposition and tensor power iterations. We provide guaranteed recovery of community memberships and model parameters, and present a careful finite sample analysis of our learning method. Additionally, our results match the best known scaling requirements for the special case of the (homogeneous) stochastic block model.},
 address = {Princeton, NJ, USA},
 author = {Anandkumar, Animashree and Ge, Rong and Hsu, Daniel and Kakade, Sham},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2167026441},
 pages = {867--881},
 pdf = {http://proceedings.mlr.press/v30/Anandkumar13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {A Tensor Spectral Approach to Learning Mixed Membership Community Models},
 url = {https://proceedings.mlr.press/v30/Anandkumar13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Anava13,
 abstract = {We address the problem of predicting a time series using the ARMA (autoregressive moving average) model, under minimal assumptions on the noise terms. Using regret minimization techniques, we develop eective online learning algorithms for the prediction problem, without assuming that the noise terms are Gaussian, identically distributed or even independent. Furthermore, we show that our algorithm’s performances asymptotically approaches the performance of the best ARMA model in hindsight.},
 address = {Princeton, NJ, USA},
 author = {Anava, Oren and Hazan, Elad and Mannor, Shie and Shamir, Ohad},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2126007324},
 pages = {172--184},
 pdf = {http://proceedings.mlr.press/v30/Anava13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Online Learning for Time Series Prediction},
 url = {https://proceedings.mlr.press/v30/Anava13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Anderson13,
 abstract = {We show an ecient algorithm for the following problem: Given uniformly random points from an arbitrary n-dimensional simplex, estimate the simplex. The size of the sample and the number of arithmetic operations of our algorithm are polynomial in n. This answers a question of Frieze, Jerrum and Kannan Frieze et al. (1996). Our result can also be interpreted as eciently learning the intersection of n + 1 half-spaces in R n in the model where the intersection is bounded and we are given polynomially many uniform samples from it. Our proof uses the local search technique from Independent Component Analysis (ICA), also used by Frieze et al. (1996). Unlike these previous algorithms, which were based on analyzing the fourth moment, ours is based on the third moment. We also show a direct connection between the problem of learning a simplex and ICA: a simple randomized reduction to ICA from the problem of learning a simplex. The connection is based on a known representation of the uniform measure on a simplex. Similar representations lead to a reduction from the problem of learning an ane transformation},
 address = {Princeton, NJ, USA},
 author = {Anderson, Joseph and Goyal, Navin and Rademacher, Luis},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2962991120},
 pages = {1020--1045},
 pdf = {http://proceedings.mlr.press/v30/Anderson13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Efficient Learning of Simplices},
 url = {https://proceedings.mlr.press/v30/Anderson13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Andrew13,
 abstract = {We consider algorithms for "smoothed online convex optimization" problems, a variant of the class of online convex optimization problems that is strongly related to metrical task systems. Prior literature on these problems has focused on two performance metrics: regret and the competitive ratio. There exist known algorithms with sublinear regret and known algorithms with constant competitive ratios; however, no known algorithm achieves both simultaneously. We show that this is due to a fundamental incompatibility between these two metrics - no algorithm (deterministic or randomized) can achieve sublinear regret and a constant competitive ratio, even in the case when the objective functions are linear. However, we also exhibit an algorithm that, for the important special case of one-dimensional decision spaces, provides sublinear regret while maintaining a competitive ratio that grows arbitrarily slowly.},
 address = {Princeton, NJ, USA},
 author = {Andrew, Lachlan and Barman, Siddharth and Ligett, Katrina and Lin, Minghong and Meyerson, Adam and Roytman, Alan and Wierman, Adam},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W3039767703},
 pages = {741--763},
 pdf = {http://proceedings.mlr.press/v30/Andrew13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {A Tale of Two Metrics: Simultaneous Bounds on Competitiveness and Regret},
 url = {https://proceedings.mlr.press/v30/Andrew13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Awasthi13,
 abstract = {We introduce a new model of membership query (MQ) learning, where the learning algorithm is restricted to query points that are close to random examples drawn from the underlying distribution. The learning model is intermediate between the PAC model (Valiant, 1984) and the PAC+MQ model (where the queries are allowed to be arbitrary points). Membership query algorithms are not popular among machine learning practitioners. Apart from the obvious diculty of adaptively querying labelers, it has also been observed},
 address = {Princeton, NJ, USA},
 author = {Awasthi, Pranjal and Feldman, Vitaly and Kanade, Varun},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2963937021},
 pages = {398--431},
 pdf = {http://proceedings.mlr.press/v30/Awasthi13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning using Local Membership Queries},
 url = {https://proceedings.mlr.press/v30/Awasthi13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Bach13,
 abstract = {We consider supervised learning problems within the positive-definite kernel framework, such as kernel ridge regression, kernel logistic regression or the support vector machine. With kernels leading to infinite-dimensional feature spaces, a common practical limiting difficulty is the necessity of computing the kernel matrix, which most frequently leads to algorithms with running time at least quadratic in the number of observations n, i.e., O(n^2). Low-rank approximations of the kernel matrix are often considered as they allow the reduction of running time complexities to O(p^2 n), where p is the rank of the approximation. The practicality of such methods thus depends on the required rank p. In this paper, we show that in the context of kernel ridge regression, for approximations based on a random subset of columns of the original kernel matrix, the rank p may be chosen to be linear in the degrees of freedom associated with the problem, a quantity which is classically used in the statistical analysis of such methods, and is often seen as the implicit number of parameters of non-parametric estimators. This result enables simple algorithms that have sub-quadratic running time complexity, but provably exhibit the same predictive performance than existing algorithms, for any given problem instance, and not only for worst-case situations.},
 address = {Princeton, NJ, USA},
 author = {Bach, Francis},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2127459401},
 pages = {185--209},
 pdf = {http://proceedings.mlr.press/v30/Bach13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Sharp analysis of low-rank kernel matrix approximations},
 url = {https://proceedings.mlr.press/v30/Bach13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Balcan13,
 abstract = {We provide new results concerning label efficient, polynomial time, passive and active learning of linear separators. We prove that active learning provides an exponential improvement over PAC (passive) learning of homogeneouslinear separators under nearly log-concave distributions. Building on this, we provide a computationally efficient PAC algorithm with optimal (up to a constant factor) sample complexity for such problems. This resolves an open question of (Long, 1995, 2003; Bshouty et al., 2009) concerning the sample complexity of efficient PAC algorithms under the uniformdistribution in the unit ball. Moreover,it providesthe first bound for a polynomial-time PAC algorithm that is tight for an interesting infinite class of hypothesis functions under a general and natural class of data-distributions, providing significant progress towards a longstanding open question of (Ehrenfeucht et al., 1989; Blumer et al., 1989). We also provide new bounds for active and passive learning in the case that the data might not be linearly separable, both in the agnostic case and and underthe Tsybakovlow-noisecondition. To derive our results, we provide new structural results for (nearly) log-concave distributions, which might be of independent interest as well.},
 address = {Princeton, NJ, USA},
 author = {Balcan, Maria-Florina and Long, Phil},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2963402790},
 pages = {288--316},
 pdf = {http://proceedings.mlr.press/v30/Balcan13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Active and passive learning of linear separators under log-concave distributions},
 url = {https://proceedings.mlr.press/v30/Balcan13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Bartlett13,
 abstract = {We study online learning under logarithmic loss with regular parametric models. Hedayati and Bartlett (2012b) showed that a Bayesian prediction strategy with Jereys prior and sequential normalized maximum likelihood (SNML) coincide and are optimal if and only if the latter is exchangeable, and if and only if the optimal strategy can be calculated without knowing the time horizon in advance. They put forward the question what families have exchangeable SNML strategies. This paper fully answers this open problem for onedimensional exponential families. The exchangeability can happen only for three classes of natural exponential family distributions, namely the Gaussian, Gamma, and the Tweedie exponential family of order 3=2.},
 address = {Princeton, NJ, USA},
 author = {Bartlett, Peter and GrÃ¼nwald, Peter and HarremoÃ«s, Peter and Hedayati, Fares and Kotlowski, Wojciech},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2962839951},
 pages = {639--661},
 pdf = {http://proceedings.mlr.press/v30/Bartlett13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Horizon-Independent Optimal Prediction with Log-Loss in Exponential Families},
 url = {https://proceedings.mlr.press/v30/Bartlett13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Bartok13,
 abstract = {Partial monitoring is an online learning model where in every time step, after a learner and an opponent choose their actions, the loss and the feedback for the learner is calculated based on a loss and a feedback function, both of which are known to the learner ahead of time. As in other online learning scenarios, the goal of the learner is to minimize his cumulative loss. In this paper we present and analyze a new algorithm for locally observable partial monitoring games. We prove that the expected regret of our algorithm is of O( √ N ′T ), where T is the time horizon and N ′ is the size of the largest point-local game. The most important improvement of this bound compared to previous results is that it does not depend directly on the number of actions, but rather on the structure of the game.},
 address = {Princeton, NJ, USA},
 author = {BartÃ³k, GÃ¡bor},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W148375489},
 pages = {696--710},
 pdf = {http://proceedings.mlr.press/v30/Bartok13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {A near-optimal algorithm for finite partial-monitoring games against adversarial opponents},
 url = {https://proceedings.mlr.press/v30/Bartok13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Belkin13,
 abstract = {A prototypical blind signal separation problem is the so-called cocktail party problem, with n people talking simultaneously and n dierent microphones within a room. The goal is to recover each speech signal from the microphone inputs. Mathematically this can be modeled by assuming that we are given samples from an n-dimensional random variable X = AS, where S is a vector whose coordinates are independent random variables corresponding to each speaker. The objective is to recover the matrix A 1 given random samples from X. A range of techniques collectively known as Independent Component Analysis (ICA) have been proposed to address this problem in the signal processing and machine learning literature. Many of these techniques are based on using the kurtosis or other cumulants to recover the components. In this paper we propose a new algorithm for solving the blind signal separation problem in the presence of additive Gaussian noise, when we are given samples from X = AS + , where is drawn from an unknown, not necessarily spherical n-dimensional Gaussian distribution. Our approach is based on a method for decorrelating a sample with additive Gaussian noise under the assumption that the underlying distribution is a linear transformation of a distribution with independent components. Our decorrelation routine is based on the properties of cumulant tensors and can be combined with any standard cumulant-based method for ICA to get an algorithm that is provably robust in the presence of Gaussian noise. We derive polynomial bounds for the sample complexity and error propagation of our method.},
 address = {Princeton, NJ, USA},
 author = {Belkin, Mikhail and Rademacher, Luis and Voss, James},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2963122254},
 pages = {270--287},
 pdf = {http://proceedings.mlr.press/v30/Belkin13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Blind Signal Separation in the Presence of Gaussian Noise},
 url = {https://proceedings.mlr.press/v30/Belkin13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Bernstein13,
 abstract = {This paper considers a generalized no-regret problem with vector-valued rewards, defined in terms of a desired reward set of the agent. For each mixed action q of the opponent, the agent has a set R � (q) where the average reward should reside. In addition, the agent has a response mixed action p which brings the expected reward under these two actions, r(p;q), to R � (q). If a strategy of the agent ensures that the average reward converges to R � (¯qn), where ¯ qn is the empirical distribution of the opponent’s actions, for any strategy of the opponent, we say that it is a no-regret strategy with respect to R � (q). When the multifunction q 㜡 R � (q) is convex, as is the case in the standard no-regret problem, noregret strategies can be devised. Our main interest in this paper is in cases where this convexity property does not hold. The best that can be guaranteed in general then is the convergence of the average reward to R c (¯qn), the convex hull of R � (¯qn). However, as the game unfolds, it may turn out that the opponent’s choices of actions are limited in some way. If these restrictions were known in advance, the agent could possibly ensure convergence of the average reward to some desired subset of R c (¯qn), or even approach R � (¯qn) itself. We formulate appropriate goals for opportunistic no-regret strategies, in the sense that they may exploit such limitations on the opponent’s action sequence in an on-line manner, without knowing them beforehand. As the main technical tool, we propose a class of approachability algorithms that rely on a calibrated forecast of the opponent’s actions, which are opportunistic in the above mentioned sense. As an application, we consider the online no-regret problem with average cost constraints, introduced in Mannor, Tsitsiklis, and Yu (2009). We show, in particular, that our algorithm does attain the best-responsein-hindsight for this problem if the opponent’s play happens to be stationary, or close to stationary in a certain sense.},
 address = {Princeton, NJ, USA},
 author = {Bernstein, Andrey and Mannor, Shie and Shimkin, Nahum},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2165078956},
 pages = {158--171},
 pdf = {http://proceedings.mlr.press/v30/Bernstein13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Opportunistic Strategies for Generalized No-Regret Problems},
 url = {https://proceedings.mlr.press/v30/Bernstein13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Berthet13,
 abstract = {In the context of sparse principal component detection, we bring evidence towards the existence of a statistical price to pay for computational efficiency. We measure the performance of a test by the smallest signal strength that it can detect and we propose a computationally efficient method based on semidefinite programming.We also prove that the statistical performance of this test cannot be strictly improved by any computationally efficient method. Our results can be viewed as complexity theoretic lower bounds conditionally on the assumptions that some instances of the planted clique problem cannot be solved in randomized polynomial time.},
 address = {Princeton, NJ, USA},
 author = {Berthet, Quentin and Rigollet, Philippe},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W58673994},
 pages = {1046--1066},
 pdf = {http://proceedings.mlr.press/v30/Berthet13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Complexity Theoretic Lower Bounds for Sparse Principal Component Detection},
 url = {https://proceedings.mlr.press/v30/Berthet13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Bubeck13,
 abstract = {We study the stochastic multi-armed bandit problem when one knows the value µ (⋆) of an optimal arm, as a well as a positive lower bound on the smallest positive gap�. We propose a new randomized policy that attains a regret uniformly bounded over timein this setting. We also prove several lower bounds, which show in particular that bounded regret is not possible if one only knows �, and bounded regret of order 1/� is not possible if one only knows µ (⋆) .},
 address = {Princeton, NJ, USA},
 author = {Bubeck, SÃ©bastien and Perchet, Vianney and Rigollet, Philippe},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2962949156},
 pages = {122--134},
 pdf = {http://proceedings.mlr.press/v30/Bubeck13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Bounded regret in stochastic multi-armed bandits},
 url = {https://proceedings.mlr.press/v30/Bubeck13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Chiang13,
 abstract = {Consider the online convex optimization problem, in which a player has to choose actions iteratively and suffers corresponding losses according to some convex loss functions, and the goal is to minimize the regret. In the full-information setting, the player after choosing her action can observe the whole loss function in that round, while in the bandit setting, the only information the player can observe is the loss value of that action. Designing such bandit algorithms appears challenging, as the best regret currently achieved for general convex loss functions is much higher than that in the full-information setting, while for strongly convex loss functions, there is even a regret lower bound which is exponentially higher than that achieved in the full-information setting. To aim for smaller regrets, we adopt a relaxed two-point bandit setting in which the player can play two actions in each round and observe the loss values of those two actions. Moreover, we consider loss functions parameterized by their deviation D, which measures how fast they evolve, and we study how regrets depend on D. We show that two-point bandit algorithms can in fact achieve regrets matching those in the full-information setting in terms of D. More precisely, for convex loss functions, we achieve a regret of O( √ D), while for strongly convex loss functions, we achieve a regret of O(lnD), which is much smaller than the Ω( √ D) lower bound in the traditional bandit setting.},
 address = {Princeton, NJ, USA},
 author = {Chiang, Chao-Kai and Lee, Chia-Jung and Lu, Chi-Jen},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W102889024},
 pages = {210--227},
 pdf = {http://proceedings.mlr.press/v30/Chiang13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Beating bandits in gradually evolving worlds},
 url = {https://proceedings.mlr.press/v30/Chiang13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Choi13,
 abstract = {We consider the problem of nding the edges of a hidden weighted graph and their weights by using a certain type of queries as few times as possible, with focusing on two types of queries with additive property. For a set of vertices, the additive query asks the sum of weights of the edges with both ends in the set. For a pair of disjoint sets of vertices, the cross-additive query asks the sum of weights of the edges crossing between the two sets. These queries are related to DNA sequencing and nding Fourier coecients of pseudo-Boolean functions, and have been paid attention to in computational learning. In this paper, we achieve an ultimate goal of recent years for graph nding, by constructing the rst polynomial time algorithms with optimal query complexity for the general class of graphs with n vertices and at most m edges in which the weights of edges are arbitrary real numbers. The algorithms are randomized and their query complexities areO mlog n log m which improve the best known bounds by a factor of logm. To build a key component for graph nding, we consider coin weighing with a spring scale which itself has been paid attention to in a long history of combinatorial search. We construct the rst polynomial time algorithm with optimal query complexity for the general case in which the weight dierences between counterfeit and authentic coins are arbitrary real numbers. We also construct the rst polynomial time optimal query algorithm for nding Fourier coecients of a certain class of pseudo-Boolean functions.},
 address = {Princeton, NJ, USA},
 author = {Choi, Sung-Soon},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W12328283},
 pages = {797--818},
 pdf = {http://proceedings.mlr.press/v30/Choi13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Polynomial Time Optimal Query Algorithms for Finding Graphs with Arbitrary Real Weights},
 url = {https://proceedings.mlr.press/v30/Choi13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Daniely13,
 abstract = {We consider two scenarios of multiclass online learning of a hypothesis class H Y X . In the full information scenario, the learner is exposed to instances together with their labels. In the bandit scenario, the true label is not exposed, but rather an indication whether the learner’s prediction is correct or not. We show that the ratio between the error rates in the two scenarios is at most 8j Yj log(jYj) in the realizable case, and ~ O( p jYj) in the agnostic case. The results are tight up to a logarithmic factor and essentially answer an open question from Daniely et al. (2011). We apply these results to the class of multiclass linear classiers in R d with margin 1 D . We show that the bandit error rate of this class is ~ D 2 jYj in the realizable case and ~ D p jYjT in the agnostic case. This resolves an open question from Kakade et al. (2008).},
 address = {Princeton, NJ, USA},
 author = {Daniely, Amit and Helbertal, Tom},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2964101589},
 pages = {93--104},
 pdf = {http://proceedings.mlr.press/v30/Daniely13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {The price of bandit information in multiclass online classification},
 url = {https://proceedings.mlr.press/v30/Daniely13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Dasgupta13,
 abstract = {The k-d tree was one of the first spatial data structures proposed for nearest neighbor search. Its efficacy is diminished in high-dimensional spaces, but several variants, with randomization and overlapping cells, have proved to be successful in practice. We analyze three such schemes. We show that the probability that they fail to find the nearest neighbor, for any data set and any query point, is directly related to a simple potential function that captures the difficulty of the point configuration. We then bound this potential function in two situations of interest: the first, when data come from a doubling measure, and the second, when the data are documents from a topic model.},
 address = {Princeton, NJ, USA},
 author = {Dasgupta, Sanjoy and Sinha, Kaushik},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2239648585},
 pages = {317--337},
 pdf = {http://proceedings.mlr.press/v30/Dasgupta13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Randomized partition trees for exact nearest neighbor search},
 url = {https://proceedings.mlr.press/v30/Dasgupta13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Devroye13,
 abstract = {We propose a version of the follow-the-perturbed-leader online prediction algorithm in which the cumulative losses are perturbed by independent symmetric random walks. The forecaster is shown to achieve an expected regret of the optimal order O(sqrt(n log N)) where n is the time horizon and N is the number of experts. More importantly, it is shown that the forecaster changes its prediction at most O(sqrt(n log N)) times, in expectation. We also extend the analysis to online combinatorial optimization and show that even in this more general setting, the forecaster rarely switches between experts while having a regret of near-optimal order.},
 address = {Princeton, NJ, USA},
 author = {Devroye, Luc and Lugosi, GÃ¡bor and Neu, Gergely},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2133238387},
 pages = {460--473},
 pdf = {http://proceedings.mlr.press/v30/Devroye13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Prediction by Random-Walk Perturbation},
 url = {https://proceedings.mlr.press/v30/Devroye13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Feldman13,
 abstract = {We study the complexity of approximate representation and learning of submodular functions over the uniform distribution on the Boolean hypercube $\{0,1\}^n$. Our main result is the following structural theorem: any submodular function is $\epsilon$-close in $\ell_2$ to a real-valued decision tree (DT) of depth $O(1/\epsilon^2)$. This immediately implies that any submodular function is $\epsilon$-close to a function of at most $2^{O(1/\epsilon^2)}$ variables and has a spectral $\ell_1$ norm of $2^{O(1/\epsilon^2)}$. It also implies the closest previous result that states that submodular functions can be approximated by polynomials of degree $O(1/\epsilon^2)$ (Cheraghchi et al., 2012). Our result is proved by constructing an approximation of a submodular function by a DT of rank $4/\epsilon^2$ and a proof that any rank-$r$ DT can be $\epsilon$-approximated by a DT of depth $\frac{5}{2}(r+\log(1/\epsilon))$. 
We show that these structural results can be exploited to give an attribute-efficient PAC learning algorithm for submodular functions running in time $\tilde{O}(n^2) \cdot 2^{O(1/\epsilon^{4})}$. The best previous algorithm for the problem requires $n^{O(1/\epsilon^{2})}$ time and examples (Cheraghchi et al., 2012) but works also in the agnostic setting. In addition, we give improved learning algorithms for a number of related settings. 
We also prove that our PAC and agnostic learning algorithms are essentially optimal via two lower bounds: (1) an information-theoretic lower bound of $2^{\Omega(1/\epsilon^{2/3})}$ on the complexity of learning monotone submodular functions in any reasonable model; (2) computational lower bound of $n^{\Omega(1/\epsilon^{2/3})}$ based on a reduction to learning of sparse parities with noise, widely-believed to be intractable. These are the first lower bounds for learning of submodular functions over the uniform distribution.},
 address = {Princeton, NJ, USA},
 author = {Feldman, Vitaly and Kothari, Pravesh and VondrÃ¡k, Jan},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W1779941205},
 pages = {711--740},
 pdf = {http://proceedings.mlr.press/v30/Feldman13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Representation, Approximation and Learning of Submodular Functions Using Low-rank Decision Trees},
 url = {https://proceedings.mlr.press/v30/Feldman13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Gentile13,
 abstract = {We consider online similarity prediction problems over networked data. We begin by relating this task to the more standard class prediction problem, showing that, given an arbitrary algorithm for class prediction, we can construct an algorithm for similarity prediction with nearly the same mistake bound, and vice versa. After noticing that this general construction is computationally infeasible, we target our study to {\em feasible} similarity prediction algorithms on networked data. We initially assume that the network structure is {\em known} to the learner. Here we observe that Matrix Winnow \cite{w07} has a near-optimal mistake guarantee, at the price of cubic prediction time per round. This motivates our effort for an efficient implementation of a Perceptron algorithm with a weaker mistake guarantee but with only poly-logarithmic prediction time. Our focus then turns to the challenging case of networks whose structure is initially {\em unknown} to the learner. In this novel setting, where the network structure is only incrementally revealed, we obtain a mistake-bounded algorithm with a quadratic prediction time per round.},
 address = {Princeton, NJ, USA},
 author = {Gentile, Claudio and Herbster, Mark and Pasteris, Stephen},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W1923436425},
 pages = {662--695},
 pdf = {http://proceedings.mlr.press/v30/Gentile13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Online Similarity Prediction of Networked Data from Known and Unknown Graphs},
 url = {https://proceedings.mlr.press/v30/Gentile13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Gofer13,
 abstract = {We study regret minimization bounds in which the dependence on the number of experts is replaced by measures of the realized complexity of the expert class. The measures we consider are defined in retrospect given the realized losses. We concentrate on two interesting cases. In the first, our measure of complexity is the number of different “leading experts”, namely, experts that were best at some point in time. We derive regret bounds that depend only on this measure, independent of the total number of experts. We also consider a case where all experts remain grouped in just a few clusters in terms of their realized cumulative losses. Here too, our regret bounds depend only on the number of clusters determined in retrospect, which serves as a measure of complexity. Our results are obtained as special cases of a more general analysis for a setting of branching experts, where the set of experts may grow over time according to a tree-like structure, determined by an adversary. For this setting of branching experts, we give algorithms and analysis that cover both the full information and the bandit scenarios.},
 address = {Princeton, NJ, USA},
 author = {Gofer, Eyal and Cesa-Bianchi, NicolÃ² and Gentile, Claudio and Mansour, Yishay},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2146725634},
 pages = {618--638},
 pdf = {http://proceedings.mlr.press/v30/Gofer13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Regret Minimization for Branching Experts},
 url = {https://proceedings.mlr.press/v30/Gofer13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Guha13,
 abstract = {We design differentially private algorithms for statistical model selection. Given a data set and a large, discrete collection of “models”, each of which is a family of probability distributions, the goal is to determine the model that best “fits” the data. This is a basic problem in many areas of statistics and machine learning. We consider settings in which there is a well-defined answer, in the following sense: Suppose that there is a nonprivate model selection proceduref which is the reference to which we compare our performance. Our differentially private algorithms output the correct valuef(D) wheneverf is stable on the input data setD. We work with two notions, perturbation stability and subsampling stability. We give two classes of results: generic ones, that apply to any function with discrete output set; and specific algorithms for the problem of sparse linear regression. The algorithms we describe are efficient and in some cases match the optimal nonprivate asymptotic sample complexity. Our algorithms for sparse linear regression require analyzing the stability properties of the popular LASSO estimator. We give sufficient conditions for the LASSO estimator to be robust to small changes in the data set, and show that these conditions hold with high probability under essentially the same stochastic assumptions that are used in the literature to analyze convergence of the LASSO.},
 address = {Princeton, NJ, USA},
 author = {Thakurta, Abhradeep Guha and Smith, Adam},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W92292672},
 pages = {819--850},
 pdf = {http://proceedings.mlr.press/v30/Guha13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Differentially Private Feature Selection via Stability Arguments, and the Robustness of the Lasso},
 url = {https://proceedings.mlr.press/v30/Guha13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Han13,
 abstract = {We study the problem of online learning with a notion of regret defined with respect to a set of strategies. We develop tools for analyzing the minimax rates and for deriving regret-minimization algorithms in this scenario. While the standard methods for minimizing the usual notion of regret fail, through our analysis we demonstrate existence of regret-minimization methods that compete with such sets of strategies as: autoregressive algorithms, strategies based on statistical models, regularized least squares, and follow the regularized leader strategies. In several cases we also derive efficient learning algorithms. },
 address = {Princeton, NJ, USA},
 author = {Han, Wei and Rakhlin, Alexander and Sridharan, Karthik},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 pages = {966--992},
 pdf = {http://proceedings.mlr.press/v30/Han13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Competing With Strategies},
 url = {https://proceedings.mlr.press/v30/Han13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Hardt13,
 abstract = {We consider a fundamental problem in unsupervised learning called \emph{subspace recovery}: given a collection of $m$ points in $\mathbb{R}^n$, if many but not necessarily all of these points are contained in a $d$-dimensional subspace $T$ can we find it? The points contained in $T$ are called {\em inliers} and the remaining points are {\em outliers}. This problem has received considerable attention in computer science and in statistics. Yet efficient algorithms from computer science are not robust to {\em adversarial} outliers, and the estimators from robust statistics are hard to compute in high dimensions. Are there algorithms for subspace recovery that are both robust to outliers and efficient? We give an algorithm that finds $T$ when it contains more than a $\frac{d}{n}$ fraction of the points. Hence, for say $d = n/2$ this estimator is both easy to compute and well-behaved when there are a constant fraction of outliers. We prove that it is Small Set Expansion hard to find $T$ when the fraction of errors is any larger, thus giving evidence that our estimator is an {\em optimal} compromise between efficiency and robustness. As it turns out, this basic problem has a surprising number of connections to other areas including small set expansion, matroid theory and functional analysis that we make use of here.},
 address = {Princeton, NJ, USA},
 author = {Hardt, Moritz and Moitra, Ankur},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2962933442},
 pages = {354--375},
 pdf = {http://proceedings.mlr.press/v30/Hardt13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Algorithms and Hardness for Robust Subspace Recovery},
 url = {https://proceedings.mlr.press/v30/Hardt13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Hutter13,
 abstract = {Online estimation and modelling of i.i.d. data for short sequences over large or complex alphabets is a ubiquitous (sub)problem in machine learning, information theory, data compression, statistical language processing, and document analysis. The Dirichlet-Multinomial distribution (also called Polya urn scheme) and extensions thereof are widely applied for online i.i.d. estimation. Good a-priori choices for the parameters in this regime are difficult to obtain though. I derive an optimal adaptive choice for the main parameter via tight, data-dependent redundancy bounds for a related model. The 1-line recommendation is to set the 'total mass' = 'precision' = 'concentration' parameter to m/2ln[(n+1)/m], where n is the (past) sample size and m the number of different symbols observed (so far). The resulting estimator (i) is simple, (ii) online, (iii) fast, (iv) performs well for all m, small, middle and large, (v) is independent of the base alphabet size, (vi) non-occurring symbols induce no redundancy, (vii) the constant sequence has constant redundancy, (viii) symbols that appear only finitely often have bounded/constant contribution to the redundancy, (ix) is competitive with (slow) Bayesian mixing over all sub-alphabets.},
 address = {Princeton, NJ, USA},
 author = {Hutter, Marcus},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2108147145},
 pages = {432--459},
 pdf = {http://proceedings.mlr.press/v30/Hutter13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Sparse Adaptive Dirichlet-Multinomial-like Processes},
 url = {https://proceedings.mlr.press/v30/Hutter13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Kane13,
 abstract = {We give the first polynomial-time algorithm for agnostically learning any function of a constant number of halfspaces with respect to any log-concave distribution (for any constant accuracy parameter). This result was not known even for the case of PAC learning the intersection of two halfspaces. We give two very different proofs of this result. The first develops a theory of polynomial approximation for log-concave measures and constructs a low-degree‘1 polynomial approximator for sufficiently smooth functions. The second uses techniques related to the classical moment problem to obtain sandwiching polynomials. Both approaches deviate significantly from known Fourier-based methods, where essentially all previous work required the underlying distribution to have some product structure. Additionally, we show that in the smoothed-analysis setting, the above results hold with respect to distributions that have sub-exponential tails, a property satisfied by many natural and well-studied distributions in machine learning.},
 address = {Princeton, NJ, USA},
 author = {Kane, Daniel and Klivans, Adam and Meka, Raghu},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W59017731},
 pages = {522--545},
 pdf = {http://proceedings.mlr.press/v30/Kane13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning Halfspaces Under Log-Concave Densities: Polynomial Approximations and Moment Matching},
 url = {https://proceedings.mlr.press/v30/Kane13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Kaufmann13,
 abstract = {We consider the problem of eciently exploring the arms of a stochastic bandit to identify the best subset of a specied size. Under the PAC and the xed-budget formulations, we derive improved bounds by using KL-divergence-based condence intervals. Whereas the application of a similar idea in the regret setting has yielded bounds in terms of the KL-divergence between the arms, our bounds in the pure-exploration setting involve the \Cherno information between the arms. In addition to introducing this novel quantity to the bandits literature, we contribute a comparison between strategies based on uniform and adaptive sampling for pure-exploration problems, nding evidence in favor of the latter.},
 address = {Princeton, NJ, USA},
 author = {Kaufmann, Emilie and Kalyanakrishnan, Shivaram},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W8700100},
 pages = {228--251},
 pdf = {http://proceedings.mlr.press/v30/Kaufmann13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Information Complexity in Bandit Subset Selection},
 url = {https://proceedings.mlr.press/v30/Kaufmann13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Koolen13,
 abstract = {Assume our data consists of unit vectors (directions) and we are to nd a small orthogonal set of the \the most important directions summarizing the data. We develop online algorithms for this type of problem. The techniques used are similar to Principal Component Analysis which nds the most important small rank subspace of the data. The new problem is signicantly more complex since the online algorithm maintains uncertainty over the most relevant subspace as well as directional information.},
 address = {Princeton, NJ, USA},
 author = {Koolen, Wouter M. and Nie, Jiazhong and Warmuth, Manfred},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W161751758},
 pages = {851--866},
 pdf = {http://proceedings.mlr.press/v30/Koolen13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning a set of directions},
 url = {https://proceedings.mlr.press/v30/Koolen13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Koren13,
 abstract = {Stochastic exp-concave optimization is an important primitive in machine learning that captures several fundamental problems, including linear regression, logistic regression and more. The exp-concavity property allows for fast convergence rates, as compared to general stochastic optimization. However, current algorithms that attain such rates scale poorly with the dimension n and run in time O(n), even on very simple instances of the problem. The question we pose is whether it is possible to obtain fast rates for exp-concave functions using more computationally-efficient algorithms. Consider the problem of minimizing a convex function F over a convex set K ⊆ Rn where our only access to F is via a stochastic gradient oracle, that given a point x ∈ K returns a random vector ĝx for which E[ĝx] = ∇F (x). We make the following assumptions: (i) F is α-exp-concave and twice differentiable; that is, if gx = ∇F (x) and Hx = ∇2F (x) are the gradient and Hessian at some point x ∈ K, then Hx α gxg x . (ii) The gradient oracle has ‖ĝx‖2 ≤ G with probability 1 at any point x ∈ K, for some positive constant G. (iii) For concreteness, we assume the case that K = {x ∈ Rn : ‖x‖2 ≤ 1} is the Euclidean unit ball. An important special case is when F is given as an expectation F (x) = Ez∼D[f(x, z)] over an unknown distribution D of parameters z, where for every fixed parameter value z the function f(x, z) is α-exp-concave with gradients bounded by G. Indeed, this implies that F is itself α-exp-concave (see Appendix A). Given the ability to sample from the distribution D, we can implement a gradient oracle by setting ĝx = ∇f(x, z) where z ∼ D. For example, f(x, (a, b)) = 1 2(a >x − b)2 corresponds to linear regression. In a learning scenario it is reasonable to assume that f(x, (a, b)) ≤ M with probability 1 for some constant M , which also guarantees that f is exp-concave with α = 1/M . Additional examples include the log-loss f(x, a) = − log(a>x) and the logistic loss f(x, (a, b)) = log(1+exp(−b ·a>x)), both are exp-concave provided that a, b and x are properly bounded. The goal of an optimization algorithm, given a target accuracy e, is to compute a point x for which F (x)−minx∈K F (x) ≤ e (either in expectation, or with high probability). The standard approach to general stochastic optimization, namely the Stochastic Gradient Descent algorithm, computes an e-approximate solution using O(1/e2) oracle queries. Since each iteration runs in linear time1, the total runtime of this approach is O(n/e2). 1. We assume that an oracle query runs in time O(1).},
 address = {Princeton, NJ, USA},
 author = {Koren, Tomer},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W129379251},
 pages = {1073--1075},
 pdf = {http://proceedings.mlr.press/v30/Koren13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Open Problem: Fast Stochastic Exp-Concave Optimization},
 url = {https://proceedings.mlr.press/v30/Koren13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Li13,
 abstract = {In this paper, we summarize some recent results in Li et al. (2012), which can be used to extend an important PAC-Bayesian approach, namely the Gibbs posterior, to study the nonadditive ranking risk. The methodology is based on assumption-free risk bounds and nonasymptotic oracle inequalities, which leads to nearly optimal convergence rates and optimal model selection to balance the approximation errors and the stochastic errors.},
 address = {Princeton, NJ, USA},
 author = {Li, Cheng and Jiang, Wenxin and Tanner, Martin},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2156752954},
 pages = {512--521},
 pdf = {http://proceedings.mlr.press/v30/Li13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {General Oracle Inequalities for Gibbs Posterior with Application to Ranking},
 url = {https://proceedings.mlr.press/v30/Li13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Livni13,
 abstract = {The existence of a compression scheme for every concept class with bounded VC-dimension is one of the oldest open problems in statistical learning theory. Here we demonstrate the existence of such compression schemes under stronger assumptions than nite VCdimension. Specically, for each concept class we associate a family of concept classes that we call the alternating concept classes. Under the assumption that these concept classes have bounded VC-dimension, we prove existence of a compression scheme. This result is motivated by recent progress in the eld of model theory with respect to an analogues problem. In fact, our proof can be considered as a constructive proof of these advancements. This means that we describe the reconstruction function explicitly. Not less important, the theorems and proofs we present are in purely combinatorial terms and are available to the reader who is unfamiliar with model theory. Also, using tools from model theory, we apply our results and prove existence of compression schemes in interesting cases such as concept classes dened by hyperplanes, polynomials, exponentials, restricted analytic functions and compositions, additions and multiplications of all of the above.},
 address = {Princeton, NJ, USA},
 author = {Livni, Roi and Simon, Pierre},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W27926580},
 pages = {77--92},
 pdf = {http://proceedings.mlr.press/v30/Livni13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Honest compressions and their application to compression schemes},
 url = {https://proceedings.mlr.press/v30/Livni13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Mahdavi13,
 abstract = {In this paper we consider learning in passive setting but with a slight modication. We as- sume that the target expected loss, also referred to as target risk, is provided in advance for learner as prior knowledge. Unlike most studies in the learning theory that only incorpo- rate the prior knowledge into the generalization bounds, we are able to explicitly utilize the target risk in the learning process. Our analysis reveals a surprising result on the sample complexity of learning: by exploiting the target risk in the learning algorithm, we show that when the loss function is both strongly convex and smooth, the sample complexity reduces to O (log ( 1 ) ), an exponential improvement compared to the sample complexity O ( 1 ϵ ) for learning with strongly convex loss functions. Furthermore, our proof is constructive and is based on a computationally ecient stochastic optimization algorithm for such settings which demonstrate that the proposed algorithm is practically useful.},
 address = {Princeton, NJ, USA},
 author = {Mahdavi, Mehrdad and Jin, Rong},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2963579725},
 pages = {252--269},
 pdf = {http://proceedings.mlr.press/v30/Mahdavi13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Passive Learning with Target Risk},
 url = {https://proceedings.mlr.press/v30/Mahdavi13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Minsker13,
 abstract = {We propose a new method for estimating the locations and the value of an absolute maximum (minimum) of a function from the observations contaminated by random noise. Our goal is to solve the problem under minimal regularity and shape constraints. In particular, we do not assume dierentiability of a function nor that its maximum is attained at a single point. We provide tight upper and lower bounds for the performance of proposed estimators. Our method is adaptive with respect to the unknown parameters of the problem over a large class of underlying distributions.},
 address = {Princeton, NJ, USA},
 author = {Minsker, Stanislav},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2113719870},
 pages = {105--121},
 pdf = {http://proceedings.mlr.press/v30/Minsker13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Estimation of Extreme Values and Associated Level Sets of a Regression Function via Selective Sampling},
 url = {https://proceedings.mlr.press/v30/Minsker13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Nie13,
 abstract = {Boosting algorithms can be viewed as a zero-sum game. At each iteration a new column / hypothesis is chosen from a game matrix representing the entire hypotheses class. There are algorithms for which the gap between the value of the sub-matrix (the t columns chosen so far) and the value of the entire game matrix is O( √ logn t ). A matching lower bound has been shown for random game matrices for t up to n where α ∈ (0, 1 2 ). We conjecture that with Hadamard matrices we can build a certain game matrix for which the game value grows at the slowest possible rate for t up to a fraction of n. 1. Boosting as a zero-sum game Boosting algorithms follow the following protocol in each iteration (e.g. Freund and Schapire, 1997; Freund, 1995): The algorithm provides a distribution d on a given set of n examples. Then an oracle provides “weak hypothesis” from some hypotheses class and the distribution is updated. At the end, the algorithm outputs a convex combination w of the hypotheses it received from the oracle. One can view Boosting as a zero-sum game between a row and a column player (Freund and Schapire, 1997). Each possible hypothesis provided by the oracle is a column chosen from an underlying game matrix U that represents the entire hypotheses class available to the oracle. The examples correspond to the rows of this matrix. At the end of iteration t, the algorithm has received t columns/hypotheses so far, and we use Ut to denote this sub-matrix of U. The minimax value of Ut is defined as follows: val(Ut) = min d∈Sn max w∈St dUt w = max w∈St min r=1,...,n [Ut w]r. (1) Here d is the distribution on the rows/examples and w represents a convex combination of the t columns of Ut. Finally [Ut w]r is the margin of row/example r wrt the convex combination w of the current hypotheses set. So in Boosting the value of Ut is the maximum minimum margin of all examples achievable with the current t columns of Ut. The value of Ut increases as columns are added and in this view of Boosting, the goal is to raise the value of Ut as quickly as possible to the value of the entire underlying game matrix U. There are boosting algorithms that guarantee that after O( logn 2 ) iterations, the c © 2013 J. Nie, M.K. Warmuth, S. Vishwanathan & X. Zhang. Nie Warmuth Vishwanathan Zhang gap val(U)− val(Ut) is at most (Freund and Schapire, 1997; Ratsch and Warmuth, 2005; Warmuth et al., 2008). In other words, the gap at iteration t is at most O( √ logn t ). Here we are interested in finding game matrices with a matching lower bound for the value gap. The lower bound should hold for any boosting algorithm, and therefore the gap in this case is defined as the maximum over all submatrices Ut of t columns of U: 1 gapt(U) := val(U)−max Ut val(Ut). First notice that the gap is non-zero only when t ≤ n, since for any n ×m (m > n) game matrix, its value is always attained by one of its sub-matrices of size n × (n + 1). This follows from Carathodory theorem which implies that for any column player w ∈ Sm, there is ŵ with support of size at most n+ 1 satisfying Uw = Uŵ. So wlog m ≤ n. Klein and Young (1999) showed that for a limited range of t (log n ≤ t ≤ nα with α ∈ (0, 1 2)), the gap is Ω( √ logn t ) with high probability for random bit matrices U. 2 We claim that with certain game matrices the range of t in this lower bound can be increased. 2. Lower bounds with Hadamard matrices Hadamard matrices have been used before for proving hardness results in Machine Learning (eg Kivinen et al., 1997; Warmuth and Vishwanathan, 2005) and for iteratively constructing game matrices with large gaps (Nemirovski and Yudin, 1983; Ben-Tal et al., 2001). We begin by giving a simple but weak lower bound using these matrices (an adaptation of Proposition 4.2 of Ben-Tal et al. (2001)). Let n = 2k and H be the n × n Hadamard matrix. Define Ĥ to be H with first row removed. We use game matrix U = [ Ĥ −Ĥ ] and let valD(U) denote val ([ U −U ]) . Notice that by definition 1, valD(U) = −minw∈Sn ‖Uw‖∞ ≤ 0. Theorem For 1 ≤ t ≤ n2 , valD(Ĥ) −maxĤt valD(Ĥt) ≥ √ 1 2t , where the maximum is over all sub-matrices Ĥt of t columns of Ĥ. Proof First we show valD(Ĥ) = 0. Notice that Ĥ has row sum zero and valD(Ĥ) = − min w∈Sn ‖Ĥw‖∞ ≥ −‖Ĥ 1 n ‖∞ = 0. Since H has orthogonal columns, we have that for any Ĥt, Ĥ > t Ĥt = n It − 1t1t and min w∈St ‖Ĥtw‖∞ ≥ min w∈St ‖Ĥtw‖2 √ n− 1 = min w∈St √ w>Ĥt Ĥtw n− 1 = min w∈St √ n n− 1 w>w − 1 n− 1 ≥ √ (n− t)/(n− 1)t. 1. Freund (1995) originally gave an adversarial oracle that iteratively produces a hypothesis of error w.r.t. the current distribution, and for any particular algorithm, the oracle can make this go on for Ω( logn 2 ) iterations. A lower bound of Ω( √ (logn)/t) on the value gap is a much stronger type of lower bound. 2. The same lower bound translates to random ±1 matrices via shifting and scaling.},
 address = {Princeton, NJ, USA},
 author = {Nie, Jiazhong and Warmuth, Manfred K. and Vishwanathan, S.V.N. and Zhang, Xinhua},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W146899193},
 pages = {1076--1079},
 pdf = {http://proceedings.mlr.press/v30/Nie13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Open Problem: Lower bounds for Boosting with Hadamard Matrices},
 url = {https://proceedings.mlr.press/v30/Nie13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Perchet13,
 abstract = {Approachability has become a central tool in the analysis of repeated games and online learning. A player plays a repeated vector-valued game against Nature and her objective is to have her long-term average reward inside some target set. The celebrated results of Blackwell provide a 1= p n convergence rate of the expected point-to-set distance if this is achievable, i.e., if the set is approachable. In this paper we provide a characterization for the convergence rates of approachability and show that in some cases a set can be approached with a 1=n rate. Our characterization is solely based on a combination of geometric properties of the set with properties of the repeated game, and not on additional restrictive assumptions on Nature’s behavior.},
 address = {Princeton, NJ, USA},
 author = {Perchet, Vianney and Mannor, Shie},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2136243650},
 pages = {474--488},
 pdf = {http://proceedings.mlr.press/v30/Perchet13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Approachability, fast and slow},
 url = {https://proceedings.mlr.press/v30/Perchet13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Pontil13,
 abstract = {Trace norm regularization is a popular method of multitask learning. We give excess risk bounds with explicit dependence on the number of tasks, the number of examples per task and properties of the data distribution. The bounds are independent of the dimension of the input space, which may be innite as in the case of reproducing kernel Hilbert spaces. A byproduct of the proof are bounds on the expected norm of sums of random positive semidenite matrices with subexponential moments.},
 address = {Princeton, NJ, USA},
 author = {Pontil, Massimiliano and Maurer, Andreas},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2963917643},
 pages = {55--76},
 pdf = {http://proceedings.mlr.press/v30/Pontil13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Excess risk bounds for multitask learning with trace norm regularization},
 url = {https://proceedings.mlr.press/v30/Pontil13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Rakhlin13,
 abstract = {We present methods for online linear optimization that take advantage of benign (as opposed to worst-case) sequences. Specically if the sequence encountered by the learner is described well by a known \predictable process, the algorithms presented enjoy tighter bounds as compared to the typical worst case bounds. Additionally, the methods achieve the usual worst-case regret bounds if the sequence is not benign. Our approach can be seen as a way of adding prior knowledge about the sequence within the paradigm of online learning. The setting is shown to encompass partial and side information. Variance and path-length bounds [11, 9] can be seen as particular examples of online learning with simple predictable sequences. We further extend our methods and results to include competing with a set of possible predictable processes (models), that is \learning the predictable process itself concurrently with using it to obtain better regret guarantees. We show that such model selection is possible under various assumptions on the available feedback. Our results suggest a promising direction of further research with potential applications to stock market and time series prediction.},
 address = {Princeton, NJ, USA},
 author = {Rakhlin, Alexander and Sridharan, Karthik},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W1878322007},
 pages = {993--1019},
 pdf = {http://proceedings.mlr.press/v30/Rakhlin13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Online Learning With Predictable Sequences},
 url = {https://proceedings.mlr.press/v30/Rakhlin13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Scott13,
 abstract = {In many real-world classification problems, the labels of training examples are randomly corrupted.Most previous theoretical work on classification with label noise assumes that the two classes are separable, that the label noise is independent of the true class label, or that the noise proportions for each class are known.In this work, we give conditions that are necessary and sufficient for the true class-conditional distributions to be identifiable.These conditions are weaker than those analyzed previously, and allow for the classes to be nonseparable and the noise levels to be asymmetric and unknown.The conditions essentially state that a majority of the observed labels are correct and that the true class-conditional distributions are "mutually irreducible," a concept we introduce that limits the similarity of the two distributions.For any label noise problem, there is a unique pair of true class-conditional distributions satisfying the proposed conditions, and we argue that this pair corresponds in a certain sense to maximal denoising of the observed distributions. Classification with asymmetric label noise 2781Our results are facilitated by a connection to "mixture proportion estimation," which is the problem of estimating the maximal proportion of one distribution that is present in another.We establish a novel rate of convergence result for mixture proportion estimation, and apply this to obtain consistency of a discrimination rule based on surrogate loss minimization.Experimental results on benchmark data and a nuclear particle classification problem demonstrate the efficacy of our approach.},
 address = {Princeton, NJ, USA},
 author = {Scott, Clayton and Blanchard, Gilles and Handy, Gregory},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2963314381},
 pages = {489--511},
 pdf = {http://proceedings.mlr.press/v30/Scott13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Classification with asymmetric label noise: Consistency and maximal denoising},
 url = {https://proceedings.mlr.press/v30/Scott13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Seldin13,
 abstract = {Adversarial multiarmed bandits with expert advice is one of the fundamental problems in studying the exploration-exploitation trade-o. It is known that if we observe the advice of all experts on every round we can achieve O(√KTlnN) regret, where K is the number of arms, T is the number of game rounds, and N is the number of experts. It is also known that if we observe the advice of just one expert on every round, we can achieve regret of order O(√NT). Our open problem is what can be achieved by asking M experts on every round, where 1 < M < N.},
 address = {Princeton, NJ, USA},
 author = {Seldin, Yevgeny and Crammer, Koby and Bartlett, Peter},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W1510389552},
 pages = {1067--1072},
 pdf = {http://proceedings.mlr.press/v30/Seldin13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Open Problem: Adversarial Multiarmed Bandits with Limited Advice},
 url = {https://proceedings.mlr.press/v30/Seldin13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Shalev13,
 abstract = {Fractional calculus has gained considerable popularity and importance during the past three decades mainly because of its demonstrated applications in numerous seemingly diverse and widespread fields of science and engineering. The chapter presents results, including the existence and uniqueness of solutions for the Cauchy Type and Cauchy problems involving nonlinear ordinary fractional differential equations, explicit solutions of linear differential equations and of the corresponding initial-value problems by their reduction to Volterra integral equations and by using operational and compositional methods; applications of the one-and multidimensional Laplace, Mellin, and Fourier integral transforms in deriving the closed-form solutions of ordinary and partial differential equations; and a theory of the so-called “sequential linear fractional differential equations,” including a generalization of the classical Frobenius method.},
 address = {Princeton, NJ, USA},
 author = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W4240465921},
 pages = {1--2},
 pdf = {http://proceedings.mlr.press/v30/Shalev13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Preface},
 url = {https://proceedings.mlr.press/v30/Shalev13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Shamir13,
 abstract = {The problem of stochastic convex optimization with bandit feedback (in the learning community) or without knowledge of gradients (in the optimization community) has received much attention in recent years, in the form of algorithms and performance upper bounds. However, much less is known about the inherent complexity of these problems, and there are few lower bounds in the literature, especially for nonlinear functions. In this paper, we investigate the attainable error/regret in the bandit and derivative-free settings, as a function of the dimension d and the available number of queries T . We provide a precise characterization of the attainable performance for strongly-convex and smooth functions, which also imply a non-trivial lower bound for more general problems. Moreover, we prove that in both the bandit and derivative-free setting, the required number of queries must scale at least quadratically with the dimension. Finally, we show that on the natural class of quadratic functions, it is possible to obtain a \fastO(1=T ) error rate in terms of T , under mild assumptions, even without having access to gradients. To the best of our knowledge, this is the rst such rate in a derivative-free stochastic setting, and holds despite previous},
 address = {Princeton, NJ, USA},
 author = {Shamir, Ohad},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2963062786},
 pages = {3--24},
 pdf = {http://proceedings.mlr.press/v30/Shamir13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization},
 url = {https://proceedings.mlr.press/v30/Shamir13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Telgarsky13,
 abstract = {This manuscript provides optimization guarantees, generalization bounds, and statistical consistency results for AdaBoost variants which replace the exponential loss with the logistic and similar losses (specifically, twice differentiable convex losses which are Lipschitz and tend to zero on one side). 
The heart of the analysis is to show that, in lieu of explicit regularization and constraints, the structure of the problem is fairly rigidly controlled by the source distribution itself. The first control of this type is in the separable case, where a distribution-dependent relaxed weak learning rate induces speedy convergence with high probability over any sample. Otherwise, in the nonseparable case, the convex surrogate risk itself exhibits distribution-dependent levels of curvature, and consequently the algorithm's output has small norm with high probability.},
 address = {Princeton, NJ, USA},
 author = {Telgarsky, Matus},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W1480769552},
 pages = {911--965},
 pdf = {http://proceedings.mlr.press/v30/Telgarsky13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Boosting with the Logistic Loss is Consistent},
 url = {https://proceedings.mlr.press/v30/Telgarsky13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Urner13,
 abstract = {We investigate the label complexity of active learning under some smoothness assumptions on the data-generating process. We propose a procedure, PLAL, for “activising” passive, sample-based learners. The procedure takes an unlabeled sample, queries the labels of some of its members, and outputs a full labeling of that sample. Assuming the data satisfies “Probabilistic Lipschitzness”, a notion of clusterability, we show that for several common learning paradigms, applying our procedure as a preprocessing leads to provable label complexity reductions (over any “passive” learning algorithm, under the same data assumptions). Our labeling procedure is simple and easy to implement. We complement our theoretical findings with experimental validations.},
 address = {Princeton, NJ, USA},
 author = {Urner, Ruth and Wulff, Sharon and Ben-David, Shai},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W43025842},
 pages = {376--397},
 pdf = {http://proceedings.mlr.press/v30/Urner13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {PLAL: Cluster-based active learning},
 url = {https://proceedings.mlr.press/v30/Urner13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Vandermeulen13,
 abstract = {The kernel density estimator (KDE) based on a radial positive-semiden ite kernel may be viewed as a sample mean in a reproducing kernel Hilbert space. This mean can be viewed as the solution of a least squares problem in that space. Replacing the squared loss with a robust loss yields a robust kernel density estimator (RKDE). Previous work has shown that RKDEs are weighted kernel density estimators which have desirable robustness properties. In this paper we establish asymptotic L 1 consistency of the RKDE for a class of losses and show that the RKDE converges with the same rate on bandwidth required for the traditional KDE. We also present a novel proof of the consistency of the traditional KDE.},
 address = {Princeton, NJ, USA},
 author = {Vandermeulen, Robert and Scott, Clayton},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2170823753},
 pages = {568--591},
 pdf = {http://proceedings.mlr.press/v30/Vandermeulen13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Consistency of Robust Kernel Density Estimators},
 url = {https://proceedings.mlr.press/v30/Vandermeulen13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Wang13,
 abstract = {A central problem in ranking is to design a ranking measure for evaluation of ranking functions. In this paper we study, from a theoretical perspective, the widely used Normalized Discounted Cumulative Gain (NDCG)-type ranking measures. Although there are extensive empirical studies of NDCG, little is known about its theoretical properties. We first show that, whatever the ranking function is, the standard NDCG which adopts a logarithmic discount, converges to 1 as the number of items to rank goes to infinity. On the first sight, this result is very surprising. It seems to imply that NDCG cannot differentiate good and bad ranking functions, contradicting to the empirical success of NDCG in many applications. In order to have a deeper understanding of ranking measures in general, we propose a notion referred to as consistent distinguishability. This notion captures the intuition that a ranking measure should have such a property: For every pair of substantially different ranking functions, the ranking measure can decide which one is better in a consistent manner on almost all datasets. We show that NDCG with logarithmic discount has consistent distinguishability although it converges to the same limit for all ranking functions. We next characterize the set of all feasible discount functions for NDCG according to the concept of consistent distinguishability. Specifically we show that whether NDCG has consistent distinguishability depends on how fast the discount decays, and 1/r is a critical point. We then turn to the cut-off version of NDCG, i.e., NDCG@k. We analyze the distinguishability of NDCG@k for various choices of k and the discount functions. Experimental results on real Web search datasets agree well with the theory.},
 address = {Princeton, NJ, USA},
 author = {Wang, Yining and Wang, Liwei and Li, Yuanzhi and He, Di and Liu, Tie-Yan},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2131676173},
 pages = {25--54},
 pdf = {http://proceedings.mlr.press/v30/Wang13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {A Theoretical Analysis of NDCG Type Ranking Measures},
 url = {https://proceedings.mlr.press/v30/Wang13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Woodruff13,
 abstract = {Oblivious low-distortion subspace embeddings are a crucial building block for numerical linear algebra problems. We show for any real p; 1 p <1, given a matrix M 2 R n d with n d, with constant probability we can choose a matrix with max(1;n 1 2=p )poly(d) rows and n columns so that simultaneously for all x2 R d ,kMxkp k Mxk1 poly(d)kMxkp: Importantly, M can be computed in the optimalO(nnz(M)) time, where nnz(M) is the number of non-zero entries ofM . This generalizes all previous oblivious subspace embeddings which required p 2 [1; 2] due to their use of p-stable random variables. Using our matrices , we also improve the best known distortion of oblivious subspace embeddings of ‘1 into ‘1 with ~ O(d) target dimension in O(nnz(M)) time from ~ O(d 3 ) to},
 address = {Princeton, NJ, USA},
 author = {Woodruff, David and Zhang, Qin},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W2128054898},
 pages = {546--567},
 pdf = {http://proceedings.mlr.press/v30/Woodruff13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Subspace Embeddings and $\ell_p$-Regression Using Exponential Random Variables},
 url = {https://proceedings.mlr.press/v30/Woodruff13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Zhang13,
 abstract = {We study a decomposition-based scalable approach to performing kernel ridge regression. The method is simple to describe: it randomly partitions a dataset of size N into m subsets of equal size, computes an independent kernel ridge regression estimator for each subset, then averages the local solutions into a global predictor. This partitioning leads to a substantial reduction in computation time versus the standard approach of performing kernel ridge regression on all N samples. Our main theorem establishes that despite the computational speed-up, statistical optimality is retained: if m is not too large, the partition-based estimate achieves optimal rates of convergence for the full sample size N. As concrete examples, our theory guarantees that m may grow polynomially in N for Sobolev spaces, and nearly linearly for finite-rank kernels and Gaussian kernels. We conclude with simulations complementing our theoretical results and exhibiting the computational and statistical benefits of our approach.},
 address = {Princeton, NJ, USA},
 author = {Zhang, Yuchen and Duchi, John and Wainwright, Martin},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W199271301},
 pages = {592--617},
 pdf = {http://proceedings.mlr.press/v30/Zhang13.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Divide and Conquer Kernel Ridge Regression},
 url = {https://proceedings.mlr.press/v30/Zhang13.html},
 volume = {30},
 year = {2013}
}

@inproceedings{pmlr-v30-Zhang13a,
 abstract = {Random projection has been widely used in data classification. It maps high-dimensional data into a low-dimensional subspace in order to reduce the computational cost in solving the related optimization problem. While previous studies are focused on analyzing the classification performance of using random projection, in this work, we consider the recovery problem, i.e., how to accurately recover the optimal solution to the original optimization problem in the high-dimensional space based on the solution learned from the subspace spanned by random projections. We present a simple algorithm, termed Dual Random Projection, that uses the dual solution of the low-dimensional optimization problem to recover the optimal solution to the original problem. Our theoretical analysis shows that with a high probability, the proposed algorithm is able to accurately recover the optimal solution to the original problem, provided that the data matrix is of low rank or can be well approximated by a low rank matrix.},
 address = {Princeton, NJ, USA},
 author = {Zhang, Lijun and Mahdavi, Mehrdad and Jin, Rong and Yang, Tianbao and Zhu, Shenghuo},
 booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
 editor = {Shalev-Shwartz, Shai and Steinwart, Ingo},
 month = {12--14 Jun},
 openalex = {W1501884374},
 pages = {135--157},
 pdf = {http://proceedings.mlr.press/v30/Zhang13a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Recovering the Optimal Solution by Dual Random Projection},
 url = {https://proceedings.mlr.press/v30/Zhang13a.html},
 volume = {30},
 year = {2013}
}
