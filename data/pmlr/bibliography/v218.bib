@proceedings{CDPD20232023,
 booktitle = {Proceedings of The KDD'23 Workshop on Causal Discovery, Prediction and Decision},
 editor = {Thuc Le and Jiuyong Li and Robert Ness and Sofia Triantafillou and Shohei Shimizu and Peng Cui and Kun Kuang and Jian Pei and Fei Wang and Mattia Prosperi},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Proceedings of The KDD'23 Workshop on Causal Discovery, Prediction and Decision},
 volume = {218}
}

@inproceedings{pmlr-v218-jun23a,
 abstract = {Developing models for individualized, time-varying treatment optimization from observational data with large variable spaces, e.g., electronic health records (EHR), is problematic because of inherent, complex bias that can change over time. Traditional methods such as the g-formula are robust, but must identify critical subsets of variables due to combinatorial issues. Machine learning approaches such as causal survival forests have fewer constraints and can provide fine-tuned, individualized counterfactual predictions. In this study, we aimed to optimize time-varying antibiotic treatment -identifying treatment heterogeneity and conditional treatment effects- against invasive methicillin-resistant Staphylococcus Aureus (MRSA) infections, using statewide EHR data collected in Florida, USA. While many previous studies focused on measuring the effects of the first empiric treatment (i.e., usually vancomycin), our study focuses on dynamic sequential treatment changes, comparing possible vancomycin switches with other antibiotics at clinically relevant time points, e.g., after obtaining a bacterial culture and susceptibility testing. Our study population included adult individuals admitted to the hospital with invasive MRSA. We collected demographic, clinical, medication, and laboratory information from the EHR for these patients. Then, we followed three sequential antibiotic choices (i.e., their empiric treatment, subsequent directed treatment, and final sustaining treatment), evaluating 30-day mortality as the outcome. We applied both causal survival forests and g-formula using different clinical intervention policies. We found that switching from vancomycin to another antibiotic improved survival probability, yet there was a benefit from initiating vancomycin compared to not using it at any time point. These findings show consistency with the empiric choice of vancomycin before confirmation of MRSA and shed light on how to manage switches on course. In conclusion, this application of causal machine learning on EHR demonstrates utility in modeling dynamic, heterogeneous treatment effects that cannot be evaluated precisely using randomized clinical trials.},
 author = {Jun, Inyoung and Cohen, Scott A. and Ser, Sarah E and Marini, Simone and Lucero, Robert J. and Bian, Jiang and Prosperi, Mattia},
 booktitle = {Proceedings of The KDD'23 Workshop on Causal Discovery, Prediction and Decision},
 editor = {Le, Thuc and Li, Jiuyong and Ness, Robert and Triantafillou, Sofia and Shimizu, Shohei and Cui, Peng and Kuang, Kun and Pei, Jian and Wang, Fei and Prosperi, Mattia},
 month = {07 Aug},
 openalex = {W4387765234},
 pages = {98--115},
 pdf = {https://proceedings.mlr.press/v218/jun23a/jun23a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Optimizing Dynamic Antibiotic Treatment Strategies against Invasive Methicillin-Resistant Staphylococcus Aureus Infections using Causal Survival Forests and G-Formula on Statewide Electronic Health Record Data.},
 url = {https://proceedings.mlr.press/v218/jun23a.html},
 volume = {218},
 year = {2023}
}

@inproceedings{pmlr-v218-le23a,
 abstract = {Preface to the 2023 KDD Workshop on Causal Discovery, Prediction and Decision (CDPD 2023)},
 author = {Le, Thuc and Li, Jiuyong and Ness, Robert  and Triantafillou, Sofia and Shimizu, Shohei and Cui, Peng and Kuang, Kun  and Pei, Jian  and Wang, Fei,  and Prosperi, Mattia},
 booktitle = {Proceedings of The KDD'23 Workshop on Causal Discovery, Prediction and Decision},
 editor = {Le, Thuc and Li, Jiuyong and Ness, Robert and Triantafillou, Sofia and Shimizu, Shohei and Cui, Peng and Kuang, Kun and Pei, Jian and Wang, Fei and Prosperi, Mattia},
 month = {07 Aug},
 pages = {1--2},
 pdf = {https://proceedings.mlr.press/v218/le23a/le23a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Preface: The 2023 ACM SIGKDD Workshop on Causal Discovery, Prediction and Decision },
 url = {https://proceedings.mlr.press/v218/le23a.html},
 volume = {218},
 year = {2023}
}

@inproceedings{pmlr-v218-lu23a,
 abstract = {The distribution shifts between training and test data typically undermine the performance of models. In recent years, lots of work pays attention to domain generalization (DG) where distribution shifts exist, and target data are unseen. Despite the progress in algorithm design, two foundational factors have long been ignored: 1) the optimization for regularization-based objectives, and 2) the model selection for DG since no knowledge about the target domain can be utilized. In this paper, we propose Mixup guided optimization and selection techniques for DG. For optimization, we utilize an adapted Mixup to generate an out-of-distribution dataset that can guide the preference direction and optimize with Pareto optimization. For model selection, we generate a validation dataset with a closer distance to the target distribution, and thereby it can better represent the target data. We also present some theoretical insights behind our proposals. Comprehensive experiments demonstrate that our model optimization and selection techniques can largely improve the performance of existing domain generalization algorithms and even achieve new state-of-the-art results.},
 author = {Lu, Wang  and Wang, Jindong and Wang, Yidong and Xie, Xing},
 booktitle = {Proceedings of The KDD'23 Workshop on Causal Discovery, Prediction and Decision},
 editor = {Le, Thuc and Li, Jiuyong and Ness, Robert and Triantafillou, Sofia and Shimizu, Shohei and Cui, Peng and Kuang, Kun and Pei, Jian and Wang, Fei and Prosperi, Mattia},
 month = {07 Aug},
 openalex = {W4294783356},
 pages = {75--97},
 pdf = {https://proceedings.mlr.press/v218/lu23a/lu23a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Towards Optimization and Model Selection for Domain Generalization: A Mixup-guided Solution},
 url = {https://proceedings.mlr.press/v218/lu23a.html},
 volume = {218},
 year = {2023}
}

@inproceedings{pmlr-v218-masoero23a,
 abstract = {Companies offering web services routinely run randomized online experiments to estimate the causal impact associated with the adoption of new features and policies on key performance metrics of interest. These experiments are used to estimate a variety of effects: the increase in click rate due to the repositioning of a banner, the impact on subscription rate as a consequence of a discount or special offer, etc. In these settings, even effects whose sizes are very small can have large downstream impacts. The simple difference in means estimator (Splawa-Neyman et al., 1990) is still the standard estimator of choice for many online A/B testing platforms due to its simplicity. This method, however, can fail to detect small effects, even when the experiment contains thousands or millions of observational units. As a by-product of these experiments, however, large amounts of additional data (covariates) are collected. In this paper, we discuss benefits, costs and risks of allowing experimenters to leverage more complicated estimators that make use of covariates when estimating causal effects of interest. We adapt a recently proposed general-purpose algorithm for the estimation of causal effects with covariates to the setting of online A/B tests. Through this paradigm, we implement several covariate-adjusted causal estimators. We thoroughly evaluate their performance at scale, highlighting benefits and shortcomings of different methods. We show on real experiments how "covariate-adjusted" estimators can (i) lead to more precise quantification of the causal effects of interest and (ii) fix issues related to imbalance across treatment arms - a practical concern often overlooked in the literature. In turn, (iii) these more precise estimates can reduce experimentation time, cutting cost and helping to streamline decision-making processes, allowing for faster adoption of beneficial interventions.},
 author = {Masoero, Lorenzo  and Hains, Doug  and McQueen, James},
 booktitle = {Proceedings of The KDD'23 Workshop on Causal Discovery, Prediction and Decision},
 editor = {Le, Thuc and Li, Jiuyong and Ness, Robert and Triantafillou, Sofia and Shimizu, Shohei and Cui, Peng and Kuang, Kun and Pei, Jian and Wang, Fei and Prosperi, Mattia},
 month = {07 Aug},
 openalex = {W4376864586},
 pages = {25--48},
 pdf = {https://proceedings.mlr.press/v218/masoero23a/masoero23a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Leveraging covariate adjustments at scale in online A/B testing},
 url = {https://proceedings.mlr.press/v218/masoero23a.html},
 volume = {218},
 year = {2023}
}

@inproceedings{pmlr-v218-schacht23a,
 abstract = {In manufacturing, rework refers to an optional step of a production process which aims to eliminate errors or remedy products that do not meet the desired quality standards. Reworking a production lot involves repeating a previous production stage with adjustments to ensure that the final product meets the required specifications. While offering the chance to improve the yield and thus increase the revenue of a production lot, a rework step also incurs additional costs. Additionally, the rework of parts that already meet the target specifications may damage them and decrease the yield. In this paper, we apply double/debiased machine learning (DML) to estimate the conditional treatment effect of a rework step during the color conversion process in opto-electronic semiconductor manufacturing on the final product yield. We utilize the implementation DoubleML to develop policies for the rework of components and estimate their value empirically. From our causal machine learning analysis we derive implications for the coating of monochromatic LEDs with conversion layers.},
 author = {Schacht, Oliver and Klaassen, Sven and Schwarz, Philipp and Spindler, Martin and Grunbaum, Daniel and Imhof, Sebastian},
 booktitle = {Proceedings of The KDD'23 Workshop on Causal Discovery, Prediction and Decision},
 editor = {Le, Thuc and Li, Jiuyong and Ness, Robert and Triantafillou, Sofia and Shimizu, Shohei and Cui, Peng and Kuang, Kun and Pei, Jian and Wang, Fei and Prosperi, Mattia},
 month = {07 Aug},
 openalex = {W4379933569},
 pages = {3--24},
 pdf = {https://proceedings.mlr.press/v218/schacht23a/schacht23a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Causally Learning an Optimal Rework Policy},
 url = {https://proceedings.mlr.press/v218/schacht23a.html},
 volume = {218},
 year = {2023}
}

@inproceedings{pmlr-v218-xiong23a,
 abstract = {We study the analysis and design of simultaneous temporal experiments, where a set of interventions are applied concurrently in continuous time, and outcomes are measured on a sequence of events observed in time. As a motivating setting, suppose multiple data science teams are conducting experiments simultaneously and independently on a ride- hailing platform to test changes to marketplace algorithms such as pricing and matching, and estimating effects from observed event outcomes such as the rate at which ride requests are completed. The design problem involves partitioning a continuous space of time into intervals and assigning treatments at the interval level. Design and analysis must account for three factors: carryover effects from interventions at earlier times, correlation in event outcomes, and effects of interventions tested simultaneously. We provide simulations to build intuition and guidance for practitioners.},
 author = {Xiong, Ruoxuan and Chin, Alex and Taylor, Sean},
 booktitle = {Proceedings of The KDD'23 Workshop on Causal Discovery, Prediction and Decision},
 editor = {Le, Thuc and Li, Jiuyong and Ness, Robert and Triantafillou, Sofia and Shimizu, Shohei and Cui, Peng and Kuang, Kun and Pei, Jian and Wang, Fei and Prosperi, Mattia},
 month = {07 Aug},
 pages = {115--131},
 pdf = {https://proceedings.mlr.press/v218/xiong23a/xiong23a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Bias-Variance Tradeoffs for Designing Simultaneous Temporal Experiments},
 url = {https://proceedings.mlr.press/v218/xiong23a.html},
 volume = {218},
 year = {2023}
}

@inproceedings{pmlr-v218-zhang23a,
 abstract = {Graph is a flexible and effective tool to represent complex structures in practice and graph neural networks (GNNs) have been shown to be effective on various graph tasks with randomly separated training and testing data. In real applications, however, the distribution of training graph might be different from that of the test one (e.g., users' interactions on the user-item training graph and their actual preference on items, i.e., testing environment, are known to have inconsistencies in recommender systems). Moreover, the distribution of test data is always agnostic when GNNs are trained. Hence, we are facing the agnostic distribution shift between training and testing on graph learning, which would lead to unstable inference of traditional GNNs across different test environments. To address this problem, we propose a novel stable prediction framework for GNNs, which permits both locally and globally stable learning and prediction on graphs. In particular, since each node is partially represented by its neighbors in GNNs, we propose to capture the stable properties for each node (locally stable) by re-weighting the information propagation/aggregation processes. For global stability, we propose a stable regularizer that reduces the training losses on heterogeneous environments and thus warping the GNNs to generalize well. We conduct extensive experiments on several graph benchmarks and a noisy industrial recommendation dataset that is collected from 5 consecutive days during a product promotion festival. The results demonstrate that our method outperforms various SOTA GNNs for stable prediction on graphs with agnostic distribution shift, including shift caused by node labels and attributes.},
 author = {Zhang, Shengyu  and Tong, Yunze  and Kuang, Kun  and Feng, Fuli and Qiu, Jiezhong and Yu, Jin  and Zhao, Zhou and Yang, Hongxia  and Zhang, Zhongfei and Wu, Fei},
 booktitle = {Proceedings of The KDD'23 Workshop on Causal Discovery, Prediction and Decision},
 editor = {Le, Thuc and Li, Jiuyong and Ness, Robert and Triantafillou, Sofia and Shimizu, Shohei and Cui, Peng and Kuang, Kun and Pei, Jian and Wang, Fei and Prosperi, Mattia},
 month = {07 Aug},
 openalex = {W3205190744},
 pages = {49--74},
 pdf = {https://proceedings.mlr.press/v218/zhang23a/zhang23a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Stable Prediction on Graphs with Agnostic Distribution Shift},
 url = {https://proceedings.mlr.press/v218/zhang23a.html},
 volume = {218},
 year = {2023}
}
