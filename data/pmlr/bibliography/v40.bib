@proceedings{COLT2015,
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {Peter GrÃ¼nwald and Elad Hazan and Satyen Kale},
 openalex = {W2951788462},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Proceedings of the 28th International Conference on Algorithmic Learning Theory},
 volume = {40}
}

@inproceedings{pmlr-v40-Agarwal15,
 abstract = {Surrogate risk minimization is a popular framework for supervised learning; property elicitation is a widely studied area in probability forecasting, machine learning, statistics and economics. In this paper, we connect these two themes by showing that calibrated surrogate losses in supervised learning can essentially be viewed as eliciting or estimating certain properties of the underlying conditional label distribution that are sufficient to construct an optimal classifier under the target loss of interest. Our study helps to shed light on the design of convex calibrated surrogates. We also give a new framework for designing convex calibrated surrogates under low-noise conditions by eliciting properties that allow one to construct ‘coarse’ estimates of the underlying distribution.},
 address = {Paris, France},
 author = {Agarwal, Arpit and Agarwal, Shivani},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1598305097},
 pages = {4--22},
 pdf = {http://proceedings.mlr.press/v40/Agarwal15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {On Consistent Surrogate Risk Minimization and Property Elicitation},
 url = {https://proceedings.mlr.press/v40/Agarwal15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Alon15,
 abstract = {We study a general class of online learning problems where the feedback is specified by a graph. This class includes online prediction with expert advice and the multi-armed bandit problem, but also several learning problems where the online player does not necessarily observe his own loss. We analyze how the structure of the feedback graph controls the inherent difficulty of the induced $T$-round learning problem. Specifically, we show that any feedback graph belongs to one of three classes: strongly observable graphs, weakly observable graphs, and unobservable graphs. We prove that the first class induces learning problems with $\widetildeΘ(α^{1/2} T^{1/2})$ minimax regret, where $α$ is the independence number of the underlying graph; the second class induces problems with $\widetildeΘ(δ^{1/3}T^{2/3})$ minimax regret, where $δ$ is the domination number of a certain portion of the graph; and the third class induces problems with linear minimax regret. Our results subsume much of the previous work on learning with feedback graphs and reveal new connections to partial monitoring games. We also show how the regret is affected if the graphs are allowed to vary with time.},
 address = {Paris, France},
 author = {Alon, Noga and Cesa-Bianchi, NicolÃ² and Dekel, Ofer and Koren, Tomer},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963200117},
 pages = {23--35},
 pdf = {http://proceedings.mlr.press/v40/Alon15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Online Learning with Feedback Graphs: Beyond Bandits},
 url = {https://proceedings.mlr.press/v40/Alon15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Anandkumar15,
 abstract = {We provide guarantees for learning latent variable models emphasizing on the overcomplete regime, where the dimensionality of the latent space exceeds the observed dimensionality. In particular, we consider multiview mixtures, ICA, and sparse coding models. Our main tool is a new algorithm for tensor decomposition that works in the overcomplete regime. In the semi-supervised setting, we exploit label information to get a rough estimate of the model parameters, and then refine it using the tensor method on unlabeled samples. We establish learning guarantees when the number of components scales as k = o(d), where d is the observed dimension, and p is the order of the observed moment employed in the tensor method (usually p = 3, 4). In the unsupervised setting, a simple initialization algorithm based on SVD of the tensor slices is proposed, and the guarantees are provided under the stricter condition that k ≤ βd (where constant β can be larger than 1). For the learning applications, we provide tight sample complexity bounds through novel covering arguments.},
 address = {Paris, France},
 author = {Anandkumar, Animashree and Ge, Rong and Janzamin, Majid},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1856913691},
 pages = {36--112},
 pdf = {http://proceedings.mlr.press/v40/Anandkumar15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning Overcomplete Latent Variable Models through Tensor Methods},
 url = {https://proceedings.mlr.press/v40/Anandkumar15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Arora15,
 abstract = {Sparse coding is a basic task in many fields including signal processing, neuroscience and machine learning where the goal is to learn a basis that enables a sparse representation of a given set of data, if one exists. Its standard formulation is as a non-convex optimization problem which is solved in practice by heuristics based on alternating minimization. Re- cent work has resulted in several algorithms for sparse coding with provable guarantees, but somewhat surprisingly these are outperformed by the simple alternating minimization heuristics. Here we give a general framework for understanding alternating minimization which we leverage to analyze existing heuristics and to design new ones also with provable guarantees. Some of these algorithms seem implementable on simple neural architectures, which was the original motivation of Olshausen and Field (1997a) in introducing sparse coding. We also give the first efficient algorithm for sparse coding that works almost up to the information theoretic limit for sparse recovery on incoherent dictionaries. All previous algorithms that approached or surpassed this limit run in time exponential in some natural parameter. Finally, our algorithms improve upon the sample complexity of existing approaches. We believe that our analysis framework will have applications in other settings where simple iterative algorithms are used.},
 address = {Paris, France},
 author = {Arora, Sanjeev and Ge, Rong and Ma, Tengyu and Moitra, Ankur},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2105459687},
 pages = {113--149},
 pdf = {http://proceedings.mlr.press/v40/Arora15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Simple, Efficient, and Neural Algorithms for Sparse Coding},
 url = {https://proceedings.mlr.press/v40/Arora15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Awasthi15a,
 abstract = {We resolve an open question from Christiano (2014b) posed in COLT’14 regarding the optimal dependency of the regret achievable for online local learning on the size of the label set. In this framework, the algorithm is shown a pair of items at each step, chosen from a set of n items. The learner then predicts a label for each item, from a label set of size L and receives a real valued payoff. This is a natural framework which captures many interesting scenarios such as online gambling and online max cut. Christiano (2014a) designed an efficient online learning algorithm for this problem achieving a regret of O( p nL 3 T ), where T is the number of rounds. Information theoretically, one can achieve a regret of O( p n logLT ). One of the main open questions left in this framework concerns closing the above gap. In this work, we provide a complete answer to the question above via two main results. We show, via a tighter analysis, that the semi-definite programming based algorithm of Christiano (2014a) in fact achieves a regret ofO( p nLT ). Second, we show a matching computational lower bound. Namely, we show that a polynomial time algorithm for online local learning with lower regret would imply a polynomial time algorithm for the planted clique problem which is widely believed to be hard. We prove a similar hardness result under a related conjecture concerning planted dense subgraphs that we put forth. Unlike planted clique, the planted dense subgraph problem does not have any known quasi-polynomial time algorithms. Computational lower bounds for online learning are relatively rare, and we hope that the ideas developed in this work will lead to lower bounds for other online learning scenarios as well.},
 address = {Paris, France},
 author = {Awasthi, Pranjal and Charikar, Moses and Lai, Kevin A and Risteski, Andrej},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963358104},
 pages = {150--166},
 pdf = {http://proceedings.mlr.press/v40/Awasthi15a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Label optimal regret bounds for online local learning},
 url = {https://proceedings.mlr.press/v40/Awasthi15a.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Awasthi15b,
 abstract = {We study the learnability of linear separators in < in the presence of bounded (a.k.a Massart) noise. This is a realistic generalization of the random classification noise model, where the adversary can flip each example x with probability η(x) ≤ η. We provide the first polynomial time algorithm that can learn linear separators to arbitrarily small excess error in this noise model under the uniform distribution over the unit sphere in <, for some constant value of η. While widely studied in the statistical learning theory community in the context of getting faster convergence rates, computationally efficient algorithms in this model had remained elusive. Our work provides the first evidence that one can indeed design algorithms achieving arbitrarily small excess error in polynomial time under this realistic noise model and thus opens up a new and exciting line of research. We additionally provide lower bounds showing that popular algorithms such as hinge loss minimization and averaging cannot lead to arbitrarily small excess error under Massart noise, even under the uniform distribution. Our work, instead, makes use of a margin based technique developed in the context of active learning. As a result, our algorithm is also an active learning algorithm with label complexity that is only logarithmic in the desired excess error .},
 address = {Paris, France},
 author = {Awasthi, Pranjal and Balcan, Maria-Florina and Haghtalab, Nika and Urner, Ruth},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2962703558},
 pages = {167--190},
 pdf = {http://proceedings.mlr.press/v40/Awasthi15b.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Efficient Learning of Linear Separators under Bounded Noise},
 url = {https://proceedings.mlr.press/v40/Awasthi15b.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Balcan15,
 abstract = {It has been a long-standing goal in machine learning, as well as in AI more generally, to develop life-long learning systems that learn many different tasks over time, and reuse insights from tasks learned, “learning to learn” as they do so. In this work we pose and provide efficient algorithms for several natural theoretical formulations of this goal. Specifically, we consider the problem of learning many different target functions over time, that share certain commonalities that are initially unknown to the learning algorithm. Our aim is to learn new internal representations as the algorithm learns new target functions, that capture this commonality and allow subsequent learning tasks to be solved more efficiently and from less data. We develop efficient algorithms for two very different kinds of commonalities that target functions might share: one based on learning common lowdimensional and unions of low-dimensional subspaces and one based on learning nonlinear Boolean combinations of features. Our algorithms for learning Boolean feature combinations additionally have a dual interpretation, and can be viewed as giving an efficient procedure for constructing near-optimal sparse Boolean autoencoders under a natural “anchor-set” assumption.},
 address = {Paris, France},
 author = {Balcan, Maria-Florina and Blum, Avrim and Vempala, Santosh},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1587813652},
 pages = {191--210},
 pdf = {http://proceedings.mlr.press/v40/Balcan15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Efficient Representations for Lifelong Learning and Autoencoding},
 url = {https://proceedings.mlr.press/v40/Balcan15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Balsubramani15,
 abstract = {We develop a worst-case analysis of aggregation of classifier ensembles for binary classification. The task of predicting to minimize error is formulated as a game played over a given set of unlabeled data (a transductive setting), where prior label information is encoded as constraints on the game. The minimax solution of this game identifies cases where a weighted combination of the classifiers can perform significantly better than any single classifier.},
 address = {Paris, France},
 author = {Balsubramani, Akshay and Freund, Yoav},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963711681},
 pages = {211--225},
 pdf = {http://proceedings.mlr.press/v40/Balsubramani15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Optimally Combining Classifiers Using Unlabeled Data},
 url = {https://proceedings.mlr.press/v40/Balsubramani15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Banerjee15,
 abstract = {The restricted eigenvalue (RE) condition characterizes the sample complexity of accurate recovery in the context of high-dimensional estimators such as Lasso and Dantzig selector (Bickel et al., 2009). Recent work has shown that random design matrices drawn from any thin-tailed (subGaussian) distributions satisfy the RE condition with high probability, when the number of samples scale as the square of the Gaussian width of the restricted set (Banerjee et al., 2014; Tropp, 2015). We pose the equivalent question for heavy-tailed distributions: Given a random design matrix drawn from a heavy-tailed distribution satisfying the small-ball property (Mendelson, 2015), does the design matrix satisfy the RE condition with the same order of sample complexity as subGaussian distributions? An answer to the question will guide the design of high-dimensional estimators for heavy tailed problems.},
 address = {Paris, France},
 author = {Banerjee, Arindam and Chen, Sheng and Sivakumar, Vidyashankar},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1577259240},
 pages = {1752--1755},
 pdf = {http://proceedings.mlr.press/v40/Banerjee15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Open Problem: Restricted Eigenvalue Condition for Heavy Tailed Designs},
 url = {https://proceedings.mlr.press/v40/Banerjee15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Bartlett15,
 abstract = {We consider a linear regression game in which the covariates are known in advance: at each round, the learner predicts a real-value, the adversary reveals a label, and the learner incurs a squared error loss. The aim is to minimize the regret with respect to linear predictions. For a variety of constraints on the adversary’s labels, we show that the minimax optimal strategy is linear, with a parameter choice that is reminiscent of ordinary least squares (and as easy to compute). The predictions depend on all covariates, past and future, with a particular weighting assigned to future covariates corresponding to the role that they play in the minimax regret. We study two families of label sequences: box constraints (under a covariate compatibility condition), and a weighted 2norm constraint that emerges naturally from the analysis. The strategy is adaptive in the sense that it requires no knowledge of the constraint set. We obtain an explicit expression for the minimax regret for these games. For the case of uniform box constraints, we show that, with worst case covariate sequences, the regret isO(dlogT), with no dependence on the scaling of the covariates.},
 address = {Paris, France},
 author = {Bartlett, Peter L. and Koolen, Wouter M. and Malek, Alan and Takimoto, Eiji and Warmuth, Manfred K.},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1532442784},
 pages = {226--239},
 pdf = {http://proceedings.mlr.press/v40/Bartlett15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Minimax fixed-design linear regression},
 url = {https://proceedings.mlr.press/v40/Bartlett15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Belloni15,
 abstract = {We consider the problem of optimizing an approximately convex function over a bounded convex set in R n using only function evaluations. The problem is reduced to sampling from an approximately log-concave distribution using the Hit-and-Run method, with query complexity of O ⁄ (n 4.5 ). In the context of zeroth order stochastic convex optimization, the proposed method produces an †minimizer after O ⁄ (n 7.5 † i2 ) noisy function evaluations by inducing a O (†/n)-approximately log concave distribution. We also consider the case when the “amount of non-convexity” decays towards the optimum of the function. Other applications of the random walk method include private computation of empirical risk minimizers, two-stage stochastic programming, and approximate dynamic programming for online learning.},
 address = {Paris, France},
 author = {Belloni, Alexandre and Liang, Tengyuan and Narayanan, Hariharan and Rakhlin, Alexander},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963870478},
 pages = {240--265},
 pdf = {http://proceedings.mlr.press/v40/Belloni15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Escaping the Local Minima via Simulated Annealing: Optimization of Approximately Convex Functions},
 url = {https://proceedings.mlr.press/v40/Belloni15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Bubeck15a,
 abstract = {We analyze the minimax regret of the adversarial bandit convex optimization problem. Focusing on the one-dimensional case, we prove that the minimax regret is e ( p T ) and partially resolve a decade-old open problem. Our analysis is non-constructive, as we do not present a concrete algorithm that attains this regret rate. Instead, we use minimax duality to reduce the problem to a Bayesian setting, where the convex loss functions are drawn from a worst-case distribution, and then we solve the Bayesian version of the problem with a variant of Thompson Sampling. Our analysis features a novel use of convexity, formalized as a “local-to-global” property of convex functions, that may be of independent interest.},
 address = {Paris, France},
 author = {Bubeck, SÃ©bastien and Dekel, Ofer and Koren, Tomer and Peres, Yuval},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963350293},
 pages = {266--278},
 pdf = {http://proceedings.mlr.press/v40/Bubeck15a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Bandit Convex Optimization: sqrt{T} Regret in One Dimension},
 url = {https://proceedings.mlr.press/v40/Bubeck15a.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Bubeck15b,
 abstract = {We prove that the Cramér transform of the uniform measure on a convex body in $\mathbb{R}^n$ is a $(1+o(1)) n$-self-concordant barrier, improving a seminal result of Nesterov and Nemirovski. This gives the first explicit construction of a universal barrier for convex bodies with optimal self-concordance parameter. The proof is based on basic geometry of log-concave distributions, and elementary duality in exponential families.},
 address = {Paris, France},
 author = {Bubeck, SÃ©bastien and Eldan, Ronen},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1837018238},
 pages = {279--279},
 pdf = {http://proceedings.mlr.press/v40/Bubeck15b.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {The entropic barrier: a simple and optimal universal self-concordant barrier},
 url = {https://proceedings.mlr.press/v40/Bubeck15b.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Cai15,
 abstract = {We propose an optimum mechanism for providing monetary incentives to the data sources of a statistical estimator such as linear regression, so that high q uality data is provided at low cost, in the sense that the weighted sum of payments and estimation error is minimized. The mechanism applies to a broad range of estimators, including linear and polynomial regression, kernel regression, and, under some additional assumptions, ridge regression. It also generaliz es to several objectives, including minimizing estimation error subject to budget constraints. Besides ou r concrete results for regression problems, we contribute a mechanism design framework through which to design and analyze statistical estimators whose examples are supplied by workers with cost for labeling said examples.},
 address = {Paris, France},
 author = {Cai, Yang and Daskalakis, Constantinos and Papadimitriou, Christos},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963246254},
 pages = {280--296},
 pdf = {http://proceedings.mlr.press/v40/Cai15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Optimum Statistical Estimation with Strategic Data Sources},
 url = {https://proceedings.mlr.press/v40/Cai15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Cesa-Bianchi15,
 abstract = {We investigate data based procedures for selecting the kernel when learning with Support Vector Machines. We provide generalization error bounds by estimating the Rademacher complexities of the corresponding function classes. In particular we obtain a complexity bound for function classes induced by kernels with given eigenvectors, i.e., we allow to vary the spectrum and keep the eigenvectors fix. This bound is only a logarithmic factor bigger than the complexity of the function class induced by a single kernel. However, optimizing the margin over such classes leads to overfitting. We thus propose a suitable way of constraining the class. We use an efficient algorithm to solve the resulting optimization problem, present preliminary experimental results, and compare them to an alignment-based approach.},
 address = {Paris, France},
 author = {Cesa-Bianchi, NicolÃ² and Mansour, Yishay and Shamir, Ohad},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2123068691},
 pages = {297--325},
 pdf = {http://proceedings.mlr.press/v40/Cesa-Bianchi15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {On the Complexity of Learning the Kernel Matrix},
 url = {https://proceedings.mlr.press/v40/Cesa-Bianchi15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Chen15a,
 abstract = {The problem of learning the solution space of an unknown formula has been studied in multiple embodiments in computational learning theory. In this article, we study a family of such learning problems; this family contains, for each relational structure, the problem of learning the solution space of an unknown conjunctive query evaluated on the structure. A progression of results aimed to classify the learnability of each of the problems in this family, and thus far a culmination thereof was a positive learnability result generalizing all previous ones. This article completes the classification program towards which this progression of results strived, by presenting a negative learnability result that complements the mentioned positive learnability result. In order to obtain our negative result, we make use of universal-algebraic concepts, and our result is phrased in terms of the varietal property of non-congruence modularity.},
 address = {Paris, France},
 author = {Chen, Hubie and Valeriote, Matthew},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1956860503},
 pages = {326--337},
 pdf = {http://proceedings.mlr.press/v40/Chen15a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learnability of Solutions to Conjunctive Queries: The Full Dichotomy},
 url = {https://proceedings.mlr.press/v40/Chen15a.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Chen15b,
 abstract = {Optimal information gathering is a central challenge in machine learning and science in general. A common objective that quantifies the usefulness of observations is Shannon’s mutual information, defined w.r.t. a probabilistic model. Greedily selecting observations that maximize the mutual information is the method of choice in numerous applications, ranging from Bayesian experimental design to automated diagnosis, to active learning in Bayesian models. Despite its importance and widespread use in applications, little is known about the theoretical properties of sequential information maximization, in particular under noisy observations. In this paper, we analyze the widely used greedy policy for this task, and identify problem instances where it provides provably near-maximal utility, even in the challenging setting of persistent noise. Our results depend on a natural separability condition associated with a channel injecting noise into the observations. We also identify examples where this separability parameter is necessary in the bound: if it is too small, then the greedy policy fails to select informative tests.},
 address = {Paris, France},
 author = {Chen, Yuxin and Hassani, S. Hamed and Karbasi, Amin and Krause, Andreas},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1559938618},
 pages = {338--363},
 pdf = {http://proceedings.mlr.press/v40/Chen15b.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Sequential Information Maximization: When is Greedy Near-optimal?},
 url = {https://proceedings.mlr.press/v40/Chen15b.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Cheng15,
 abstract = {Motivated by a sampling problem basic to computational statistical inference, we develop a toolset based on spectral sparsification for a family of fundamental problems involving Gaussian sampling, matrix functionals, and reversible Markov chains. Drawing on the connection between Gaussian graphical models and the recent breakthroughs in spectral graph theory, we give the first nearly linear time algorithm for the following basic matrix problem: Given an n× n Laplacian matrix M and a constant −1 ≤ p ≤ 1, provide efficient access to a sparse n× n linear operator C such that M ≈ CC>, where ≈ denotes spectral similarity. When p is set to −1, this gives the first parallel sampling algorithm that is essentially optimal both in total work and randomness for Gaussian random fields with symmetric diagonally dominant (SDD) precision matrices. It only requires nearly linear work and 2n i.i.d. random univariate Gaussian samples to generate an n-dimensional i.i.d. Gaussian random sample in polylogarithmic depth. The key ingredient of our approach is an integration of spectral sparsification with multilevel method: Our algorithms are based on factoring M into a product of well-conditioned matrices, then introducing powers and replacing dense matrices with sparse approximations. We give two sparsification methods for this approach that may be of independent interest. The first invokes Maclaurin series on the factors, while the second builds on our new nearly linear time spectral sparsification algorithm for random-walk matrix polynomials. We expect these algorithmic advances will also help to strengthen the connection between machine learning and spectral graph theory, two of the most active fields in understanding large data and networks.},
 address = {Paris, France},
 author = {Cheng, Dehua and Cheng, Yu and Liu, Yan and Peng, Richard and Teng, Shang-Hua},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W755406177},
 pages = {364--390},
 pdf = {http://proceedings.mlr.press/v40/Cheng15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Efficient Sampling for Gaussian Graphical Models via Spectral Sparsification},
 url = {https://proceedings.mlr.press/v40/Cheng15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Chin15,
 abstract = {In this paper, we present and analyze a simple and robust spectral algorithm for the stochastic block model with $k$ blocks, for any $k$ fixed. Our algorithm works with graphs having constant edge density, under an optimal condition on the gap between the density inside a block and the density between the blocks. As a co-product, we settle an open question posed by Abbe et. al. concerning censor block models.},
 address = {Paris, France},
 author = {Chin, Peter and Rao, Anup and Vu, Van},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2964211741},
 pages = {391--423},
 pdf = {http://proceedings.mlr.press/v40/Chin15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Stochastic Block Model and Community Detection in the Sparse Graphs: A spectral algorithm with optimal rate of recovery},
 url = {https://proceedings.mlr.press/v40/Chin15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Choromanska15,
 abstract = {Deep learning has enjoyed a resurgence of interest in the last few years for such applications as image and speech recognition, or natural language processing. The vast majority of practical applications of deep learning focus on supervised learning, where the supervised loss function is minimized using stochastic gradient descent. The properties of this highly non-convex loss function, such as its landscape and the behavior of critical points (maxima, minima, and saddle points), as well as the reason why largeand small-size networks achieve radically different practical performance, are however very poorly understood. It was only recently shown that new results in spin-glass theory potentially may provide an explanation for these problems by establishing a connection between the loss function of the neural networks and the Hamiltonian of the spherical spin-glass models. The connection between both models relies on a number of possibly unrealistic assumptions, yet the empirical evidence suggests that the connection may exist in real. The question we pose is whether it is possible to drop some of these assumptions to establish a stronger connection between both models.},
 address = {Paris, France},
 author = {Choromanska, Anna and LeCun, Yann and Ben Arous, GÃ©rard},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2601424732},
 pages = {1756--1760},
 pdf = {http://proceedings.mlr.press/v40/Choromanska15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Open Problem: The landscape of the loss surfaces of multilayer networks},
 url = {https://proceedings.mlr.press/v40/Choromanska15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Cortes15,
 abstract = {We consider two broad families of non-additive loss functions covering a large number of applications: rational losses and tropical losses. We give new algorithms extending the Followthe-Perturbed-Leader (FPL) algorithm to both of these families of loss functions and similarly give new algorithms extending the Randomized Weighted Majority (RWM) algorithm to both of these families. We prove that the time complexity of our extensions to rational losses of both FPL and RWM is polynomial and present regret bounds for both. We further show that these algorithms can play a critical role in improving performance in applications such as structured prediction.},
 address = {Paris, France},
 author = {Cortes, Corinna and Kuznetsov, Vitaly and Mohri, Mehryar and Warmuth, Manfred},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W796102254},
 pages = {424--447},
 pdf = {http://proceedings.mlr.press/v40/Cortes15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {On-line learning algorithms for path experts with non-additive losses},
 url = {https://proceedings.mlr.press/v40/Cortes15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Cummings15,
 abstract = {We consider the problem of fitting a linear model to data held by individuals who are concerned about their privacy. Incentivizing most players to truthfully report their data to the analyst constrains our design to mechanisms that provide a privacy guarantee to the participants; we use differential privacy to model individuals' privacy losses. This immediately poses a problem, as differentially private computation of a linear model necessarily produces a biased estimation, and existing approaches to design mechanisms to elicit data from privacy-sensitive individuals do not generalize well to biased estimators. We overcome this challenge through an appropriate design of the computation and payment scheme.},
 address = {Paris, France},
 author = {Cummings, Rachel and Ioannidis, Stratis and Ligett, Katrina},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2962877736},
 pages = {448--483},
 pdf = {http://proceedings.mlr.press/v40/Cummings15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Truthful Linear Regression},
 url = {https://proceedings.mlr.press/v40/Cummings15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Daniely15,
 abstract = {We present a PTAS for agnostically learning halfspaces w.r.t. the uniform distribution on the $d$ dimensional sphere. Namely, we show that for every $μ&gt;0$ there is an algorithm that runs in time $\mathrm{poly}(d,\frac{1}ε)$, and is guaranteed to return a classifier with error at most $(1+μ)\mathrm{opt}+ε$, where $\mathrm{opt}$ is the error of the best halfspace classifier. This improves on Awasthi, Balcan and Long [ABL14] who showed an algorithm with an (unspecified) constant approximation ratio. Our algorithm combines the classical technique of polynomial regression (e.g. [LMN89, KKMS05]), together with the new localization technique of [ABL14].},
 address = {Paris, France},
 author = {Daniely, Amit},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2964349279},
 pages = {484--502},
 pdf = {http://proceedings.mlr.press/v40/Daniely15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {A PTAS for Agnostically Learning Halfspaces},
 url = {https://proceedings.mlr.press/v40/Daniely15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Dasarathy15,
 abstract = {This paper investigates the problem of active learning for binary label prediction on a graph. We introduce a simple and label-efficient algorithm called S for this task. At each step, S selects the vertex to be labeled based on the structure of the graph and all previously gathered labels. Specifically, S queries for the label of the vertex that bisects the shortest shortest path between any pair of oppositely labeled vertices. We present a theoretical estimate of the number of queries S needs in terms of a novel parametrization of the complexity of binary functions on graphs. We also present experimental results demonstrating the performance of S on both real and synthetic data. While other graph-based active learning algorithms have shown promise in practice, our algorithm is the first with both good performance and theoretical guarantees. Finally, we demonstrate the implications of the S algorithm to the theory of nonparametric active learning. In particular, we show that S achieves near minimax optimal excess risk for an important class of nonparametric classification problems.},
 address = {Paris, France},
 author = {Dasarathy, Gautam and Nowak, Robert and Zhu, Xiaojin},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963984243},
 pages = {503--522},
 pdf = {http://proceedings.mlr.press/v40/Dasarathy15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {S2: An Efficient Graph Based Active Learning Algorithm with Application to Nonparametric Classification},
 url = {https://proceedings.mlr.press/v40/Dasarathy15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Deshpande15,
 abstract = {Given a large data matrix $A\in\mathbb{R}^{n\times n}$, we consider the problem of determining whether its entries are i.i.d. with some known marginal distribution $A_{ij}\sim P_0$, or instead $A$ contains a principal submatrix $A_{{\sf Q},{\sf Q}}$ whose entries have marginal distribution $A_{ij}\sim P_1\neq P_0$. As a special case, the hidden (or planted) clique problem requires to find a planted clique in an otherwise uniformly random graph. 
Assuming unbounded computational resources, this hypothesis testing problem is statistically solvable provided $|{\sf Q}|\ge C \log n$ for a suitable constant $C$. However, despite substantial effort, no polynomial time algorithm is known that succeeds with high probability when $|{\sf Q}| = o(\sqrt{n})$. Recently Meka and Wigderson \cite{meka2013association}, proposed a method to establish lower bounds within the Sum of Squares (SOS) semidefinite hierarchy. 
Here we consider the degree-$4$ SOS relaxation, and study the construction of \cite{meka2013association} to prove that SOS fails unless $k\ge C\, n^{1/3}/\log n$. An argument presented by Barak implies that this lower bound cannot be substantially improved unless the witness construction is changed in the proof. Our proof uses the moments method to bound the spectrum of a certain random association scheme, i.e. a symmetric random matrix whose rows and columns are indexed by the edges of an Erdos-Renyi random graph.},
 address = {Paris, France},
 author = {Deshpande, Yash and Montanari, Andrea},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1859301526},
 pages = {523--562},
 pdf = {http://proceedings.mlr.press/v40/Deshpande15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Improved Sum-of-Squares Lower Bounds for Hidden Clique and Hidden Submatrix Problems},
 url = {https://proceedings.mlr.press/v40/Deshpande15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Dudik15,
 abstract = {We consider the problem of learning to choose actions using contextual information when provided with limited feedback in the form of relative pairwise comparisons. We study this problem in the dueling-bandits framework of Yue et al. (2009), which we extend to incorporate context. Roughly, the learner's goal is to find the policy, or way of behaving, in some space of policies, although best is not always so clearly defined. Here, we propose a new and natural solution concept, rooted in game theory, called a von Neumann winner, a randomized policy that beats or ties every other policy. We show that this notion overcomes important limitations of existing solutions, particularly the Condorcet winner which has typically been used in the past, but which requires strong and often unrealistic assumptions. We then present three efficient algorithms for online learning in our setting, and for approximating a von Neumann winner from batch-like data. The first of these algorithms achieves particularly low regret, even when data is adversarial, although its time and space requirements are linear in the size of the policy space. The other two algorithms require time and space only logarithmic in the size of the policy space when provided access to an oracle for solving classification problems on the space.},
 address = {Paris, France},
 author = {DudÃ­k, Miroslav and Hofmann, Katja and Schapire, Robert E. and Slivkins, Aleksandrs and Zoghi, Masrour},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1951936954},
 pages = {563--587},
 pdf = {http://proceedings.mlr.press/v40/Dudik15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Contextual Dueling Bandits},
 url = {https://proceedings.mlr.press/v40/Dudik15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Eldridge15,
 abstract = {Hierarchical clustering is a popular method for analyzing data which associates a tree to a dataset. Hartigan consistency has been used extensively as a framework to analyze such clustering algorithms from a statistical point of view. Still, as we show in the paper, a tree which is Hartigan consistent with a given density can look very different than the correct limit tree. Specifically, Hartigan consistency permits two types of undesirable configurations which we term over-segmentation and improper nesting. Moreover, Hartigan consistency is a limit property and does not directly quantify difference between trees. In this paper we identify two limit properties, separation and minimality, which address both over-segmentation and improper nesting and together imply (but are not implied by) Hartigan consistency. We proceed to introduce a merge distortion metric between hierarchical clusterings and show that convergence in our distance implies both separation and minimality. We also prove that uniform separation and minimality imply convergence in the merge distortion metric. Furthermore, we show that our merge distortion metric is stable under perturbations of the density. Finally, we demonstrate applicability of these concepts by proving convergence results for two clustering algorithms. First, we show convergence (and hence separation and minimality) of the recent robust single linkage algorithm of Chaudhuri and Dasgupta (2010). Second, we provide convergence results on manifolds for topological split tree clustering.},
 address = {Paris, France},
 author = {Eldridge, Justin and Belkin, Mikhail and Wang, Yusu},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963918728},
 pages = {588--606},
 pdf = {http://proceedings.mlr.press/v40/Eldridge15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Beyond Hartigan Consistency: Merge Distortion Metric for Hierarchical Clustering},
 url = {https://proceedings.mlr.press/v40/Eldridge15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Falahatgar15,
 abstract = {There has been considerable recent interest in distribution-tests whose run-time and sample requirements are sublinear in the domain-size $k$. We study two of the most important tests under the conditional-sampling model where each query specifies a subset $S$ of the domain, and the response is a sample drawn from $S$ according to the underlying distribution. For identity testing, which asks whether the underlying distribution equals a specific given distribution or $ε$-differs from it, we reduce the known time and sample complexities from $\tilde{\mathcal{O}}(ε^{-4})$ to $\tilde{\mathcal{O}}(ε^{-2})$, thereby matching the information theoretic lower bound. For closeness testing, which asks whether two distributions underlying observed data sets are equal or different, we reduce existing complexity from $\tilde{\mathcal{O}}(ε^{-4} \log^5 k)$ to an even sub-logarithmic $\tilde{\mathcal{O}}(ε^{-5} \log \log k)$ thus providing a better bound to an open problem in Bertinoro Workshop on Sublinear Algorithms [Fisher, 2004].},
 address = {Paris, France},
 author = {Falahatgar, Moein and Jafarpour, Ashkan and Orlitsky, Alon and Pichapati, Venkatadheeraj and Suresh, Ananda Theertha},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963041981},
 pages = {607--636},
 pdf = {http://proceedings.mlr.press/v40/Falahatgar15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Faster Algorithms for Testing under Conditional Sampling},
 url = {https://proceedings.mlr.press/v40/Falahatgar15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Feige15,
 abstract = {We consider a model where given an uncorrupted input an adversary can corrupt it to one out of m corrupted inputs. We model the classification and inference problems as a zero-sum game between a learner, minimizing the expected error, and an adversary, maximizing the expected error. The value of this game is the optimal error rate achievable. For learning using a limited hypothesis class H over corrupted inputs, we give an efficient algorithm that given an uncorrupted sample returns a hypothesis h ∈ H whose error on adversarially corrupted inputs is near optimal. Our algorithm uses as a blackbox an oracle that solves the ERM problem for the hypothesis class H. We provide a generalization bound for our setting, showing that for a sufficiently large sample, the performance on the sample and on future unseen corrupted inputs will be similar. This gives an efficient learning algorithm for our adversarial setting, based on an ERM oracle. We also consider an inference related setting of the problem, where given a corrupted input, the learner queries the target function on various uncorrupted inputs and generates a prediction regarding the given corrupted input. There is no limitation on the prediction function the learner may generate, so implicitly the hypothesis class includes all possible hypotheses. In this setting we characterize the optimal learner policy as a minimum vertex cover in a given bipartite graph, and the optimal adversary policy as a maximum matching in the same bipartite graph. We design efficient local algorithms for approximating minimum vertex cover in bipartite graphs, which implies an efficient near optimal algorithm for the learner.},
 address = {Paris, France},
 author = {Feige, Uriel and Mansour, Yishay and Schapire, Robert},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1905905554},
 pages = {637--657},
 pdf = {http://proceedings.mlr.press/v40/Feige15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning and inference in the presence of corrupted inputs},
 url = {https://proceedings.mlr.press/v40/Feige15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Flammarion15,
 abstract = {We show that accelerated gradient descent, averaged gradient descent and the heavy-ball method for non-strongly-convex problems may be reformulated as constant parameter second-order difference equation algorithms, where stability of the system is equivalent to convergence at rate O(1/n 2), where n is the number of iterations. We provide a detailed analysis of the eigenvalues of the corresponding linear dynamical system , showing various oscillatory and non-oscillatory behaviors, together with a sharp stability result with explicit constants. We also consider the situation where noisy gradients are available, where we extend our general convergence result, which suggests an alternative algorithm (i.e., with different step sizes) that exhibits the good aspects of both averaging and acceleration.},
 address = {Paris, France},
 author = {Flammarion, Nicolas and Bach, Francis},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1946256299},
 pages = {658--695},
 pdf = {http://proceedings.mlr.press/v40/Flammarion15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {From Averaging to Acceleration, There is Only a Step-size},
 url = {https://proceedings.mlr.press/v40/Flammarion15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Foster15,
 abstract = {Variable selection for sparse linear regression is the problem of finding, given an m x p matrix B and a target vector y, a sparse vector x such that Bx approximately equals y. Assuming a standard complexity hypothesis, we show that no polynomial-time algorithm can find a k'-sparse x with ||Bx-y||^2&lt;=h(m,p), where k'=k*2^{log^{1-delta} p} and h(m,p)&lt;=p^(C_1)*m^(1-C_2), where delta&gt;0, C_1&gt;0,C_2&gt;0 are arbitrary. This is true even under the promise that there is an unknown k-sparse vector x^* satisfying Bx^*=y. We prove a similar result for a statistical version of the problem in which the data are corrupted by noise. To the authors' knowledge, these are the first hardness results for sparse regression that apply when the algorithm simultaneously has k'&gt;k and h(m,p)&gt;0.},
 address = {Paris, France},
 author = {Foster, Dean and Karloff, Howard and Thaler, Justin},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1729367118},
 pages = {696--709},
 pdf = {http://proceedings.mlr.press/v40/Foster15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Variable Selection is Hard},
 url = {https://proceedings.mlr.press/v40/Foster15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Frongillo15,
 abstract = {The elicitation of a statistic, or property of a distribution, is the task of devising proper scoring rules, equivalently proper losses, which incentivize an agent or algorithm to truthfully estimate the desired property of the underlying probability distribution or data set. Leveraging connections between elicitation and convex analysis, we address the vector-valued property case, which has received little attention in the literature despite its applications to both machine learning and statistics. We first provide a very general characterization of linear and ratio-of-linear properties, the first of which resolves an open problem by unifying and strengthening several previous characterizations in machine learning and statistics. We then ask which vectors of properties admit nonseparable scores, which cannot be expressed as a sum of scores for each coordinate separately, a natural desideratum for machine learning. We show that linear and ratio-of-linear do admit nonseparable scores, and provide evidence for a conjecture that these are the only such properties (up to link functions). Finally, we give a general method for producing identification functions and address an open problem by showing that convex maximal level sets are insufficient for elicitability in general.},
 address = {Paris, France},
 author = {Frongillo, Rafael and Kash, Ian A.},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1858239745},
 pages = {710--727},
 pdf = {http://proceedings.mlr.press/v40/Frongillo15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Vector-Valued Property Elicitation},
 url = {https://proceedings.mlr.press/v40/Frongillo15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Frostig15,
 abstract = {In many estimation problems, e.g. linear and logistic regression, we wish to minimize an unknown objective given only unbiased samples of the objective function. Furthermore, we aim to achieve this using as few samples as possible. In the absence of computational constraints, the minimizer of a sample average of observed data ‐ commonly referred to as either the empirical risk minimizer (ERM) or the M -estimator ‐ is widely regarded as the estimation strategy of choice due to its desirable statistical convergence properties. Our goal in this work is to perform as well as the ERM, on every problem, while minimizing the use of computational resources such as running time and space usage. We provide a simple streaming algorithm which, under standard regularity assumptions on the underlying problem, enjoys the following properties: 1. The algorithm can be implemented in linear time with a single pass of the observed data, using space linear in the size of a single sample. 2. The algorithm achieves the same statistical rate of convergence as the empirical risk minimizer on every problem, even considering constant factors. 3. The algorithm’s performance depends on the initial error at a rate that decreases super-polynomially. 4. The algorithm is easily parallelizable. Moreover, we quantify the (finite-sample) rate at which the algorithm becomes competitive with the ERM.},
 address = {Paris, France},
 author = {Frostig, Roy and Ge, Rong and Kakade, Sham M. and Sidford, Aaron},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963646202},
 pages = {728--763},
 pdf = {http://proceedings.mlr.press/v40/Frostig15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Competing with the Empirical Risk Minimizer in a Single Pass},
 url = {https://proceedings.mlr.press/v40/Frostig15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Gaillard15,
 abstract = {We consider the problem of online nonparametric regression with arbitrary deterministic sequences. Using ideas from the chaining technique, we design an algorithm that achieves a Dudley-type regret bound similar to the one obtained in a non-constructive fashion by Rakhlin and Sridharan (2014). Our regret bound is expressed in terms of the metric entropy in the sup norm, which yields optimal guarantees when the metric and sequential entropies are of the same order of magnitude. In particular our algorithm is the first one that achieves optimal rates for online regression over H{ö}lder balls. In addition we show for this example how to adapt our chaining algorithm to get a reasonable computational efficiency with similar regret guarantees (up to a log factor).},
 address = {Paris, France},
 author = {Gaillard, Pierre and Gerchinovitz, SÃ©bastien},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W167834439},
 pages = {764--796},
 pdf = {http://proceedings.mlr.press/v40/Gaillard15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {A Chaining Algorithm for Online Nonparametric Regression},
 url = {https://proceedings.mlr.press/v40/Gaillard15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Ge15,
 abstract = {We analyze stochastic gradient descent for optimizing non-convex functions. In many cases for non-convex functions the goal is to find a reasonable local minimum, and the main concern is that gradient updates are trapped in saddle points. In this paper we identify strict saddle property for non-convex problem that allows for efficient optimization. Using this property we show that stochastic gradient descent converges to a local minimum in a polynomial number of iterations. To the best of our knowledge this is the first work that gives global convergence guarantees for stochastic gradient descent on non-convex functions with exponentially many local minima and saddle points. Our analysis can be applied to orthogonal tensor decomposition, which is widely used in learning a rich class of latent variable models. We propose a new optimization formulation for the tensor decomposition problem that has strict saddle property. As a result we get the first online algorithm for orthogonal tensor decomposition with global convergence guarantee.},
 address = {Paris, France},
 author = {Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2964106499},
 pages = {797--842},
 pdf = {http://proceedings.mlr.press/v40/Ge15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Escaping From Saddle Points --- Online Stochastic Gradient for Tensor Decomposition},
 url = {https://proceedings.mlr.press/v40/Ge15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Goix15,
 abstract = {Assessing the probability of occurrence of extreme events is a crucial issue in various fields like finance, insurance, telecommunication or environmental sciences. In a multivariate framework, the tail dependence is characterized by the so-called stable tail dependence function (STDF). Learning this structure is the keystone of multivariate extremes. Although extensive studies have proved consistency and asymptotic normality for the empirical version of the STDF, non-asymptotic bounds are still missing. The main purpose of this paper is to fill this gap. Taking advantage of adapted VC-type concentration inequalities, upper bounds are derived with expected rate of convergence in O(k^-1/2). The concentration tools involved in this analysis rely on a more general study of maximal deviations in low probability regions, and thus directly apply to the classification of extreme data.},
 address = {Paris, France},
 author = {Goix, Nicolas and Sabourin, Anne and ClÃ©men\ccon, StÃ©phan},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2950579281},
 pages = {843--860},
 pdf = {http://proceedings.mlr.press/v40/Goix15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning the dependence structure of rare events: a non-asymptotic study},
 url = {https://proceedings.mlr.press/v40/Goix15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Gopalan15,
 abstract = {We consider reinforcement learning in parameterized Markov Decision Processes (MDPs), where the parameterization may induce correlation across transition probabilities or rewards. Consequently, observing a particular state transition might yield useful information about other, unobserved, parts of the MDP. We present a version of Thompson sampling for parameterized reinforcement learning problems, and derive a frequentist regret bound for priors over general parameter spaces. The result shows that the number of instants where suboptimal actions are chosen scales logarithmically with time, with high probability. It holds for prior distributions that put significant probability near the true model, without any additional, specific closed-form structure such as conjugate or product-form priors. The constant factor in the logarithmic scaling encodes the information complexity of learning the MDP in terms of the Kullback-Leibler geometry of the parameter space.},
 address = {Paris, France},
 author = {Gopalan, Aditya and Mannor, Shie},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963603291},
 pages = {861--898},
 pdf = {http://proceedings.mlr.press/v40/Gopalan15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Thompson Sampling for Learning Parameterized Markov Decision Processes},
 url = {https://proceedings.mlr.press/v40/Gopalan15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Grunwald15,
 abstract = {These proceedings contain the 70 papers accepted to and presented at the 28th Conference on Learning Theory (COLT), held in Paris, France on July 2-6, 2015. These papers were selected by the program committee with additional help from external expert reviewers from 180 submissions. Of the 70 papers, 19 were given a 20-minute presentation, the remaining 51 a 5-minute presentation. All authors were given the opportunity to present a poster of their paper as well. These proceedings also contain the six open problems selected from among nine submissions. Selection of the open problems was handled by the Open Problem Chair, Jacob Abernethy, based on reviews of the submissions by three additional external reviewers. In addition to the papers and open problems published in these proceedings, the conference program also included three invited talks, one by Tim Roughgarden titled “Applications of Learning Theory in Algorithmic Game Theory”, one by Daniel Spielman titled “Laplacian Matrices of Graphs: Algorithms and Applications”, and one by Cedric Villani titled “Synthetic theory of Ricci curvature when information theory, optimization, geometry and gradient flows meet”. The paper “An Almost Optimal PAC Algorithm” by Hans-Ulrich Simon received the best paper award. There were still several candidates for the best student paper award at the time of writing these proceedings; the final decision was made during the conference, also based on the quality of presentation. The local arrangements chair was Vianney Perchet and the publication chair was Satyen Kale. We would like to express our gratitude to the entire program committee and to the external reviewers for their invaluable contributions to the success of conference. Finally, we would like to thank our generous sponsors: Labex Ecodec Chaire Havas, Microsoft Research Joint Center Inria, Huawei Research Labs, Chaire Big Data, Telecom ParisTech, CMLA, ENS Cachan, Facebook, Google, GdR Jemma, Microsoft Research, CNRS Institut INS2I, LPMA Paris Diderot & UPMC, Criteo, PGMO Foundation Jacques Hadamard & EDF, Machine Learning Journal GdR MOA, Yahoo! Labs. We would also like to acknowledge the technical support of the Foundation Sciences Mathematiques de Paris, and of University Pierre and Marie Curie.},
 address = {Paris, France},
 author = {GrÃ¼nwald, Peter and Hazan, Elad},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2474235300},
 pages = {1--3},
 pdf = {http://proceedings.mlr.press/v40/Grunwald15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Conference on Learning Theory 2015: Preface},
 url = {https://proceedings.mlr.press/v40/Grunwald15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Guzman15,
 abstract = {First-order convex minimization algorithms are currently the methods of choice for large-scale sparse – and more generally parsimonious – regression models. We pose the question on the limits of performance of black-box oriented methods for convex minimization in non-standard settings, where the regularity of the objective is measured in a norm not necessarily induced by the feasible domain. This question is studied for `p/`q-settings, and their matrix analogues (Schatten norms), where we find surprising gaps on lower bounds compared to state of the art methods. We propose a conjecture on the optimal convergence rates for these settings, for which a positive answer would lead to significant improvements on minimization algorithms for parsimonious regression models. Let (E, ‖ · ‖) be a finite-dimensional normed space. Given parameters, 1 0, we consider the class F‖·‖(κ, L) of convex functions that are (κ, L)-smooth w.r.t. norm ‖ · ‖. One such function f : E→ R satisfies that ‖∇f(y)−∇f(x)‖∗ ≤ L‖x− y‖κ−1 ∀x, y ∈ E. Notice that the case κ → 1 corresponds essentially to nonsmooth (Lipschitz continuous) convex functions, and κ = 2 corresponds to smooth (with Lipschitz continuous gradients) convex functions. Given a convex body X ⊆ E, we are interested on the complexity of the problem class P = (F‖·‖(κ, L), X), comprised of optimization problems with objective f ∈ F‖·‖(κ, L) Opt(f,X) = min{f(x) : x ∈ X}. (Pf,X) We study a black-box oracle model where most algorithms based on subgradient computations can be implemented1. Here, an algorithm is allowed to perform queries x ∈ E, and for any such query the oracle returns Of (x) (e.g., for first-order methods, Of (x) = ∇f(x)). The only assumption on the oracle is locality: For any x ∈ E and f, g ∈ F such that there exists a neighborhood B(x, δ) where f ≡ g, then Of (x) = Og(x). Given T > 0, we consider an algorithm A whose output xT (A, f) is only determined by T (adaptive) oracle queries. We define the accuracy of algorithm A on an instance f as e(A, f) := f(xT (A, f)) − Opt(f,X), if xT (A, f) ∈ X , otherwise e(A, f) = ∞. We characterize optimal 1. Notable exceptions are methods exploiting explicit saddle-point description, e.g., the smoothing technique by Nesterov (2005). Note however that such algorithms do not give improvement in the smooth case.},
 address = {Paris, France},
 author = {GuzmÃ¡n, CristÃ³bal},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1854971760},
 pages = {1761--1763},
 pdf = {http://proceedings.mlr.press/v40/Guzman15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Open Problem: The Oracle Complexity of Smooth Convex Optimization in Nonstandard Settings},
 url = {https://proceedings.mlr.press/v40/Guzman15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Hajek15,
 abstract = {This paper studies the problem of detecting the presence of a small dense community planted in a large Erd\H{o}s-R\'enyi random graph $\mathcal{G}(N,q)$, where the edge probability within the community exceeds $q$ by a constant factor. Assuming the hardness of the planted clique detection problem, we show that the computational complexity of detecting the community exhibits the following phase transition phenomenon: As the graph size $N$ grows and the graph becomes sparser according to $q=N^{-\alpha}$, there exists a critical value of $\alpha = \frac{2}{3}$, below which there exists a computationally intensive procedure that can detect far smaller communities than any computationally efficient procedure, and above which a linear-time procedure is statistically optimal. The results also lead to the average-case hardness results for recovering the dense community and approximating the densest $K$-subgraph.},
 address = {Paris, France},
 author = {Hajek, Bruce and Wu, Yihong and Xu, Jiaming},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2964145111},
 pages = {899--928},
 pdf = {http://proceedings.mlr.press/v40/Hajek15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Computational Lower Bounds for Community Detection on Random Graphs},
 url = {https://proceedings.mlr.press/v40/Hajek15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Harchaoui15,
 abstract = {We present a theoretical framework for adaptive estimation and prediction of signals of unknown structure in the presence of noise. The framework allows to address two intertwined challenges: (i) designing optimal statistical estimators; (ii) designing efficient numerical algorithms. In particular, we establish oracle inequalities for the performance of adaptive procedures, which rely upon convex optimization and thus can be efficiently implemented. As an application of the proposed approach, we consider denoising of harmonic oscillations.},
 address = {Paris, France},
 author = {Harchaoui, Zaid and Juditsky, Anatoli and Nemirovski, Arkadi and Ostrovsky, Dmitry},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2227712299},
 pages = {929--955},
 pdf = {http://proceedings.mlr.press/v40/Harchaoui15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Adaptive Recovery of Signals by Convex Optimization},
 url = {https://proceedings.mlr.press/v40/Harchaoui15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Hopkins15,
 abstract = {We study a statistical model for the tensor principal component analysis problem introduced by Montanari and Richard: Given a order-3 tensor T of the form T = τ · v⊗3 0 + A, where τ > 0 is a signal-to-noise ratio, v0 is a unit vector, and A is a random noise tensor, the goal is to recover the planted vector v0. For the case that A has iid standard Gaussian entries, we give an efficient algorithm to recover v0 whenever τ > ω(n3/4 log(n)1/4), and certify that the recovered vector is close to a maximum likelihood estimator, all with high probability over the random choice of A. The previous best algorithms with provable guarantees required τ > Ω(n). In the regime τ 6 o(n), natural tensor-unfolding-based spectral relaxations for the underlying optimization problem break down. To go beyond this barrier, we use convex relaxations based on the sum-of-squares method. Our recovery algorithm proceeds by rounding a degree-4 sum-ofsquares relaxations of the maximum-likelihood-estimation problem for the statistical model. To complement our algorithmic results, we show that degree-4 sum-of-squares relaxations break down for τ 6 O(n3/4/ log(n)1/4), which demonstrates that improving our current guarantees (by more than logarithmic factors) would require new techniques or might even be intractable. Finally, we show how to exploit additional problem structure in order to solve our sum-ofsquares relaxations, up to some approximation, very efficiently. Our fastest algorithm runs in nearly-linear time using shifted (matrix) power iteration and has similar guarantees as above. The analysis of this algorithm also confirms a variant of a conjecture of Montanari and Richard about singular vectors of tensor unfoldings.},
 address = {Paris, France},
 author = {Hopkins, Samuel B. and Shi, Jonathan and Steurer, David},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963595633},
 pages = {956--1006},
 pdf = {http://proceedings.mlr.press/v40/Hopkins15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Tensor principal component analysis via sum-of-square proofs.},
 url = {https://proceedings.mlr.press/v40/Hopkins15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Jain15,
 abstract = {Matrix completion is the problem of recovering a low rank matrix by observing a small fraction of its entries. A series of recent works (Keshavan, 2012; Jain et al., 2013; Hardt, 2014) have proposed fast non-convex optimization based iterative algorithms to solve this problem. However, the sample complexity in all these results is sub-optimal in its dependence on the rank, condition number and the desired accuracy. In this paper, we present a fast iterative algorithm that solves the matrix completion problem by observing O ( nr log n ) entries, which is independent of the condition number and the desired accuracy. The run time of our algorithm is O ( nr log n log 1/ ) which is near linear in the dimension of the matrix. To the best of our knowledge, this is the first near linear time algorithm for exact matrix completion with finite sample complexity (i.e. independent of ). Our algorithm is based on a well known projected gradient descent method, where the projection is onto the (nonconvex) set of low rank matrices. There are two key ideas in our result: 1) our argument is based on a `∞ norm potential function (as opposed to the spectral norm) and provides a novel way to obtain perturbation bounds for it. 2) we prove and use a natural extension of the Davis-Kahan theorem to obtain perturbation bounds on the best low rank approximation of matrices with good eigen gap. Both of these ideas may be of independent interest.},
 address = {Paris, France},
 author = {Jain, Prateek and Netrapalli, Praneeth},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963684688},
 pages = {1007--1034},
 pdf = {http://proceedings.mlr.press/v40/Jain15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Fast Exact Matrix Completion with Finite Samples},
 url = {https://proceedings.mlr.press/v40/Jain15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Kamalaruban15,
 abstract = {The goal of online prediction with expert advice is to find a decision strategy which will perform almost as well as the best expert in a given pool of experts, on any sequence of outcomes. This problem has been widely studied and O( √ T ) and O(log T ) regret bounds can be achieved for convex losses (Zinkevich (2003)) and strictly convex losses with bounded first and second derivatives (Hazan et al. (2007)) respectively. In special cases like the Aggregating Algorithm (Vovk (1995)) with mixable losses and the Weighted Average Algorithm (Kivinen and Warmuth (1999)) with exp-concave losses, it is possible to achieve O(1) regret bounds. van Erven (2012) has argued that mixability and exp-concavity are roughly equivalent under certain conditions. Thus by understanding the underlying relationship between these two notions we can gain the best of both algorithms (strong theoretical performance guarantees of the Aggregating Algorithm and the computational efficiency of the Weighted Average Algorithm). In this paper we provide a complete characterization of the exp-concavity of any proper composite loss. Using this characterization and the mixability condition of proper losses (Van Erven et al. (2012)), we show that it is possible to transform (reparameterize) any β-mixable binary proper loss into a β-exp-concave composite loss with the same β. In the multi-class case, we propose an approximation approach for this transformation.},
 address = {Paris, France},
 author = {Kamalaruban, Parameswaran and Williamson, Robert and Zhang, Xinhua},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1847357338},
 pages = {1035--1065},
 pdf = {http://proceedings.mlr.press/v40/Kamalaruban15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Exp-Concavity of Proper Composite Losses},
 url = {https://proceedings.mlr.press/v40/Kamalaruban15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Kamath15,
 abstract = {One of the most natural and important questions in statistical learning is: how well can a distribution be approximated from its samples. Surprisingly, this question has so far been resolved for only one loss, the KL-divergence and even in this case, the estimator used is ad hoc and not well understood. We study distribution approximations for general loss measures. For ‘ 2 we determine the best approximation possible, for‘1 and 2 we derive tight bounds on the best approximation, and when the probabilities are bounded away from zero, we resolve the question for all sufficiently smooth loss measures, thereby providing a coherent understanding of the rate at which distributions can be approximated from their samples.},
 address = {Paris, France},
 author = {Kamath, Sudeep and Orlitsky, Alon and Pichapati, Dheeraj and Suresh, Ananda Theertha},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W840677367},
 pages = {1066--1100},
 pdf = {http://proceedings.mlr.press/v40/Kamath15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {On Learning Distributions from their Samples},
 url = {https://proceedings.mlr.press/v40/Kamath15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Kanade15,
 abstract = {The theory of learning under the uniform distribution is rich and deep, with connections to cryptography, computational complexity, and the analysis of boolean functions to name a few areas. This theory however is very limited due to the fact that the uniform distribution and the corresponding Fourier basis are rarely encountered as a statistical model. A family of distributions that vastly generalizes the uniform distribution on the Boolean cube is that of distributions represented by Markov Random Fields (MRF). Markov Random Fields are one of the main tools for modeling high dimensional data in many areas of statistics and machine learning. In this paper we initiate the investigation of extending central ideas, methods and algorithms from the theory of learning under the uniform distribution to the setup of learning concepts given examples from MRF distributions. In particular, our results establish a novel connection between properties of MCMC sampling of MRFs and learning under the MRF distribution. },
 address = {Paris, France},
 author = {Kanade, Varun and Mossel, Elchanan},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 pages = {1101--1128},
 pdf = {http://proceedings.mlr.press/v40/Kanade15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {MCMC Learning},
 url = {https://proceedings.mlr.press/v40/Kanade15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Karnin15,
 abstract = {This paper revisits the online PCA problem. Given a stream of n vectors xt2 R d (columns of X) the algorithm must outputyt2 R ‘ (columns ofY ) before receivingxt+1. The goal of online PCA is to simultaneously minimize the target dimension‘ the errorkX (XY + )Yk 2 . We describe two simple deterministic algorithms. The first, receives a parameter guarantees that kX (XY + )Yk 2 is not significantly larger than . It requires a target dimension of ‘ = O(k=) for any k; such that  2 1 + 2+1 , with i being the i’th singular value of X. The second receivesk and guarantees thatkX (XY + )Yk 2  2 + 2+1 . It requires a target dimension of O(k logn= 2 ). Different models algorithms for Online PCA were considered in the past.},
 address = {Paris, France},
 author = {Karnin, Zohar and Liberty, Edo},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1862255080},
 pages = {1129--1140},
 pdf = {http://proceedings.mlr.press/v40/Karnin15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Online {PCA} with Spectral Bounds},
 url = {https://proceedings.mlr.press/v40/Karnin15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Komiyama15,
 abstract = {We study the $K$-armed dueling bandit problem, a variation of the standard stochastic bandit problem where the feedback is limited to relative comparisons of a pair of arms. We introduce a tight asymptotic regret lower bound that is based on the information divergence. An algorithm that is inspired by the Deterministic Minimum Empirical Divergence algorithm (Honda and Takemura, 2010) is proposed, and its regret is analyzed. The proposed algorithm is found to be the first one with a regret upper bound that matches the lower bound. Experimental comparisons of dueling bandit algorithms show that the proposed algorithm significantly outperforms existing ones.},
 address = {Paris, France},
 author = {Komiyama, Junpei and Honda, Junya and Kashima, Hisashi and Nakagawa, Hiroshi},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963159975},
 pages = {1141--1154},
 pdf = {http://proceedings.mlr.press/v40/Komiyama15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Regret Lower Bound and Optimal Algorithm in Dueling Bandit Problem},
 url = {https://proceedings.mlr.press/v40/Komiyama15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Koolen15a,
 abstract = {We aim to design strategies for sequential decision making that adjust to the difficulty of the learning problem. We study this question both in the setting of prediction with expert advice, and for more general combinatorial decision tasks. We are not satisfied with just guaranteeing minimax regret rates, but we want our algorithms to perform significantly better on easy data. Two popular ways to formalize such adaptivity are second-order regret bounds and quantile bounds. The underlying notions of ‘easy data’, which may be paraphrased as “the learning problem has small variance” and “multiple decisions are useful”, are synergetic. But even though there are sophisticated algorithms that exploit one of the two, no existing algorithm is able to adapt to both. The difficulty in combining the two notions lies in tuning a parameter called the learning rate, whose optimal value behaves non-monotonically. We introduce a potential function for which (very surprisingly!) it is sufficient to simply put a prior on learning rates; an approach that does not work for any previous method. By choosing the right prior we construct efficient algorithms and show that they reap both benefits by proving the first bounds that are both second-order and incorporate quantiles.},
 address = {Paris, France},
 author = {Koolen, Wouter M. and Van Erven, Tim},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2775694264},
 pages = {1155--1175},
 pdf = {http://proceedings.mlr.press/v40/Koolen15a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Second-order quantile methods for experts and combinatorial games},
 url = {https://proceedings.mlr.press/v40/Koolen15a.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Koolen15b,
 abstract = {There has been much work on extending the prediction with expert advice methodology to the case when experts are composed of components and there are combinatorially many such experts. One of the core examples is the Online Shortest Path problem where the components are edges and the experts are paths. In this note we revisit this online routing problem in the case where in each trial some of the edges or components are sabotaged / blocked. In the vanilla expert setting a known method can solve this extension where experts are now awake or asleep in each trial. We ask whether this technology can be upgraded efficiently to the case when at each trial every component can be awake or asleep. It is easy get to get an initial regret bound by using combinatorially many experts. However it is open whether there are efficient algorithms achieving the same regret.},
 address = {Paris, France},
 author = {Koolen, Wouter M. and Warmuth, Manfred K. and Adamskiy, Dmitri},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W855012616},
 pages = {1764--1766},
 pdf = {http://proceedings.mlr.press/v40/Koolen15b.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Open Problem: Online Sabotaged Shortest Path},
 url = {https://proceedings.mlr.press/v40/Koolen15b.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Kpotufe15,
 abstract = {Given a joint distributionPX;Y over a spaceX and a label setY =f0; 1g, we consider the problem of recovering the labels of an unlabeled sample with as few label queries as possible. The recovered labels can be passed to a passive learner, thus turning the procedure into an active learning approach. We analyze a family of labeling procedures based on a hierarchical clustering of the data. While such labeling procedures have been studied in the past, we provide a new parametrization ofPX;Y that captures their behavior in general low-noise settings, and which accounts for data-dependent clustering, thus providing new theoretical underpinning to practically used tools.},
 address = {Paris, France},
 author = {Kpotufe, Samory and Urner, Ruth and Ben-David, Shai},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1512936184},
 pages = {1176--1189},
 pdf = {http://proceedings.mlr.press/v40/Kpotufe15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Hierarchical Label Queries with Data-Dependent Partitions},
 url = {https://proceedings.mlr.press/v40/Kpotufe15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Kun15,
 abstract = {We pose an open problem on the complexity of learning the behavior of a quantum circuit with value injection queries. We dene the learning model for quantum circuits and give preliminary results. Using the test-path lemma of Angluin et al. (2009a), we show that new ideas are likely needed to tackle value injection queries for the quantum setting.},
 address = {Paris, France},
 author = {Kun, Jeremy and Reyzin, Lev},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W801794628},
 pages = {1767--1769},
 pdf = {http://proceedings.mlr.press/v40/Kun15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Open Problem: Learning Quantum Circuits with Queries},
 url = {https://proceedings.mlr.press/v40/Kun15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Kyng15,
 abstract = {We develop fast algorithms for solving regression problems on graphs where one is given the value of a function at some vertices, and must find its smoothest possible extens ion to all vertices. The extension we compute is the absolutely minimal Lipschitz extension, and is the limit for large p of p-Laplacian regularization. We present an algorithm that computes a minimal Lipschitz extension in expected linear time, and an algorithm that computes an absolutely minimal Lipschitz extension in expected time e O(mn). The latter algorithm has variants that seem to run much faster in practice. These extensions are particularly amenable to regularization: we can perform l0regularization on the given values in polynomial time and l1-regularization on the initial function values and on graph edge weights in time e O(m 3/2 ). Our definitions and algorithms naturally extend to directed graphs.},
 address = {Paris, France},
 author = {Kyng, Rasmus and Rao, Anup and Sachdeva, Sushant and Spielman, Daniel A.},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963182236},
 pages = {1190--1223},
 pdf = {http://proceedings.mlr.press/v40/Kyng15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Algorithms for Lipschitz Learning on Graphs},
 url = {https://proceedings.mlr.press/v40/Kyng15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Lafond15,
 abstract = {The matrix completion problem consists in reconstructing a matrix from a sample of entries, possibly observed with noise. A popular class of estimator, known as nuclear norm penalized estimators, are based on minimizing the sum of a data fitting term and a nuclear norm penalization. Here, we investigate the case where the noise distribution belongs to the exponential family and is sub-exponential. Our framework alllows for a general sampling scheme. We first consider an estimator defined as the minimizer of the sum of a log-likelihood term and a nuclear norm penalization and prove an upper bound on the Frobenius prediction risk. The rate obtained improves on previous works on matrix completion for exponential family. When the sampling distribution is known, we propose another estimator and prove an oracle inequality w.r.t. the Kullback-Leibler prediction risk, which translates immediatly into an upper bound on the Frobenius prediction risk. Finally, we show that all the rates obtained are minimax optimal up to a logarithmic factor.},
 address = {Paris, France},
 author = {Lafond, Jean},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1691687054},
 pages = {1224--1243},
 pdf = {http://proceedings.mlr.press/v40/Lafond15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Low Rank Matrix Completion with Exponential Family Noise},
 url = {https://proceedings.mlr.press/v40/Lafond15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Leike15,
 abstract = {A big open question of algorithmic information theory is the choice of the universal Turing machine (UTM). For Kolmogorov complexity and Solomonoff induction we have invariance theorems: the choice of the UTM changes bounds only by a constant. For the universally intelligent agent AIXI (Hutter, 2005) no invariance theorem is known. Our results are entirely negative: we discuss cases in which unlucky or adversarial choices of the UTM cause AIXI to misbehave drastically. We show that Legg-Hutter intelligence and thus balanced Pareto optimality is entirely subjective, and that every policy is Pareto optimal in the class of all computable environments. This undermines all existing optimality properties for AIXI. While it may still serve as a gold standard for AI, our results imply that AIXI is a relative theory, dependent on the choice of the UTM.},
 address = {Paris, France},
 author = {Leike, Jan and Hutter, Marcus},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1919575688},
 pages = {1244--1259},
 pdf = {http://proceedings.mlr.press/v40/Leike15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Bad Universal Priors and Notions of Optimality},
 url = {https://proceedings.mlr.press/v40/Leike15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Liang15,
 abstract = {We consider regression with square loss and general classes of functions without the boundedness assumption. We introduce a notion of offset Rademacher complexity that provides a transparent way to study localization both in expectation and in high probability. For any (possibly non-convex) class, the excess loss of a two-step estimator is shown to be upper bounded by this offset complexity through a novel geometric inequality. In the convex case, the estimator reduces to an empirical risk minimizer. The method recovers the results of (Rakhlin et al., 2015) for the bounded case while also providing guarantees without the boundedness assumption.},
 address = {Paris, France},
 author = {Liang, Tengyuan and Rakhlin, Alexander and Sridharan, Karthik},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2964282972},
 pages = {1260--1285},
 pdf = {http://proceedings.mlr.press/v40/Liang15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning with Square Loss: Localization through Offset Rademacher Complexity},
 url = {https://proceedings.mlr.press/v40/Liang15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Luo15,
 abstract = {We study the classic online learning problem of predicting with expert advice, and propose a truly parameter-free and adaptive algorithm that achieves several objectives simultaneously without using any prior information. The main component of this work is an improved version of the NormalHedge.DT algorithm (Luo and Schapire, 2014), called AdaNormalHedge. On one hand, this new algorithm ensures small regret when the competitor has small loss and almost constant regret when the losses are stochastic. On the other hand, the algorithm is able to compete with any convex combination of the experts simultaneously, with a regret in terms of the relative entropy of the prior and the competitor. This resolves an open problem proposed by Chaudhuri et al. (2009) and Chernov and Vovk (2010). Moreover, we extend the results to the sleeping expert setting and provide two applications to illustrate the power of AdaNormalHedge: 1) competing with time-varying unknown competitors and 2) predicting almost as well as the best pruning tree. Our results on these applications significantly improve previous work from different aspects, and a special case of the first application resolves another open problem proposed by Warmuth and Koolen (2014) on whether one can simultaneously achieve optimal shifting regret for both adversarial and stochastic losses.},
 address = {Paris, France},
 author = {Luo, Haipeng and Schapire, Robert E.},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1892200897},
 pages = {1286--1304},
 pdf = {http://proceedings.mlr.press/v40/Luo15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Achieving All with No Parameters: AdaNormalHedge},
 url = {https://proceedings.mlr.press/v40/Luo15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Mahdavi15,
 abstract = {In this paper we derive high probability lower and upper bounds on the excess risk of stochastic optimization of exponentially concave loss functions. Exponentially concave loss functions encompass several fundamental problems in machine learning such as squared loss in linear regression, logistic loss in classification, and negative logarithm loss in portfolio management. We demonstrate an O(d log T/T ) upper bound on the excess risk of stochastic online Newton step algorithm, and an O(d/T ) lower bound on the excess risk of any stochastic optimization method for squared loss, indicating that the obtained upper bound is optimal up to a logarithmic factor. The analysis of upper bound is based on recent advances in concentration inequalities for bounding self-normalized martingales, which is interesting by its own right, and the proof technique used to achieve the lower bound is a probabilistic method and relies on an information-theoretic minimax analysis.},
 address = {Paris, France},
 author = {Mahdavi, Mehrdad and Zhang, Lijun and Jin, Rong},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1951567707},
 pages = {1305--1320},
 pdf = {http://proceedings.mlr.press/v40/Mahdavi15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Lower and Upper Bounds on the Generalization of Stochastic Exponentially Concave Optimization},
 url = {https://proceedings.mlr.press/v40/Mahdavi15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Makarychev15,
 abstract = {In this paper, we propose and study a semi-random model for the Correlation Clustering problem on arbitrary graphs G. We give two approximation algorithms for Correlation Clustering instances from this model. The first algorithm finds a solution of value (1+δ)opt-cost+O�(nlog 3 n) with high probability, where opt-cost is the value of the optimal solution (for every δ > 0). The second algorithm finds the ground truth clustering with an arbitrarily small classific ation error η (under some additional assumptions on the instance).},
 address = {Paris, France},
 author = {Makarychev, Konstantin and Makarychev, Yury and Vijayaraghavan, Aravindan},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2605800612},
 pages = {1321--1342},
 pdf = {http://proceedings.mlr.press/v40/Makarychev15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Correlation clustering with noisy partial information},
 url = {https://proceedings.mlr.press/v40/Makarychev15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Matsumoto15,
 abstract = {We consider an online density estimation problem for the Bradley-Terry model, where each model parameter defines the probability of a match result between any pair in a set of n teams. The problem is hard because the loss function (i.e., the negative log-likelihood function in our problem setting) is not convex. To avoid the non-convexity, we can change parameters so that the loss function becomes convex with respect to the new parameter. But then the radius K of the reparameterized domain may be infinite, whereK depends on the outcome sequence. So we put a mild assumption that guarantees that K is finite. We can thus employ standard online convex optimization algorithms, namely OGD and ONS, over the reparameterized domain, and get regret bounds O(n 1 2 (lnK) p T ) andO(n 3 2K lnT ), respectively, whereT is the horizon of the game. The bounds roughly means that OGD is better whenK is large while ONS is better whenK is small. But how large can K be? We show that K can be as large as ( T n 1 ), which implies that the worst case regret bounds of OGD and ONS areO(n 3 2 p T lnT ) and ~ O(n 3 2 (T ) n 1 ), respectively. We then propose a version of Follow the Regularized Leader, whose regret bound is close to the minimum of those of OGD and ONS. In other words, our algorithm is competitive with both for a wide range of values of K. In particular, our algorithm achieves the worst case regret bound O(n 5 2T 1 3 lnT ), which is slightly better than OGD with respect to T . In addition, our algorithm},
 address = {Paris, France},
 author = {Matsumoto, Issei and Hatano, Kohei and Takimoto, Eiji},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2784013186},
 pages = {1343--1359},
 pdf = {http://proceedings.mlr.press/v40/Matsumoto15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Online density estimation of bradley-terry models},
 url = {https://proceedings.mlr.press/v40/Matsumoto15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Neu15,
 abstract = {We consider the problem of online combinatorial optimization under semi-bandit feedback, where a learner has to repeatedly pick actions from a combinatorial decision set in order to minimize the total losses associated with its decisions. After making each decision, the learner observes the losses associated with its action, but not other losses. For this problem, there are several learning algorithms that guarantee that the learner's expected regret grows as $\widetilde{O}(\sqrt{T})$ with the number of rounds $T$. In this paper, we propose an algorithm that improves this scaling to $\widetilde{O}(\sqrt{L_T^*})$, where $L_T^*$ is the total loss of the best action. Our algorithm is among the first to achieve such guarantees in a partial-feedback scheme, and the first one to do so in a combinatorial setting.},
 address = {Paris, France},
 author = {Neu, Gergely},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2964176699},
 pages = {1360--1375},
 pdf = {http://proceedings.mlr.press/v40/Neu15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {First-order regret bounds for combinatorial semi-bandits},
 url = {https://proceedings.mlr.press/v40/Neu15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Neyshabur15,
 abstract = {We investigate the capacity, convexity and characterization of a general family of norm-constrained feed-forward networks.},
 address = {Paris, France},
 author = {Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2962857907},
 pages = {1376--1401},
 pdf = {http://proceedings.mlr.press/v40/Neyshabur15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Norm-Based Capacity Control in Neural Networks},
 url = {https://proceedings.mlr.press/v40/Neyshabur15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Papadimitriou15,
 abstract = {What is the mechanism of learning in the brain? Despite breathtaking advances in neuroscience, and in machine learning, we do not seem close to an answer. Using Valiant’s neuronal model as a foundation, we introduce PJOIN (for “predictive join”), a primitive that combines association and prediction. We show that PJOIN can be implemented naturally in Valiant’s conservative, formal model of cortical computation. Using PJOIN — and almost nothing else — we give a simple algorithm for unsupervised learning of arbitrary ensembles of binary patterns (solving an open problem in Valiant’s work). This algorithm relies crucially on prediction, and entails significant downward traffic (“feedback”) while parsing stimuli. Prediction and feedback are well-known features of neural cognition and, as far as we know, this is the first theoretical prediction of their essential role in learning.},
 address = {Paris, France},
 author = {Papadimitriou, Christos H. and Vempala, Santosh S.},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W810436313},
 pages = {1402--1422},
 pdf = {http://proceedings.mlr.press/v40/Papadimitriou15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Cortical Learning via Prediction},
 url = {https://proceedings.mlr.press/v40/Papadimitriou15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Peng15,
 abstract = {In this paper we study variants of the widely used spectral clustering that partitions a graph into k clusters by (1) embedding the vertices of a graph into a low-dimensional space using the bottom eigenvectors of the Laplacian matrix, and (2) grouping the embedded points into k clusters via k-means algorithms. We show that, for a wide class of graphs, spectral clustering gives a good approximation of the optimal clustering. While this approach was proposed in the early 1990s and has comprehensive applications, prior to our work similar results were known only for graphs generated from stochastic models. We also give a nearly-linear time algorithm for partitioning well-clustered graphs based on computing a matrix exponential and approximate nearest neighbor data structures.},
 address = {Paris, France},
 author = {Peng, Richard and Sun, He and Zanetti, Luca},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2949387874},
 pages = {1423--1455},
 pdf = {http://proceedings.mlr.press/v40/Peng15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Partitioning Well-Clustered Graphs: Spectral Clustering Works!},
 url = {https://proceedings.mlr.press/v40/Peng15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Perchet15,
 abstract = {Motivated by practical applications, chiefly clinical trials, we study the regret achievable for stochastic bandits under the constraint that the employed policy must split trials into a small number of batches. We propose a simple policy, and show that a very small number of batches gives close to minimax optimal regret bounds. As a byproduct, we derive optimal policies with low switching cost for stochastic bandits.},
 address = {Paris, France},
 author = {Perchet, Vianney and Rigollet, Philippe and Chassang, Sylvain and Snowberg, Erik},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1958090791},
 pages = {1456--1456},
 pdf = {http://proceedings.mlr.press/v40/Perchet15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Batched bandit problems},
 url = {https://proceedings.mlr.press/v40/Perchet15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Rakhlin15,
 abstract = {We study online prediction where regret of the algorithm is measured against a benchmark defined via evolving constraints. This framework captures online prediction on graphs, as well as other prediction problems with combinatorial structure. A key aspect here is that finding the optimal benchmark predictor (even in hindsight, given all the data) might be computationally hard due to the combinatorial nature of the constraints. Despite this, we provide polynomial-time \emph{prediction} algorithms that achieve low regret against combinatorial benchmark sets. We do so by building improper learning algorithms based on two ideas that work together. The first is to alleviate part of the computational burden through random playout, and the second is to employ Lasserre semidefinite hierarchies to approximate the resulting integer program. Interestingly, for our prediction algorithms, we only need to compute the values of the semidefinite programs and not the rounded solutions. However, the integrality gap for Lasserre hierarchy \emph{does} enter the generic regret bound in terms of Rademacher complexity of the benchmark set. This establishes a trade-off between the computation time and the regret bound of the algorithm.},
 address = {Paris, France},
 author = {Rakhlin, Alexander and Sridharan, Karthik},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2148239377},
 pages = {1457--1479},
 pdf = {http://proceedings.mlr.press/v40/Rakhlin15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Hierarchies of Relaxations for Online Prediction Problems with Evolving Constraints},
 url = {https://proceedings.mlr.press/v40/Rakhlin15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Rebeschini15,
 abstract = {We investigate the systematic mechanism for designing fast mixing Markov chain Monte Carlo algorithms to sample from discrete point processes under the Dobrushin uniqueness condition for Gibbs measures. Discrete point processes are defined as probability distributions $μ(S)\propto \exp(βf(S))$ over all subsets $S\in 2^V$ of a finite set $V$ through a bounded set function $f:2^V\rightarrow \mathbb{R}$ and a parameter $β&gt;0$. A subclass of discrete point processes characterized by submodular functions (which include log-submodular distributions, submodular point processes, and determinantal point processes) has recently gained a lot of interest in machine learning and shown to be effective for modeling diversity and coverage. We show that if the set function (not necessarily submodular) displays a natural notion of decay of correlation, then, for $β$ small enough, it is possible to design fast mixing Markov chain Monte Carlo methods that yield error bounds on marginal approximations that do not depend on the size of the set $V$. The sufficient conditions that we derive involve a control on the (discrete) Hessian of set functions, a quantity that has not been previously considered in the literature. We specialize our results for submodular functions, and we discuss canonical examples where the Hessian can be easily controlled.},
 address = {Paris, France},
 author = {Rebeschini, Patrick and Karbasi, Amin},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W585006759},
 pages = {1480--1500},
 pdf = {http://proceedings.mlr.press/v40/Rebeschini15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Fast Mixing for Discrete Point Processes},
 url = {https://proceedings.mlr.press/v40/Rebeschini15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Reid15,
 abstract = {Mixability is a property of a loss which characterizes when 
	constant regret is possible in the game of prediction with expert
	advice. We show that a key property of mixability generalizes, and
	the $\exp$ and $\log$ operations present in the usual theory are not as
	special as one might have thought.
	In doing so we introduce a
	more general notion of $\Phi$-mixability where $\Phi$ is a general
	entropy (\ie, any convex function on probabilities). We show how a property 
	shared by the convex dual of any such entropy yields a natural
	algorithm (the minimizer of a regret bound) which, analogous to the
	classical Aggregating Algorithm, is guaranteed a constant regret
	when used with $\Phi$-mixable losses.
	We characterize which $\Phi$ have non-trivial $\Phi$-mixable losses and
	relate $\Phi$-mixability and its associated Aggregating 
	Algorithm to potential-based methods, a Blackwell-like
	condition, mirror descent, and risk measures from finance. 
	We also define a notion of ``dominance'' between different
	entropies in terms of bounds they guarantee and 
	conjecture that classical mixability gives optimal bounds, for which we 
	provide some supporting empirical evidence.},
 address = {Paris, France},
 author = {Reid, Mark D. and Frongillo, Rafael M. and Williamson, Robert C. and Mehta, Nishant},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1874624425},
 pages = {1501--1522},
 pdf = {http://proceedings.mlr.press/v40/Reid15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Generalized Mixability via Entropic Duality},
 url = {https://proceedings.mlr.press/v40/Reid15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Shamir15,
 abstract = {We study the attainable regret for online linear optimization problems with bandit feedback, where unlike the full-information setting, the player can only observe its own loss rather than the full loss vector. We show that the price of bandit information in this setting can be as large asd, disproving the well-known conjecture (Dani et al. (2007)) that the regret for bandit linear optimization is at most p d times the full-information regret. Surprisingly, this is shown using “trivial” modifications of standard domains, which have no effect in the full-information setting. This and other results we present highlight some interesting differences between full-information and bandit learning, which were not considered in previous literature.},
 address = {Paris, France},
 author = {Shamir, Ohad},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2963147981},
 pages = {1523--1551},
 pdf = {http://proceedings.mlr.press/v40/Shamir15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {On the Complexity of Bandit Linear Optimization},
 url = {https://proceedings.mlr.press/v40/Shamir15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Simon15a,
 abstract = {The best currently known general lower and upper bounds on the number of labeled examples needed for learning a concept class in the PAC framework (the realizable case) do not perfectly match: they leave a gap of order log(1= ) (resp. a gap which is logarithmic in another one of the relevant parameters). It is an unresolved question whether there exists an “optimal PAC algorithm” which establishes a general upper bound with precisely the same order of magnitude as the general lower bound. According to a result of Auer and Ortner (2007), there is no way for showing that arbitrary consistent algorithms are optimal because they can provably differ from optimality by factor log(1= ). In contrast to this result, we show that every consistent algorithm L (even a provably suboptimal one) induces a family (LK)K 1 of PAC algorithms (with 2K 1 calls of L as a subroutine) which come very close to optimality: the number of labeled examples needed by LK exceeds the general lower bound only by factor ‘K(1= ) where ‘K denotes (a truncated version of) the K-times iterated logarithm. Moreover, LK is applicable to any concept class C of finite VC-dimension and it can be implemented efficiently whenever the consistency problem for C is feasible. We show furthermore that, for every consistent algorithm L, L2 is an optimal PAC algorithm for precisely the same concept classes which were used by Auer and Ortner (2007) for showing the existence of suboptimal consistent algorithms. This can be seen as an indication that LK may have an even better performance than it is suggested by our worstcase analysis.},
 address = {Paris, France},
 author = {Simon, Hans U.},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W779731701},
 pages = {1552--1563},
 pdf = {http://proceedings.mlr.press/v40/Simon15a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {An Almost Optimal PAC Algorithm},
 url = {https://proceedings.mlr.press/v40/Simon15a.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Simon15b,
 abstract = {The Recursive Teaching Dimension (RTD) of a concept classC is a complexity parameter referring to the worst-case number of labelled examples needed to learn any target concept inC from a teacher following the recursive teaching model. It is the first teaching complexity notion for which interesting relationships to the VC dimension (VCD) have been established. In particular, for finite maximum classes of a given VCD d, the RTD equals d. To date, there is no concept class known for which the ratio of RTD over VCD exceeds 3=2. However, the only known upper bound on RTD in terms of VCD is exponential in the VCD and depends on the size of the concept class. We pose the following question: is the RTD upper-bounded by a function that grows only linearly in the VCD? Answering this question would further our understanding of the relationships between the complexity of teaching and the complexity of learning from randomly chosen examples. In addition, the answer to this question, whether positive or negative, is known to have implications on the study of the long-standing open sample compression conjecture, which claims that every concept class of VCD d has a sample compression scheme in which samples for concepts in the class are compressed to subsets of size no larger than d.},
 address = {Paris, France},
 author = {Simon, Hans U. and Zilles, Sandra},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1877234769},
 pages = {1770--1772},
 pdf = {http://proceedings.mlr.press/v40/Simon15b.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Open Problem: Recursive Teaching Dimension Versus VC Dimension},
 url = {https://proceedings.mlr.press/v40/Simon15b.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Steinhardt15,
 abstract = {We establish a minimax lower bound of kd on the sample size needed to estimate parameters in a k-sparse linear regression of dimension d under memory restrictions to B bits, where is the ‘2 parameter error. When the covariance of the regressors is the identity matrix, we also provide an algorithm that uses ~ O(B +k) bits and requires ~ O( kd B 2 ) observations to achieve error . Our lower bound holds in a more general communication-bounded setting, where instead of a memory bound, at mostB bits of information are allowed to be (adaptively) communicated about each sample.},
 address = {Paris, France},
 author = {Steinhardt, Jacob and Duchi, John},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1870267105},
 pages = {1564--1587},
 pdf = {http://proceedings.mlr.press/v40/Steinhardt15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Minimax rates for memory-bounded sparse linear regression},
 url = {https://proceedings.mlr.press/v40/Steinhardt15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Steinke15,
 abstract = {We show an essentially tight bound on the number of adaptively chosen statistical queries that a computationally efficient algorithm can answer accurately given n samples from an unknown distribution. A statistical query asks for the expectation of a predicate over the underlying distribution, and an answer to a statistical query is accurate if it is “close” to the correct expectation over the distribution. This question was recently studied by Dwork et al. [DFH+ 15], who showed how to answer Ω(n2) queries efficiently, and also by Hardt and Ullman [HU14], who showed that answering O(n3) queries is hard. We close the gap between the two bounds and show that, under a standard hardness assumption, there is no computationally efficient algorithm that, given n samples from an unknown distribution, can give valid answers to O(n2) adaptively chosen statistical queries. An implication of our results is that computationally efficient algorithms for answering arbitrary, adaptively chosen statistical queries may as well be differentially private. We obtain our results using a new connection between the problem of answering adaptively chosen statistical queries and a combinatorial object called an interactive fingerprinting code [FT01]. In order to optimize our hardness result, we give a new Fourier-analytic approach to analyzing fingerprinting codes that is simpler, more flexible, and yields better parameters than previous constructions.},
 address = {Paris, France},
 author = {Steinke, Thomas and Ullman, Jonathan},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2598809989},
 pages = {1588--1628},
 pdf = {http://proceedings.mlr.press/v40/Steinke15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Interactive Fingerprinting Codes and the Hardness of Preventing False Discovery},
 url = {https://proceedings.mlr.press/v40/Steinke15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Telgarsky15,
 abstract = {This paper proves, in very general settings, that convex risk minimization is a procedure to select a unique conditional probability model determined by the classification problem. Unlike most previous work, we give results that are general enough to include cases in which no minimum exists, as occurs typically, for instance, with standard boosting algorithms. Concretely, we first show that any sequence of predictors minimizing convex risk over the source distribution will converge to this unique model when the class of predictors is linear (but potentially of infinite dimension). Secondly, we show the same result holds for \emph{empirical} risk minimization whenever this class of predictors is finite dimensional, where the essential technical contribution is a norm-free generalization bound.},
 address = {Paris, France},
 author = {Telgarsky, Matus and DudÃ­k, Miroslav and Schapire, Robert},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W1600509147},
 pages = {1629--1682},
 pdf = {http://proceedings.mlr.press/v40/Telgarsky15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Convex Risk Minimization and Conditional Probability Estimation},
 url = {https://proceedings.mlr.press/v40/Telgarsky15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Thrampoulidis15,
 abstract = {Non-smooth regularized convex optimization procedures have emerged as a powerful tool to recover structured signals (sparse, low-rank, etc.) from (possibly compressed) noisy linear measurements. We focus on the problem of linear regression and consider a general class of optimization methods that minimize a loss function measuring the misfit of the model to the observations with an added structured-inducing regularization term. Celebrated instances include the LASSO, GroupLASSO, Least-Absolute Deviations method, etc.. We develop a quite general framework for how to determine precise prediction performance guaranties (e.g. mean-square-error) of such methods for the case of Gaussian measurement ensemble. The machinery builds upon Gordon’s Gaussian min-max theorem under additional convexity assumptions that arise in many practical applications. This theorem associates with a primary optimization (PO) problem a simplified auxiliary optimization (AO) problem from which we can tightly infer properties of the original (PO), such as the optimal cost, the norm of the optimal solution, etc. Our theory applies to general loss functions and regularization and provides guidelines on how to optimally tune the regularizer coefficient when certain structural properties (such as sparsity level, rank, etc.) are known.},
 address = {Paris, France},
 author = {Thrampoulidis, Christos and Oymak, Samet and Hassibi, Babak},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W835905657},
 pages = {1683--1709},
 pdf = {http://proceedings.mlr.press/v40/Thrampoulidis15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Regularized Linear Regression: A Precise Analysis of the Estimation Error},
 url = {https://proceedings.mlr.press/v40/Thrampoulidis15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Vempala15,
 abstract = {We present a simple, general technique for reducing the sample complexity of matrix and tensor decomposition algorithms applied to distributions. We use the technique to give a polynomial-time algorithm for standard ICA with sample complexity nearly linear in the dimension, thereby improving substantially on previous bounds. The analysis is based on properties of random polynomials, namely the spacings of an ensemble of polynomials. Our technique also applies to other applications of tensor decompositions, including spherical Gaussian mixture models.},
 address = {Paris, France},
 author = {Vempala, Santosh S. and Xiao, Ying.},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2962897783},
 pages = {1710--1723},
 pdf = {http://proceedings.mlr.press/v40/Vempala15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Max vs Min: Tensor Decomposition and ICA with nearly Linear Sample Complexity},
 url = {https://proceedings.mlr.press/v40/Vempala15.html},
 volume = {40},
 year = {2015}
}

@inproceedings{pmlr-v40-Yu15,
 abstract = {We consider emphatic temporal-difference learning algorithms for policy evaluation in discounted Markov decision processes with finite spaces. Such algorithms were recently proposed by Sutton, Mahmood, and White (2015) as an improved solution to the problem of divergence of off-policy temporal-difference learning with linear function approximation. We present in this paper the first convergence proofs for two emphatic algorithms, ETD(λ) and ELSTD(λ). We prove, under general off-policy conditions, the convergence in L for ELSTD(λ) iterates, and the almost sure convergence of the approximate value functions calculated by both algorithms using a single infinitely long trajectory. Our analysis involves new techniques with applications beyond emphatic algorithms leading, for example, to the first proof that standard TD(λ) also converges under off-policy training for λ sufficiently large.},
 address = {Paris, France},
 author = {Yu, H.},
 booktitle = {Proceedings of The 28th Conference on Learning Theory},
 editor = {GrÃ¼nwald, Peter and Hazan, Elad and Kale, Satyen},
 month = {03--06 Jul},
 openalex = {W2964112359},
 pages = {1724--1751},
 pdf = {http://proceedings.mlr.press/v40/Yu15.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {On Convergence of Emphatic Temporal-Difference Learning},
 url = {https://proceedings.mlr.press/v40/Yu15.html},
 volume = {40},
 year = {2015}
}
