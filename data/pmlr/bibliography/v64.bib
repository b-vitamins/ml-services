


@Proceedings{AutoML2016,
  title =     {Proceedings of the Workshop on Automatic Machine Learning},
  booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
  editor =    {Frank Hutter and Lars Kotthoff and Joaquin Vanschoren},
  publisher = {PMLR},
  series =    {Proceedings of Machine Learning Research},
  volume =    64
}




@InProceedings{pmlr-v64-adbdulrahman_effect_2016,
  title = 	 {Effect of Incomplete Meta-dataset on Average Ranking Method},
  author = 	 {Abdulrahman, Salisu Mamman and Brazdil, Pavel},
  booktitle = 	 {Proceedings of the Workshop on Automatic Machine Learning},
  pages = 	 {1--10},
  year = 	 {2016},
  editor = 	 {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  volume = 	 {64},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v64/adbdulrahman_effect_2016.pdf},
  url = 	 {https://proceedings.mlr.press/v64/adbdulrahman_effect_2016.html},
  abstract = 	 {One of the simplest metalearning methods is the average ranking method. This method uses metadata in the form of test results of a given algorithms on a given datasets and calculates an average rank for each algorithm. The average ranks are used to construct the average ranking. The work described here investigate the problem of how the process of generating the average ranking is affected by incomplete metadata. We are interested in this issue for the following reason. If we could show that incomplete metadata does not affect the final results much, we could explore it in future design. We could simply conduct fewer tests and save thus computation time. Our results show that our method is robust to omission in meta datasets.}
}




@InProceedings{pmlr-v64-dewancker_strategy_2016,
  title = 	 {A Strategy for Ranking Optimization Methods using Multiple Criteria},
  author = 	 {Dewancker, Ian and McCourt, Michael and Clark, Scott and Hayes, Patrick and Johnson, Alexandra and Ke, George},
  booktitle = 	 {Proceedings of the Workshop on Automatic Machine Learning},
  pages = 	 {11--20},
  year = 	 {2016},
  editor = 	 {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  volume = 	 {64},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v64/dewancker_strategy_2016.pdf},
  url = 	 {https://proceedings.mlr.press/v64/dewancker_strategy_2016.html},
  abstract = 	 {Many methods for optimizing black-box functions exist, and many metrics exist for judging the performance of a specific optimization method. There is not, however, a generally agreed upon strategy for simultaneously comparing the performance of multiple optimization methods for multiple performance metrics across a range of optimization problems. This paper proposes such a methodology, which uses nonparametric statistical tests to convert the metrics recorded for each problem into a partial ranking of optimization methods; these partial rankings are then amalgamated through a voting mechanism to generate a final score for each optimization method. Mathematical analysis is provided to motivate decisions within this strategy, and numerical results are provided to demonstrate the potential insights afforded thereby.}
}




@InProceedings{pmlr-v64-guyon_review_2016,
  title = 	 {A brief Review of the ChaLearn AutoML Challenge: Any-time Any-dataset Learning without Human Intervention},
  author = 	 {Guyon, Isabelle and Chaabane, Imad and Escalante, Hugo Jair and Escalera, Sergio and Jajetic, Damir and Lloyd, James Robert and MaciÃ , NÃºria and Ray, Bisakha and Romaszko, Lukasz and Sebag, MichÃ¨le and Statnikov, Alexander and Treguer, SÃ©bastien and Viegas, Evelyne},
  booktitle = 	 {Proceedings of the Workshop on Automatic Machine Learning},
  pages = 	 {21--30},
  year = 	 {2016},
  editor = 	 {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  volume = 	 {64},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v64/guyon_review_2016.pdf},
  url = 	 {https://proceedings.mlr.press/v64/guyon_review_2016.html},
  abstract = 	 {The ChaLearn AutoML Challenge team conducted a large scale evaluation of fully automatic, black-box learning machines for feature-based classification and regression problems. The test bed was composed of 30 data sets from a wide variety of application domains and ranging across different types of complexity. Over five rounds, participants succeeded in delivering AutoML software capable of being trained and tested without human intervention. Although improvements can still be made to close the gap between human-tweaked and AutoML models, this challenge has been a leap forward in the field and its platform will remain available for post-challenge submissions at http://codalab.org/AutoML.}
}




@InProceedings{pmlr-v64-kim_scalable_2016,
  title = 	 {Scalable Structure Discovery in Regression using Gaussian Processes},
  author = 	 {Kim, Hyunjik and Teh, Yee Whye},
  booktitle = 	 {Proceedings of the Workshop on Automatic Machine Learning},
  pages = 	 {31--40},
  year = 	 {2016},
  editor = 	 {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  volume = 	 {64},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v64/kim_scalable_2016.pdf},
  url = 	 {https://proceedings.mlr.press/v64/kim_scalable_2016.html},
  abstract = 	 {Automatic Bayesian Covariance Discovery (ABCD) in Lloyd et. al (2014) provides a framework for automating statistical modelling as well as exploratory data analysis for regression problems. However ABCD does not scale due to its $O(N^3)$ running time. This is undesirable not only because the average size of data sets is growing fast, but also because there is potentially more information in bigger data, implying a greater need for more expressive models that can discover sophisticated structure. We propose a scalable version of ABCD, to encompass big data within the boundaries of automated statistical modelling.}
}




@InProceedings{pmlr-v64-malkomes_bayesian_2016,
  title = 	 {Bayesian optimization for automated model selection},
  author = 	 {Malkomes, Gustavo and Schaff, Chip and Garnett, Roman},
  booktitle = 	 {Proceedings of the Workshop on Automatic Machine Learning},
  pages = 	 {41--47},
  year = 	 {2016},
  editor = 	 {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  volume = 	 {64},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v64/malkomes_bayesian_2016.pdf},
  url = 	 {https://proceedings.mlr.press/v64/malkomes_bayesian_2016.html},
  abstract = 	 {Despite the success of kernel-based nonparametric methods, kernel selection still requires considerable expertise, and is often described as a âblack art.â We present a sophisticated method for automatically searching for an appropriate kernel from an infinite space of potential choices. Previous efforts in this direction have focused on traversing a kernel grammar, only examining the data via computation of marginal likelihood. Our proposed search method is based on Bayesian optimization in model space, where we reason about model evidence as a function to be maximized. We explicitly reason about the data distribution and how it induces similarity between potential model choices in terms of the explanations they can offer for observed data. In this light, we construct a novel kernel between models to explain a given dataset. Our method is capable of finding a model that explains a given dataset well without any human assistance, often with fewer computatio! ns of model evidence than previous approaches, a claim we demonstrate empirically.}
}




@InProceedings{pmlr-v64-salvador_adapting_2016,
  title = 	 {Adapting Multicomponent Predictive Systems using Hybrid Adaptation Strategies with Auto-WEKA in Process Industry},
  author = 	 {Salvador, Manuel Martin and Budka, Marcin and Gabrys, Bogdan},
  booktitle = 	 {Proceedings of the Workshop on Automatic Machine Learning},
  pages = 	 {48--57},
  year = 	 {2016},
  editor = 	 {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  volume = 	 {64},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v64/salvador_adapting_2016.pdf},
  url = 	 {https://proceedings.mlr.press/v64/salvador_adapting_2016.html},
  abstract = 	 {Automation of composition and optimisation of multicomponent predictive systems (MCPSs) made of a number of preprocessing steps and predictive models is a challenging problem that has been addressed in recent works. However, one of the current challenges is how to adapt these systems in dynamic environments where data is changing over time. In this work we propose a hybrid approach combining different adaptation strategies with the Bayesian optimisation techniques for parametric, structural and hyperparameter optimisation of entire MCPSs. Experiments comparing different adaptation strategies have been performed on 7 datasets from real chemical production processes. Experimental analysis shows that optimisation of entire MCPSs as a method of adaptation to changing environments is feasible and that hybrid strategies perform better in most of the analysed cases.}
}




@InProceedings{pmlr-v64-mendoza_towards_2016,
  title = 	 {Towards Automatically-Tuned Neural Networks},
  author = 	 {Mendoza, Hector and Klein, Aaron and Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
  booktitle = 	 {Proceedings of the Workshop on Automatic Machine Learning},
  pages = 	 {58--65},
  year = 	 {2016},
  editor = 	 {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  volume = 	 {64},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v64/mendoza_towards_2016.pdf},
  url = 	 {https://proceedings.mlr.press/v64/mendoza_towards_2016.html},
  abstract = 	 {Recent advances in AutoML have led to automated tools that can compete with machine learning experts on supervised learning tasks. However, current AutoML tools do not yet support modern neural networks effectively. In this work, we present a first version of Auto-Net, which provides automatically-tuned feed-forward neural networks without any human intervention. We report results on datasets from the recent AutoML challenge showing that ensembling Auto-Net with Auto-sklearn often performs better than either alone, and report the first results on winning a competition dataset against human experts with automatically-tuned neural networks.}
}




@InProceedings{pmlr-v64-olson_tpot_2016,
  title = 	 {TPOT: A Tree-based Pipeline Optimization Tool for Automating Machine Learning},
  author = 	 {Olson, Randal S. and Moore, Jason H.},
  booktitle = 	 {Proceedings of the Workshop on Automatic Machine Learning},
  pages = 	 {66--74},
  year = 	 {2016},
  editor = 	 {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  volume = 	 {64},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v64/olson_tpot_2016.pdf},
  url = 	 {https://proceedings.mlr.press/v64/olson_tpot_2016.html},
  abstract = 	 {As data science becomes more mainstream, there will be an ever-growing demand for data science tools that are more accessible, flexible, and scalable. In response to this demand, automated machine learning (autoML) researchers have begun building systems that automate the process of designing and optimizing machine learning pipelines. In this paper we present TPOT, an open source genetic programming-based autoML system that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification task. We benchmark TPOT on a series of 150 supervised classification tasks and find that it significantly outperforms a basic machine learning analysis in 22 of them, while experiencing minimal degradation in accuracy on 5 of the benchmarksâall without any domain knowledge nor human input. As such, GP-based autoML systems show considerable promise in the autoML domain.}
}




@InProceedings{pmlr-v64-orabona_parameter_2016,
  title = 	 {Parameter-Free Convex Learning through Coin Betting},
  author = 	 {Orabona, Francesco and PÃ¡l, DÃ¡vid},
  booktitle = 	 {Proceedings of the Workshop on Automatic Machine Learning},
  pages = 	 {75--82},
  year = 	 {2016},
  editor = 	 {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  volume = 	 {64},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v64/orabona_parameter_2016.pdf},
  url = 	 {https://proceedings.mlr.press/v64/orabona_parameter_2016.html},
  abstract = 	 {We present a new parameter-free algorithm for online linear optimization over any Hilbert space. It is theoretically optimal, with regret guarantees as good as with the best possible learning rate. The algorithm is simple and easy to implement. The analysis is given via the adversarial coin-betting game, Kelly betting and the Krichevsky-Trofimov estimator. Applications to obtain parameter-free convex optimization and machine learning algorithms are shown.}
}



