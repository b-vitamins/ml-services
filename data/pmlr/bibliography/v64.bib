@proceedings{AutoML2016,
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Frank Hutter and Lars Kotthoff and Joaquin Vanschoren},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Proceedings of the Workshop on Automatic Machine Learning},
 volume = {64}
}

@inproceedings{pmlr-v64-adbdulrahman_effect_2016,
 abstract = {One of the simplest metalearning methods is the average ranking method. This method uses metadata in the form of test results of a given set of algorithms on given set of datasets and calculates an average rank for each algorithm. The ranks are used to construct the average ranking. We investigate the problem of how the process of generating the average ranking is affected by incomplete metadata including fewer test results. This issue is relevant, because if we could show that incomplete metadata does not affect the final results much, we could explore it in future design. We could simply conduct fewer tests and save thus computation time. In this paper we describe an upgraded average ranking method that is capable of dealing with incomplete metadata. Our results show that the proposed method is relatively robust to omission in test results in the meta datasets.},
 address = {New York, New York, USA},
 author = {Abdulrahman, Salisu Mamman and Brazdil, Pavel},
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 month = {24 Jun},
 openalex = {W4293385251},
 pages = {1--10},
 pdf = {http://proceedings.mlr.press/v64/adbdulrahman_effect_2016.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Effect of Incomplete Meta-dataset on Average Ranking Method},
 url = {https://proceedings.mlr.press/v64/adbdulrahman_effect_2016.html},
 volume = {64},
 year = {2016}
}

@inproceedings{pmlr-v64-dewancker_strategy_2016,
 abstract = {Many methods for optimizing black-box functions exist, and many metrics exist for judging the performance of a specific optimization method. There is not, however, a generally agreed upon strategy for simultaneously comparing the performance of multiple optimization methods for multiple performance metrics across a range of optimization problems. This paper proposes such a methodology, which uses nonparametric statistical tests to convert the metrics recorded for each problem into a partial ranking of optimization methods; these partial rankings are then amalgamated through a voting mechanism to generate a final score for each optimization method. Mathematical analysis is provided to motivate decisions within this strategy, and numerical results are provided to demonstrate the potential insights afforded thereby.},
 address = {New York, New York, USA},
 author = {Dewancker, Ian and McCourt, Michael and Clark, Scott and Hayes, Patrick and Johnson, Alexandra and Ke, George},
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 month = {24 Jun},
 openalex = {W2586993394},
 pages = {11--20},
 pdf = {http://proceedings.mlr.press/v64/dewancker_strategy_2016.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {A Strategy for Ranking Optimization Methods using Multiple Criteria},
 url = {https://proceedings.mlr.press/v64/dewancker_strategy_2016.html},
 volume = {64},
 year = {2016}
}

@inproceedings{pmlr-v64-guyon_review_2016,
 abstract = {The ChaLearn AutoML Challenge team conducted a large scale evaluation of fully auto-
matic, black-box learning machines for feature-based classi cation and regression problems. The test bed was composed of 30 data sets from a wide variety of application domains and ranged across di erent types of complexity. Over six rounds, participants succeeded in delivering AutoML software capable of being trained and tested without human intervention. Although improvements can still be made to close the gap between human-tweaked and AutoML models, this competition contributes to the development of fully automated environments by challenging practitioners to solve problems under speci c constraints and sharing their approaches; the platform will remain available for post-challenge submissions at http://codalab.org/AutoML.},
 address = {New York, New York, USA},
 author = {Guyon, Isabelle and Chaabane, Imad and Escalante, Hugo Jair and Escalera, Sergio and Jajetic, Damir and Lloyd, James Robert and MaciÃ , NÃºria and Ray, Bisakha and Romaszko, Lukasz and Sebag, MichÃ¨le and Statnikov, Alexander and Treguer, SÃ©bastien and Viegas, Evelyne},
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 month = {24 Jun},
 openalex = {W2586798638},
 pages = {21--30},
 pdf = {http://proceedings.mlr.press/v64/guyon_review_2016.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {A brief Review of the ChaLearn AutoML Challenge: Any-time Any-dataset Learning without Human Intervention},
 url = {https://proceedings.mlr.press/v64/guyon_review_2016.html},
 volume = {64},
 year = {2016}
}

@inproceedings{pmlr-v64-kim_scalable_2016,
 abstract = {Automatic Bayesian Covariance Discovery (ABCD) in Lloyd et. al (2014) provides a framework for automating statistical modelling as well as exploratory data analysis for regression problems. However ABCD does not scale due to its $O(N^3)$ running time. This is undesirable not only because the average size of data sets is growing fast, but also because there is potentially more information in bigger data, implying a greater need for more expressive models that can discover sophisticated structure. We propose a scalable version of ABCD, to encompass big data within the boundaries of automated statistical modelling.},
 address = {New York, New York, USA},
 author = {Kim, Hyunjik and Teh, Yee Whye},
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 month = {24 Jun},
 openalex = {W2586019828},
 pages = {31--40},
 pdf = {http://proceedings.mlr.press/v64/kim_scalable_2016.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Scalable Structure Discovery in Regression using Gaussian Processes},
 url = {https://proceedings.mlr.press/v64/kim_scalable_2016.html},
 volume = {64},
 year = {2016}
}

@inproceedings{pmlr-v64-malkomes_bayesian_2016,
 abstract = {Despite the success of kernel-based nonparametric methods, kernel selection still requires considerable expertise, and is often described as a “black art.” We present a sophisticated method for automatically searching for an appropriate kernel from an infinite space of potential choices. Previous efforts in this direction have focused on traversing a kernel grammar, only examining the data via computation of marginal likelihood. Our proposed search method is based on Bayesian optimization in model space, where we reason about model evidence as a function to be maximized. We explicitly reason about the data distribution and how it induces similarity between potential model choices in terms of the explanations they can offer for observed data. In this light, we construct a novel kernel between models to explain a given dataset. Our method is capable of finding a model that explains a given dataset well without any human assistance, often with fewer computations of model evidence than previous approaches, a claim we demonstrate empirically.},
 address = {New York, New York, USA},
 author = {Malkomes, Gustavo and Schaff, Chip and Garnett, Roman},
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 month = {24 Jun},
 openalex = {W2555374257},
 pages = {41--47},
 pdf = {http://proceedings.mlr.press/v64/malkomes_bayesian_2016.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Bayesian optimization for automated model selection},
 url = {https://proceedings.mlr.press/v64/malkomes_bayesian_2016.html},
 volume = {64},
 year = {2016}
}

@inproceedings{pmlr-v64-mendoza_towards_2016,
 abstract = {Recent advances in AutoML have led to automated tools that can compete with machine learning experts on supervised learning tasks. However, current AutoML tools do not yet support modern neural networks effectively. In this work, we present a first version of Auto-Net, which provides automatically-tuned feed-forward neural networks without any human intervention. We report results on datasets from the recent AutoML challenge showing that ensembling Auto-Net with Auto-sklearn often performs better than either alone, and report the first results on winning a competition dataset against human experts with automatically-tuned neural networks.},
 address = {New York, New York, USA},
 author = {Mendoza, Hector and Klein, Aaron and Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 month = {24 Jun},
 openalex = {W2587014634},
 pages = {58--65},
 pdf = {http://proceedings.mlr.press/v64/mendoza_towards_2016.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Towards Automatically-Tuned Neural Networks},
 url = {https://proceedings.mlr.press/v64/mendoza_towards_2016.html},
 volume = {64},
 year = {2016}
}

@inproceedings{pmlr-v64-olson_tpot_2016,
 abstract = {As data science becomes increasingly mainstream, there will be an ever-growing demand for data science tools that are more accessible, flexible, and scalable. In response to this demand, automated machine learning (AutoML) researchers have begun building systems that automate the process of designing and optimizing machine learning pipelines. In this chapter we present TPOT v0.3, an open source genetic programming-based AutoML system that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification task. We benchmark TPOT on a series of 150 supervised classification tasks and find that it significantly outperforms a basic machine learning analysis in 21 of them, while experiencing minimal degradation in accuracy on 4 of the benchmarks—all without any domain knowledge nor human input. As such, genetic programming-based AutoML systems show considerable promise in the AutoML domain.},
 address = {New York, New York, USA},
 author = {Olson, Randal S. and Moore, Jason H.},
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 month = {24 Jun},
 openalex = {W2947123069},
 pages = {66--74},
 pdf = {http://proceedings.mlr.press/v64/olson_tpot_2016.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning},
 url = {https://proceedings.mlr.press/v64/olson_tpot_2016.html},
 volume = {64},
 year = {2016}
}

@inproceedings{pmlr-v64-orabona_parameter_2016,
 abstract = {We present a new parameter-free algorithm for online linear optimization over any Hilbert space. It is theoretically optimal, with regret guarantees as good as with the best possible learning rate. The algorithm is simple and easy to implement. The analysis is given via the adversarial coin-betting game, Kelly betting and the Krichevsky-Trofimov estimator. Applications to obtain parameter-free convex optimization and machine learning algorithms are shown.},
 address = {New York, New York, USA},
 author = {Orabona, Francesco and PÃ¡l, DÃ¡vid},
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 month = {24 Jun},
 openalex = {W2590128729},
 pages = {75--82},
 pdf = {http://proceedings.mlr.press/v64/orabona_parameter_2016.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Parameter-Free Convex Learning through Coin Betting},
 url = {https://proceedings.mlr.press/v64/orabona_parameter_2016.html},
 volume = {64},
 year = {2016}
}

@inproceedings{pmlr-v64-salvador_adapting_2016,
 abstract = {Automation of composition and optimisation of multicomponent predictive systems (MCPSs) made of a number of preprocessing steps and predictive models is a challenging problem that has been addressed in recent works. However, one of the current challenges is how to adapt these systems in dynamic environments where data is changing over time. In this work we propose a hybrid approach combining different adaptation strategies with the Bayesian optimisation techniques for parametric, structural and hyperparameter optimisation of entire MCPSs. Experiments comparing different adaptation strategies have been performed on 7 datasets from real chemical production processes. Experimental analysis shows that optimisation of entire MCPSs as a method of adaptation to changing environments is feasible and that hybrid strategies perform better in most of the analysed cases.},
 address = {New York, New York, USA},
 author = {Salvador, Manuel Martin and Budka, Marcin and Gabrys, Bogdan},
 booktitle = {Proceedings of the Workshop on Automatic Machine Learning},
 editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 month = {24 Jun},
 openalex = {W2583365339},
 pages = {48--57},
 pdf = {http://proceedings.mlr.press/v64/salvador_adapting_2016.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Adapting Multicomponent Predictive Systems using Hybrid Adaptation Strategies with Auto-WEKA in Process Industry},
 url = {https://proceedings.mlr.press/v64/salvador_adapting_2016.html},
 volume = {64},
 year = {2016}
}
