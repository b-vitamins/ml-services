@proceedings{BigMine2016,
 booktitle = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 editor = {Wei Fan and Albert Bifet and Jesse Read and Qiang Yang and Philip S. Yu},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 volume = {53}
}

@inproceedings{pmlr-v53-ahmed16,
 abstract = {Graphlets represent small induced subgraphs and are becoming increasingly important for a variety of applications. Despite the importance of the local graphlet problem, existing work focuses mainly on counting graphlets globally over the entire graph. These global counts have been used for tasks such as graph classification as well as for understanding and summarizing the fundamental structural patterns in graphs. In contrast, this work proposes a flexible, efficient, and scalable parallel framework for the more challenging problem of counting graphlets locally for a given edge or set of edges.The local graphlet counts provide a topologically rigorous characterization of the local structure surrounding an edge. The aim of this work is to obtain the count of every graphlet of size  k â{3, 4 }  for each edge. The framework gives rise to efficient, parallel, and accurate unbiased estimation methods as well as exact graphlet algorithms for counting graphlets locally. Experiments demonstrate the effectiveness of the proposed exact and estimation methods.},
 address = {San Francisco, California, USA},
 author = {Ahmed, Nesreen K. and Willke, Theodore L. and Rossi, Ryan A.},
 booktitle = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 editor = {Fan, Wei and Bifet, Albert and Read, Jesse and Yang, Qiang and Yu, Philip S.},
 month = {14 Aug},
 openalex = {W2587302913},
 pages = {1--17},
 pdf = {http://proceedings.mlr.press/v53/ahmed16.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Exact and Estimation of Local Edge-centric Graphlet Counts},
 url = {https://proceedings.mlr.press/v53/ahmed16.html},
 volume = {53},
 year = {2016}
}

@inproceedings{pmlr-v53-bhat16,
 abstract = {In this paper, we consider the problem of Bayesian filtering and inference for time series data modeled as noisy, discrete-time observations of a stochastic differential equation (SDE) with undetermined parameters. We develop a Metropolis algorithm to sample from the high-dimensional joint posterior density of all SDE parameters and state time series. Our approach relies on an innovative density tracking by quadrature (DTQ) method to compute the likelihood of the SDE, the part of the posterior that requires the most computational effort to evaluate. As we show, the DTQ method lends itself to a natural implementation using Scala and Apache Spark, an open source framework for scalable data mining. We study the performance and scalability of our algorithm on filtering and inference problems for both regularly and irregularly spaced time series.},
 address = {San Francisco, California, USA},
 author = {Bhat, Harish S. and Madushani, R. W. M. A. and Rawat, Shagun},
 booktitle = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 editor = {Fan, Wei and Bifet, Albert and Read, Jesse and Yang, Qiang and Yu, Philip S.},
 month = {14 Aug},
 openalex = {W2588280690},
 pages = {18--34},
 pdf = {http://proceedings.mlr.press/v53/bhat16.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Scalable SDE Filtering and Inference with Apache Spark},
 url = {https://proceedings.mlr.press/v53/bhat16.html},
 volume = {53},
 year = {2016}
}

@inproceedings{pmlr-v53-fan16,
 abstract = {Fractional calculus has gained considerable popularity and importance during the past three decades mainly because of its demonstrated applications in numerous seemingly diverse and widespread fields of science and engineering. The chapter presents results, including the existence and uniqueness of solutions for the Cauchy Type and Cauchy problems involving nonlinear ordinary fractional differential equations, explicit solutions of linear differential equations and of the corresponding initial-value problems by their reduction to Volterra integral equations and by using operational and compositional methods; applications of the one-and multidimensional Laplace, Mellin, and Fourier integral transforms in deriving the closed-form solutions of ordinary and partial differential equations; and a theory of the so-called “sequential linear fractional differential equations,” including a generalization of the classical Frobenius method.},
 address = {San Francisco, California, USA},
 author = {Fan, Wei and Bifet, Albert and Read, Jesse and Yang, Qiang and Yu, Philip S.},
 booktitle = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 editor = {Fan, Wei and Bifet, Albert and Read, Jesse and Yang, Qiang and Yu, Philip S.},
 month = {14 Aug},
 openalex = {W4240465921},
 pages = {i--viii},
 pdf = {http://proceedings.mlr.press/v53/fan16.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Preface},
 url = {https://proceedings.mlr.press/v53/fan16.html},
 volume = {53},
 year = {2016}
}

@inproceedings{pmlr-v53-kader16,
 abstract = {Distributed representations of textual elements in low dimensional vector space to  capture context has gained great attention recently. Current state-of-the-art word embedding techniques compute distributed representations using co-occurrences of words within a  contextual window discounting the flexibility to incorporate other contextual phenomena like temporal, geographical, and topical contexts. In this paper, we present a flexible framework that has the ability to leverage temporal, geographical, and topical information of documents  along with the textual content to produce more effective vector representations of entities or words within a document collection. The framework first captures contextual  relationships between entities collected from different relevant documents and then leverages these relationships to produce inputs of a graph, or to train a neural network to produce vectors for the entities. Through a set of rigorous experiments we test the performance of our approach and results show that our proposed solution can produce more meaningful vectors than the state-of-the-art methods.},
 address = {San Francisco, California, USA},
 author = {Kader, Md Abdul and Boedihardjo, Arnold P. and Naim, Sheikh Motahar and Hossain, M. Shahriar},
 booktitle = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 editor = {Fan, Wei and Bifet, Albert and Read, Jesse and Yang, Qiang and Yu, Philip S.},
 month = {14 Aug},
 openalex = {W2583058142},
 pages = {35--50},
 pdf = {http://proceedings.mlr.press/v53/kader16.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Contextual Embedding for Distributed Representations of Entities in a Text Corpus},
 url = {https://proceedings.mlr.press/v53/kader16.html},
 volume = {53},
 year = {2016}
}

@inproceedings{pmlr-v53-ma16,
 abstract = {Look-alike audience extension is a practically effective way to customize high-performance audience in on-line advertising. With look-alike audience extension system, any advertiser can easily generate a set of customized audience by just providing a list of existing customers without knowing the detailed targetable attributes in a sophisticated advertising system. In this paper, we present our newly developed graph-based look-alike system in Yahoo! advertising platform which provides look-alike audiences for thousands of campaigns.  Extensive experiments have been conducted to compare our look-alike model with three other existing look-alike systems using billions of users and millions of user features. The experiment results show that our developed graph-based method with nearest-neighbor filtering outperforms other methods by more than 50% regarding conversion rate in app-install ad campaigns.},
 address = {San Francisco, California, USA},
 author = {Ma, Qiang and Wen, Musen and Xia, Zhen and Chen, Datong},
 booktitle = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 editor = {Fan, Wei and Bifet, Albert and Read, Jesse and Yang, Qiang and Yu, Philip S.},
 month = {14 Aug},
 openalex = {W2586801569},
 pages = {51--67},
 pdf = {http://proceedings.mlr.press/v53/ma16.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {A Sub-linear, Massive-scale Look-alike Audience Extension System A Massive-scale Look-alike Audience Extension},
 url = {https://proceedings.mlr.press/v53/ma16.html},
 volume = {53},
 year = {2016}
}

@inproceedings{pmlr-v53-rabieah16,
 abstract = {Support Vector Machines (SVM) are powerful supervised learnings method in machine learning. However, their applicability to large problems, where frequent retraining of the system is required, has been limited due to the time consuming training stage whose  computational cost scales quadratically with the number of examples. In this work, a complete FPGA-based system for kernelized SVM training using ensemble learning is presented. The proposed framework builds on the FPGA architecture and utilises a cascaded  multiprecision training flow, exploits the heterogeneity within the training problem by tuning the number representation used, and supports ensemble training tuned to each internal memory structure so to address very large datasets. Its performance evaluation shows that the proposed system achieves more than an order of magnitude better results  compared to state-of-the-art CPU and GPU-based implementations, providing a stepping stone for researchers and practitioners to tackle large-scale SVM problems that require frequent retraining.},
 address = {San Francisco, California, USA},
 author = {Bin Rabieah, Mudhar and Bouganis, Christos-Savvas},
 booktitle = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 editor = {Fan, Wei and Bifet, Albert and Read, Jesse and Yang, Qiang and Yu, Philip S.},
 month = {14 Aug},
 openalex = {W2587280020},
 pages = {68--84},
 pdf = {http://proceedings.mlr.press/v53/rabieah16.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {FPGASVM: A Framework for Accelerating Kernelized Support Vector Machine},
 url = {https://proceedings.mlr.press/v53/rabieah16.html},
 volume = {53},
 year = {2016}
}

@inproceedings{pmlr-v53-shah16,
 abstract = {The CDC (Centers for Disease Control and Prevention) currently diagnoses millions of cases of infectious diseases annually, generating population disease distributions that, while accurate, are far too delayed for real-time monitoring. The ability to instantly compile and monitor such distributions is critical in identifying outbreaks and facilitating real-time communication between health authorities and health-care providers. This task, however, is made challenging due to the lack of instantly available public health information, creating a need for the analysis of disease spread on frequently updated social media websites. We introduce a novel pipeline based model to generate a real-time, accurate depiction of infectious disease propagation using Twitter data. Our approach, an amalgam of natural language processing and supervised machine learning, is invariant to mass media hype and significantly reduces the noise introduced by the use of tweets. The correlation coefficient between the Twitter disease distribution obtained via our approach and CDC data from mid-2013 to mid-2014 was 0.983, improving upon the best model published for the 2012-13 flu season. Our model further correlates well with theoretical models of infection spread across airport networks, verifying its robustness and applicability in the public sphere.},
 address = {San Francisco, California, USA},
 author = {Shah, Manan},
 booktitle = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 editor = {Fan, Wei and Bifet, Albert and Read, Jesse and Yang, Qiang and Yu, Philip S.},
 month = {14 Aug},
 openalex = {W2588917861},
 pages = {85--102},
 pdf = {http://proceedings.mlr.press/v53/shah16.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Disease Propagation in Social Networks: A Novel Study of Infection Genesis and Spread on Twitter},
 url = {https://proceedings.mlr.press/v53/shah16.html},
 volume = {53},
 year = {2016}
}

@inproceedings{pmlr-v53-yang16,
 abstract = {This paper presents a combination of strategies for conversion rate (CVR) prediction de- ployed at the Yahoo! demand side platform (DSP) Brightroll, targeting at modeling  extremely high dimensional, sparse data with limited human intervention. We propose a novel probabilistic generative model by tightly integrating components of natural language processing, dynamic transfer learning and scalable prediction, named Dynamic Transfer Learning with Reinforced Word Modeling (a.k.a. Trans-RWM ) to predict user  conversion rates. Our model is based on assumptions that: on a higher level, information can be transferable between related campaigns; on a lower level, users who searched similar contents or browsed similar pages would have a higher probability of sharing similar latent purchase interests. Novelties of this framework include (i) A novel natural language modeling specifically tailored for semantic inputs of CVR prediction; (ii) A Bayesian transfer learning model to dynamically transfer the knowledge from source to the future target; (iii) An automatic new updating rule with adaptive regularization using Stochastic  Gradient Monte Carlo to support the efficient updating of Trans-RWM in high-dimensional and sparse data. We demonstrate that on Brightroll our framework can effectively discriminate extremely rare events in terms of their conversion propensity.},
 address = {San Francisco, California, USA},
 author = {Yang, Hongxia and Lu, Quan and Xianen Qiu, Angus and Han, Chun},
 booktitle = {Proceedings of the 5th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications at KDD 2016},
 editor = {Fan, Wei and Bifet, Albert and Read, Jesse and Yang, Qiang and Yu, Philip S.},
 month = {14 Aug},
 openalex = {W2586345506},
 pages = {103--119},
 pdf = {http://proceedings.mlr.press/v53/yang16.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Large Scale CVR Prediction through Dynamic Transfer Learning of Global and Local Features},
 url = {https://proceedings.mlr.press/v53/yang16.html},
 volume = {53},
 year = {2016}
}
