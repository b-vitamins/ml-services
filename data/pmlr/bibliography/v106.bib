
@Proceedings{MLHC2019,
  title =     {Proceedings of the 4th Machine Learning for Healthcare Conference},
  booktitle = {Proceedings of the 4th Machine Learning for Healthcare Conference},
  editor =    {Finale Doshi-Velez and Jim Fackler and Ken Jung and David Kale and Rajesh Ranganath and Byron Wallace and Jenna Wiens},
  publisher = {PMLR},
  series =    {Proceedings of Machine Learning Research},
  volume =    106
}
@InProceedings{pmlr-v106-moor19a,
  title = 	 {Early Recognition of Sepsis with Gaussian Process Temporal Convolutional Networks and Dynamic Time Warping},
  author =       {Moor, Michael and Horn, Max and Rieck, Bastian and Roqueiro, Damian and Borgwardt, Karsten},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {2--26},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/moor19a/moor19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/moor19a.html},
  abstract = 	 {Sepsis is a life-threatening host response to infection that is associated with high mortality, morbidity, and health costs. Its management is highly time-sensitive because each hour of delayed treatment increases mortality due to irreversible organ damage. Meanwhile, despite decades of clinical research, robust biomarkers for sepsis are missing. Therefore, detecting sepsis early by utilizing the affluence of high-resolution intensive care records has become a challenging machine learning problem. Recent advances in deep learning and data mining promise to deliver a powerful set of tools to efficiently address this task. This empirical study proposes two novel approaches for the early detection of sepsis: a deep learning model and a lazy learner that is based on time series distances. Our deep learning model employs a temporal convolutional network that is embedded in a multi-task Gaussian Process adapter framework, making it directly applicable to irregularly-spaced time series data. In contrast, our lazy learner is an ensemble approach that employs dynamic time warping. We frame the timely detection of sepsis as a supervised time series classification task. Consequently, we derive the most recent sepsis definition in an hourly resolution to provide the first fully accessible early sepsis detection environment. Seven hours before sepsis onset, our methods improve area under the precisionârecall curve from 0.25 to 0.35 and 0.40, respectively, over the state of the art. This demonstrates that they are well-suited for detecting sepsis in the crucial earlier stages when management is most effective.}
}
@InProceedings{pmlr-v106-oh19a,
  title = 	 {Relaxed Parameter Sharing: Effectively Modeling Time-Varying Relationships in Clinical Time-Series},
  author =       {Oh, Jeeheh and Wang, Jiaxuan and Tang, Shengpu and Sjoding, Michael W. and Wiens, Jenna},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {27--52},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/oh19a/oh19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/oh19a.html},
  abstract = 	 {Recurrent neural networks (RNNs) are commonly applied to clinical time-series data with the goal of learning patient risk stratification models. Their effectiveness is due, in part, to their use of parameter sharing over time (i.e., cells are repeated hence the name recurrent ). We hypothesize, however, that this trait also contributes to the increased difficulty such models have with learning relationships that change over time. Conditional shift, i.e., changes in the relationship between the input X and the output y, arises when risk factors associated with the event of interest change over the course of a patient admission. While in theory, RNNs and gated RNNs (e.g., LSTMs) in particular should be capable of learning time-varying relationships, when training data are limited, such models often fail to accurately capture these dynamics. We illustrate the advantages and disadvantages of complete parameter sharing (RNNs) by comparing an LSTM with shared parameters to a sequential architecture with time-varying parameters on prediction tasks involving three clinically-relevant outcomes: acute respiratory failure (ARF), shock, and in-hospital mortality. In experiments using synthetic data, we demonstrate how parameter sharing in LSTMs leads to worse performance in the presence of conditional shift. To improve upon the dichotomy between complete parameter sharing and no parameter sharing, we propose a novel RNN formulation based on a mixture model in which we relax parameter sharing over time. The proposed method outperforms standard LSTMs and other state-of-the-art baselines across all tasks. In settings with limited data, relaxed parameter sharing can lead to improved patient risk stratification performance.}
}
@InProceedings{pmlr-v106-devarakonda19a,
  title = 	 {FLARe: Forecasting by Learning Anticipated Representations},
  author =       {Devarakonda, Surya Teja and Wu, Joie Yeahuay and Fung, Yi Ren and Fiterau, Madalina},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {53--65},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/devarakonda19a/devarakonda19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/devarakonda19a.html},
  abstract = 	 {Computational models that forecast the progression of Alzheimerâs disease at the patient level are extremely useful tools for identifying high risk cohorts for early intervention and treatment planning. The state-of-the-art work in this area proposes models that forecast by using latent representations extracted from the longitudinal data across multiple modalities, including volumetric information extracted from medical scans and demographic info. These models incorporate the time horizon, which is the amount of time between the last recorded visit and the future visit, by directly concatenating a representation of it to the latent data representation. In this paper, we present a model which generates a sequence of latent representations of the patient status across the time horizon, providing more informative modeling of the temporal relationships between the patientâs history and future visits. Our proposed model outperforms the baseline in terms of forecasting accuracy and F1 score.}
}
@InProceedings{pmlr-v106-urteaga19a,
  title = 	 {Multi-Task Gaussian Processes and Dilated Convolutional Networks for Reconstruction of Reproductive Hormonal Dynamics},
  author =       {Urteaga, I{\~{n}}igo and Bertin, Tristan and Hardy, Theresa M. and Albers, David J. and Elhadad, No{\'{e}}mie},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {66--90},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/urteaga19a/urteaga19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/urteaga19a.html},
  abstract = 	 {We present an end-to-end statistical framework for personalized, accurate, and minimally invasive modeling of female reproductive hormonal patterns. Reconstructing and forecasting the evolution of hormonal dynamics is a challenging task, but a critical one to improve general understanding of the menstrual cycle and personalized detection of potential health issues. Our goal is to infer and forecast individual hormone daily levels over time, while accommodating pragmatic and minimally invasive measurement settings. To that end, our approach combines the power of probabilistic generative models (i.e., multi-task Gaussian processes) with the flexibility of neural networks (i.e., a dilated convolutional architecture) to learn complex temporal mappings. To attain accurate hormone level reconstruction with as little data as possible, we propose a sampling mechanism for optimal reconstruction accuracy with limited sampling budget. Our results show the validity of our proposed hormonal dynamic modeling framework, as it provides accurate predictive performance across different realistic sampling budgets and outperforms baselines methods.}
}
@InProceedings{pmlr-v106-akbari19a,
  title = 	 {Using Contextual Information to Improve Blood Glucose Prediction},
  author =       {Akbari, Mohammad and Chunara, Rumi},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {91--108},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/akbari19a/akbari19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/akbari19a.html},
  abstract = 	 {Blood glucose value prediction is an important task in diabetes management. While it is reported that glucose concentration is sensitive to social context such as mood, physical activity, stress, diet, alongside the influence of diabetes pathologies, we need more research on data and methodologies to incorporate and evaluate signals about such temporal context into prediction models. Person-generated data sources, such as actively contributed surveys as well as passively mined data from social media offer opportunity to capture such context, however the self-reported nature and sparsity of such data mean that such data are noisier and less specific than physiological measures such as blood glucose values themselves. Therefore, here we propose a Gaussian Process model to both address these data challenges and combine blood glucose and latent feature representations of contextual data for a novel multi-signal blood glucose prediction task. We find this approach outperforms common methods for multi-variate data, as well as using the blood glucose values in isolation. Given a robust evaluation across two blood glucose datasets with different forms of contextual information, we conclude that multi-signal Gaussian Processes can improve blood glucose prediction by using contextual information and may provide a significant shift in blood glucose prediction research and practice.}
}
@InProceedings{pmlr-v106-nagpal19a,
  title = 	 {Dynamically Personalized Detection of Hemorrhage},
  author =       {Nagpal, Chirag and Li, Xinyu and Pinsky, Michael R. and Dubrawski, Artur},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {109--123},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/nagpal19a/nagpal19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/nagpal19a.html},
  abstract = 	 {Rapid detection of hemorrhage is of major interest to the critical care community, enabling clinicians to take swift actions to mitigate adverse outcomes. In this paper, we describe a model that allows rapid detection of the onset of hemorrhage by monitoring the Central Venous Pressure (CVP). As opposed to prior work in the domain, our model does not rely on prior availability of a stable physiology of a patient as a baseline of reference, and it makes generative assumptions on the monitored vital sign. This allows for rapid on-the-fly personalization to a previously unseen patientâs physiology. This property makes the proposed approach particularly relevant to e.g. trauma care and other scenarios where reference hemodynamic data may not be readily available for any new patient. We compare our model against strong discriminative alternatives and demonstrate its potential utility through empirical evaluation.}
}
@InProceedings{pmlr-v106-shanmugam19a,
  title = 	 {Multiple Instance Learning for ECG Risk Stratification},
  author =       {Shanmugam, Divya and Blalock, Davis and Guttag, John},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {124--139},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/shanmugam19a/shanmugam19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/shanmugam19a.html},
  abstract = 	 {Patients who suffer an acute coronary syndrome are at elevated risk for adverse cardiovascular events such as myocardial infarction and cardiovascular death. Accurate assessment of this risk is crucial to their course of care. We focus on estimating a patientâs risk of cardiovascular death after an acute coronary syndrome based on a patientâs raw electrocardiogram (ECG) signal. Learning from this signal is challenging for two reasons: 1) positive examples signifying a downstream cardiovascular event are scarce, causing drastic class imbalance, and 2) each patientâs ECG signal consists of thousands of heartbeats, accompanied by a single label for the downstream outcome. Machine learning has been previously applied to this task, but most approaches rely on hand-crafted features and domain knowledge. We propose a method that learns a representation from the raw ECG signal by using a multiple instance learning framework. We present a learned risk score for cardiovascular death that outperforms existing risk metrics in predicting cardiovascular death within 30, 60, 90, and 365 days on a dataset of 5000 patients.}
}
@InProceedings{pmlr-v106-nagesh19a,
  title = 	 {A Spatiotemporal Approach to Predicting Glaucoma Progression Using a CT-HMM},
  author =       {Nagesh, Supriya and Moreno, Alexander and Ishikawa, Hiroshi and Wollstein, Gadi and Shuman, Joel S. and Rehg, James M.},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {140--159},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/nagesh19a/nagesh19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/nagesh19a.html},
  abstract = 	 {Glaucoma is the second leading global cause of blindness and its effects are irreversible, making early intervention crucial. The identification of glaucoma progression is therefore a challenging and important task. In this work, we model and predict longitudinal glaucoma measurements using an interpretable, discrete state space model. Two common glaucoma biomarkers are the retinal nerve fibre layer (RNFL) thickness and the visual eld index (VFI). Prior works have frequently used a scalar representation for RNFL, such as the average RNFL thickness, thereby discarding potentially-useful spatial information. We present a technique for incorporating spatiotemporal RNFL thickness measurements obtained from a sequence of OCT images into a longitudinal progression model. While these images capture the details of RNFL thickness, representing them for use in a longitudinal model poses two challenges: First, spatial changes in RNFL thickness must be encoded and organized into a temporal sequence in order to enable state space modeling. Second, a predictive model for forecasting the pattern of changes over time must be developed. We address these challenges through a novel approach to spatiotemporal progression analysis. We jointly model the change in RNFL with VFI using a CT-HMM and predict future measurements. We achieve a decrease in mean absolute error of 74% for spatial RNFL thickness encoding in comparison to prior work using the average RNFL thickness. This work will be useful for accurately predicting the spatial location and intensity of tissue degeneration. Appropriate intervention based on more accurate prediction can potentially help to improve the clinical care of glaucoma.}
}
@InProceedings{pmlr-v106-covert19a,
  title = 	 {Temporal Graph Convolutional Networks for Automatic Seizure Detection},
  author =       {Covert, Ian C. and Krishnan, Balu and Najm, Imad and Zhan, Jiening and Shore, Matthew and Hixson, John and Po, Ming Jack},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {160--180},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/covert19a/covert19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/covert19a.html},
  abstract = 	 {Seizure detection from EEGs is a challenging and time-consuming clinical problem that would benefit from the development of automated algorithms. EEGs can be viewed as structural time series, because they are multivariate time series where the placement of leads on a patientâs scalp provides prior information about the structure of interactions. Commonly used deep learning models for time series do not offer a way to leverage structural information, but this would be desirable in a model for structural time series. To address this challenge, we propose the temporal graph convolutional network (TGCN), a model that leverages temporal and structural information and has relatively few parameters. TGCN applies feature extraction operations that are localized and shared over both time and space, thereby providing a useful inductive bias in tasks where similar features are expected to be discriminative across the different sequences. In our experiments we focus on metrics that are most important to seizure detection, and demonstrate that TGCN matches the performance of related models that have been shown to be state-of-the-art in other tasks. Additionally, we investigate interpretability advantages of TGCN by exploring approaches for helping clinicians determine when precisely seizures occur, and the parts of the brain that are most involved.}
}
@InProceedings{pmlr-v106-rudovic19a,
  title = 	 {Meta-Weighted Gaussian Process Experts for Personalized Forecasting of AD Cognitive Changes},
  author =       {Rudovic, Ognjen (Oggi) and Utsumi, Yuria and Guerrero, Ricardo and Peterson, Kelly and Rueckert, Daniel and Picard, Rosalind W.},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {181--196},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/rudovic19a/rudovic19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/rudovic19a.html},
  abstract = 	 {We introduce a novel personalized Gaussian Process Experts (pGPE) model for predicting per-subject ADAS-Cog13 cognitive scores â a significant predictor of Alzheimerâs Disease (AD) in the cognitive domain â over the future 6, 12, 18, and 24 months. We start by training a population-level model using multi-modal data from previously seen subjects using a base Gaussian Process (GP) regression. Then, we personalize this model by adapting the base GP sequentially over time to a new (target) subject using domain adaptive GPs, and also by training subject-specific GP. While we show that these models achieve improved performance when selectively applied to the forecasting task (one performs better than the other on different subjects/visits), the average performance per model is suboptimal. To this end, we used the notion of meta learning in the proposed pGPE to design a regression-based weighting of these expert models, where the expert weights are optimized for each subject and his/her future visit. The results on a cohort of subjects from the ADNI dataset show that this newly introduced personalized weighting of the expert models leads to large improvements in accurately forecasting future ADAS-Cog13 scores and their fine-grained changes associated with the AD progression. This approach has potential to help identify at-risk patients early and improve the construction of clinical trials for AD.}
}
@InProceedings{pmlr-v106-xu19a,
  title = 	 {Multimodal Machine Learning for Automated ICD Coding},
  author =       {Xu, Keyang and Lam, Mike and Pang, Jingzhi and Gao, Xin and Band, Charlotte and Mathur, Piyush and Papay, Frank and Khanna, Ashish K. and Cywinski, Jacek B. and Maheshwari, Kamal and Xie, Pengtao and Xing, Eric P.},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {197--215},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/xu19a/xu19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/xu19a.html},
  abstract = 	 {This study presents a multimodal machine learning model to predict ICD-10 diagnostic codes. We developed separate machine learning models that can handle data from different modalities, including unstructured text, semi-structured text and structured tabular data. We further employed an ensemble method to integrate all modality-specific models to generate ICD codes. Key evidence was also extracted to make our prediction more convincing and explainable. We used the Medical Information Mart for Intensive Care III (MIMIC-III) dataset to validate our approach. For ICD code prediction, our best-performing model (micro-F1 = 0.7633, micro-AUC = 0.9541) significantly outperforms other baseline models including TF-IDF (micro-F1 = 0.6721, micro-AUC = 0.7879) and Text-CNN model (micro-F1 = 0.6569, micro-AUC = 0.9235). For interpretability, our approach achieves a Jaccard Similarity Coecient (JSC) of 0.1806 on text data and 0.3105 on tabular data, where well-trained physicians achieve 0.2780 and 0.5002 respectively.}
}
@InProceedings{pmlr-v106-rawat19a,
  title = 	 {Clinical Judgement Study using Question Answering from Electronic Health Records},
  author =       {Rawat, Bhanu Pratap Singh and Li, Fe and Yu, Hong},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {216--229},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/rawat19a/rawat19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/rawat19a.html},
  abstract = 	 {Clinical judgement studies are essential for recognising the causal relation of a medication with adverse drug reactions (ADRs). Traditionally, these studies are conducted via expert manual chart review. By contrast, we propose an end-to-end deep learning question answering model to automatically infer such causal relations. Our proposed model identifies the causal relation by answering a subset of Naranjo questionnaire Naranjo et al. (1981) from electronic health records. It employs multi-level attention layers along with local and global context while answering these questions. Our proposed model achieves a macro-weighted F-score of 0.4598 - 0.5142 across the selected questions and an overall F-score of 0.5011. We also did an ablation study to validate the importance of local and global context for the model.}
}
@InProceedings{pmlr-v106-shin19a,
  title = 	 {Self-Attention Based Molecule Representation for Predicting Drug-Target Interaction},
  author =       {Shin, Bonggun and Park, Sungsoo and Kang, Keunsoo and Ho, Joyce C.},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {230--248},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/shin19a/shin19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/shin19a.html},
  abstract = 	 {Predicting drug-target interactions (DTI) is an essential part of the drug discovery process, which is an expensive process in terms of time and cost. Therefore, reducing DTI cost could lead to reduced healthcare costs for a patient. In addition, a precisely learned molecule representation in a DTI model could contribute to developing personalized medicine, which will help many patient cohorts. In this paper, we propose a new molecule representation based on the self-attention mechanism, and a new DTI model using our molecule representation. The experiments show that our DTI model outperforms the state of the art by up to 4.9% points in terms of area under the precision-recall curve. Moreover, a study using the DrugBank database proves that our model effectively lists all known drugs targeting a specific cancer biomarker in the top-30 candidate list.}
}
@InProceedings{pmlr-v106-liu19a,
  title = 	 {Clinically Accurate Chest X-Ray Report Generation},
  author =       {Liu, Guanxiong and Hsu, Tzu-Ming Harry and McDermott, Matthew and Boag, Willie and Weng, Wei-Hung and Szolovits, Peter and Ghassemi, Marzyeh},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {249--269},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/liu19a/liu19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/liu19a.html},
  abstract = 	 {The automatic generation of radiology reports given medical radiographs has significant potential to operationally and improve clinical patient care. A number of prior works have focused on this problem, employing advanced methods from computer vision and natural language generation to produce readable reports. However, these works often fail to account for the particular nuances of the radiology domain, and, in particular, the critical importance of clinical accuracy in the resulting generated reports. In this work, we present a domain-aware automatic chest X-ray radiology report generation system which first predicts what topics will be discussed in the report, then conditionally generates sentences corresponding to these topics. The resulting system is fine-tuned using reinforcement learning, considering both readability and clinical accuracy, as assessed by the proposed Clinically Coherent Reward. We verify this system on two datasets, Open-I and MIMICCXR, and demonstrate that our model offers marked improvements on both language generation metrics and CheXpert assessed accuracy over a variety of competitive baselines.}
}
@InProceedings{pmlr-v106-kong19a,
  title = 	 {A Neural Model for Predicting Dementia from Language},
  author =       {Kong, Weirui and Jang, Hyeju and Carenini, Giuseppe and Field, Thalia},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {270--286},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/kong19a/kong19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/kong19a.html},
  abstract = 	 {Early prediction of neurodegenerative disorders such as Alzheimerâs disease (AD) and related dementias is important in developing early medical supports and social supports, and may identify ideal stages for testing novel therapeutics aimed at preventing disease progression. Currently, a diagnosis is based on clinical expertise and cognitive screening tests, which have limited accuracy in earlier stages of disease, or invasive and resource-intensive testing, such as lumbar puncture or specialized neuroimaging. Changes in speech and language patterns can occur in dementia in its earliest stages and may worsen as the disease progresses. This has led to recent attempts to create automatic methods that predict dementia through language analysis. In addition to features extracted from language samples, previous works have improved the prediction accuracy by introducing some task-specific features. But task-specific features prevent the model from generalizing to other tests. In this paper, we apply a neural model (Hierarchical Attention Networks) to the dementia prediction task. Remarkably, the model requires no task-specific feature and achieves state-of-the-art classification result on a widely used dementia dataset of spoken language. We also perform a detail analysis to interpret how a prediction is made. Interestingly, the same neural model does not work well on a corpus of written text, suggesting that dementia prediction from language may require different methods depending on the genre of the source language.}
}
@InProceedings{pmlr-v106-guan19a,
  title = 	 {Predicting Sick Patient Volume in a Pediatric Outpatient Setting using Time Series Analysis},
  author =       {Guan, Grace and Engelhardt, Barbara E.},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {271--287},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/guan19a/guan19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/guan19a.html},
  abstract = 	 {Reducing patientsâ medical wait times by improving resource and staffing allocation is an important area of focus in hospital operations management. Two ways to decrease wait times are to adjust staffing or to limit the number of non-urgent visits to reflect a predicted volume of sick patients. Currently, this problem has been approached by both generalized linear models and time series models, and has mainly been researched in the context of adult emergency departments. We analyze sick visit data over a nine year period from one pediatric group (PG) that serves over 30,000 sick infants, children, and adolescents yearly in a walk-in and appointment-based out-patient clinic. The PG currently schedules staff and well-child appointments assuming a constant number of sick visits daily despite weekly and seasonal cycles in the data. We develop time series models to estimate the volume of sick patients that the PG can expect on any given day, so that clinicians can be allocated and the number of well-child appointments scheduled in advance can be adjusted according to predictions. First, we find that recurrent neural network (RNN) models are able to capture the seasonality of the data and perform substantially better than state-of-the-art models, including constant predictions. Next, we find that previous daysâ data can be used to perform outbreak detection by identifying error outliers. Lastly, we find improvements in prediction when modeling sick patients as a mixture of disease types, because disease types are concentrated differently throughout the year. Resource allocation based on these findings can be expanded upon to reduce wait time by improving staffing at pediatric emergency departments and outpatient clinics.}
}
@InProceedings{pmlr-v106-qi19a,
  title = 	 {Predicting Phase 3 Clinical Trial Results by Modeling Phase 2 Clinical Trial Subject Level Data Using Deep Learning},
  author =       {Qi, Youran and Tang, Qi},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {288--303},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/qi19a/qi19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/qi19a.html},
  abstract = 	 {Predicting Phase 3 clinical trial results is a critical step of Go/No-Go decision making and Phase 3 trial design optimization. To predict the overall treatment effect for patients enrolled into a Phase 3 trial, we propose a framework consisting of two models. First, an individual trough pharmacokinetic concentration (Ctrough) model is developed to predict the trough pharmacokinetic concentration for a potentially new treatment regime planned for Phase 3. Second, an individual treatment effect model is built to model the relationship between patient baseline characteristics, Ctrough and clinical outcomes. These two models are combined together to predict Phase 3 clinical trial results. Since the clinical outcomes to be predicted are longitudinal and the predictors are a mix of time-invariant and time-variant variables, a novel neural network, Residual Semi-Recurrent Neural Network, is developed for both models. The proposed framework is applied in a post-hoc prediction of Phase 3 clinical trial results, and it outperforms the traditional method.}
}
@InProceedings{pmlr-v106-rodriguez19a,
  title = 	 {Phenotype Inference with Semi-Supervised Mixed Membership Models},
  author =       {Rodriguez, Victor A. and Perotte, Adler},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {304--324},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/rodriguez19a/rodriguez19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/rodriguez19a.html},
  abstract = 	 {Disease phenotyping algorithms are designed to sift through clinical data stores to identify patients with specific diseases. Supervised phenotyping methods require significant quantities of expert-labeled data, while unsupervised methods may learn spurious or non-disease phenotypes. To address these limitations, we propose the Semi-Supervised Mixed Membership Model (SS3M) a probabilistic graphical model for learning disease phenotypes from partially labeled clinical data. We show SS3M can generate interpretable, disease-specific phenotypes which capture the clinical features of the disease concepts specified by the labels provided to the model. Furthermore, SS3M phenotypes demonstrate competitive predictive performance relative to commonly used baselines.}
}
@InProceedings{pmlr-v106-pfohl19a,
  title = 	 {Counterfactual Reasoning for Fair Clinical Risk Prediction},
  author =       {Pfohl, Stephen R. and Duan, Tony and Ding, Daisy Yi and Shah, Nigam H.},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {325--358},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/pfohl19a/pfohl19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/pfohl19a.html},
  abstract = 	 {The use of machine learning systems to support decision making in healthcare raises questions as to what extent these systems may introduce or exacerbate disparities in care for historically underrepresented and mistreated groups, due to biases implicitly embedded in observational data in electronic health records. To address this problem in the context of clinical risk prediction models, we develop an augmented counterfactual fairness criteria that extends the group fairness criteria of equalized odds. We do so by requiring that the same prediction be made for a patient, and a counterfactual patient resulting from changing a sensitive attribute, if the factual and counterfactual outcomes do not differ. We investigate the extent to which the augmented counterfactual fairness criteria may be applied to develop fair models for prolonged inpatient length of stay and mortality with observational electronic health records data. As the fairness criteria is ill-defined without knowledge of the data generating process, we use a variational autoencoder to perform counterfactual inference in the context of an assumed causal graph. While our technique provides a means to trade off maintenance of fairness with reduction in predictive performance in the context of a learned generative model, further work is needed to assess the generality of this approach.}
}
@InProceedings{pmlr-v106-tonekaboni19a,
  title = 	 {What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use},
  author =       {Tonekaboni, Sana and Joshi, Shalmali and McCradden, Melissa D. and Goldenberg, Anna},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {359--380},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/tonekaboni19a/tonekaboni19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/tonekaboni19a.html},
  abstract = 	 {Translating machine learning (ML) models effectively to clinical practice requires establishing cliniciansâ trust. Explainability, or the ability of an ML model to justify its outcomes and assist clinicians in rationalizing the model prediction, has been generally understood to be critical to establishing trust. However, the eld suffers from the lack of concrete definitions for usable explanations in different settings. To identify specific aspects of explainability that may catalyze building trust in ML models, we surveyed clinicians from two distinct acute care specialties (Intenstive Care Unit and Emergency Department). We use their feedback to characterize when explainability helps to improve cliniciansâ trust in ML models. We further identify the classes of explanations that clinicians identified as most relevant and crucial for effective translation to clinical practice. Finally, we discern concrete metrics for rigorous evaluation of clinical explainability methods. By integrating perceptions of explainability between clinicians and ML researchers we hope to facilitate the endorsement and broader adoption and sustained use of ML systems in healthcare.}
}
@InProceedings{pmlr-v106-nestor19a,
  title = 	 {Feature Robustness in Non-stationary Health Records: Caveats to Deployable Model Performance in Common Clinical Machine Learning Tasks},
  author =       {Nestor, Bret and McDermott, Matthew B. A. and Boag, Willie and Berner, Gabriela and Naumann, Tristan and Hughes, Michael C. and Goldenberg, Anna and Ghassemi, Marzyeh},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {381--405},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/nestor19a/nestor19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/nestor19a.html},
  abstract = 	 {When training clinical prediction models from electronic health records (EHRs), a key concern should be a modelâs ability to sustain performance over time when deployed, even as care practices, database systems, and population demographics evolve. Due to de-identification requirements, however, current experimental practices for public EHR benchmarks (such as the MIMIC-III critical care dataset) are time agnostic, assigning care records to train or test sets without regard for the actual dates of care. As a result, current benchmarks cannot assess how well models trained on one year generalise to another. In this work, we obtain a Limited Data Use Agreement to access year of care for each record in MIMIC and show that all tested state-of-the-art models decay in prediction quality when trained on historical data and tested on future data, particularly in response to a system-wide record-keeping change in 2008 (0.29 drop in AUROC for mortality prediction, 0.10 drop in AUROC for length-of-stay prediction with a random forest classifier). We further develop a simple yet effective mitigation strategy: by aggregating raw features into expert-defined clinical concepts, we see only a 0.06 drop in AUROC for mortality prediction and a 0.03 drop in AUROC for length-of-stay prediction. We demonstrate that this aggregation strategy outperforms other automatic feature preprocessing techniques aimed at increasing robustness to data drift. We release our aggregated representations and code1 to encourage more deployable clinical prediction models.}
}
@InProceedings{pmlr-v106-thawani19a,
  title = 	 {Are Online Reviews of Physicians Biased Against Female Providers?},
  author =       {Thawani, Avijit and Paul, Michael J. and Sarkar, Urmimala and Wallace, Byron C.},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {406--423},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/thawani19a/thawani19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/thawani19a.html},
  abstract = 	 {Patients increasingly seek out information regarding their healthcare online. Online reviews of caregivers in particular may influence from whom patients seek treatment. Are these sources biased against female providers? To address this question we analyze a new dataset of online patient reviews of male and female healthcare providers with respect to numerical ratings and language use. We perform both regression and (data-driven) qualitative analyses of language via neural embedding models induced over review texts. In both cases we account for provider specialty. To do so while learning embeddings, we explicitly induce specialty, sex, and rating embeddings from review meta-data via a âmatched-samplingâ training regime. We find that females consistently receive less favorable numerical ratings overall, even after adjusting for specialty. To analyze language use in reviews of male versus female providers, we induce neural embeddings (distributed representations) of gender and qualitatively characterize the âdistributional semanticsâ that this induces. We observe differences in language use, e.g., analysis of average vector similarities over repeated runs reveal that many of the words closest to the coordinates in embedding space associated with positive sentiment and female providers describe interpersonal characteristics (sweet , considerate , caring , personable , compassionate ): such descriptors do not seem as similar to the point corresponding to positive sentiment regarding male providers. To facilitate research in this direction we publicly release data, embeddings, and all code (including Jupyter notebooks) to reproduce our analyses and further explore the data: https://github.com/avi-jit/RateMDs.}
}
@InProceedings{pmlr-v106-yadlowsky19a,
  title = 	 {A Calibration Metric for Risk Scores with Survival Data},
  author =       {Yadlowsky, Steve and Basu, Sanjay and Tian, Lu},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {424--450},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/yadlowsky19a/yadlowsky19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/yadlowsky19a.html},
  abstract = 	 {We study methods for assessing the degree of systematic over- or under- estimation, known as calibration, of a learned risk model in an independent validation cohort. Here, we advance methods for evaluating clinical risk prediction models by deriving a population parameter measuring the average calibration error of the predicted risk from the true risk, and providing a method for estimation and inference. Our approach improves upon commonly-used goodness of fit tests that depends on subjective bin thresholding and may yield misleading results by reporting confidence intervals for the calibration error instead of a simple P-value that conflate calibration error and sample size. This approach enables comparison among multiple risk prediction models, and can guide model revision. We illustrate how our new method helps to understand the calibration of risk models that have been profoundly influential in clinical practice, but controversial due to their potential miscalibration.}
}
@InProceedings{pmlr-v106-yoon19a,
  title = 	 {ASAC: Active Sensing using Actor-Critic models},
  author =       {Yoon, Jinsung and Jordon, James and van der Schaar, Mihaela},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {451--473},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/yoon19a/yoon19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/yoon19a.html},
  abstract = 	 {Deciding what and when to observe is critical when making observations is costly. In a medical setting where observations can be made sequentially , making these observations (or not) should be an active choice. We refer to this as the active sensing problem. In this paper, we propose a novel deep learning framework, which we call ASAC (Active Sensing using Actor-Critic models) to address this problem. ASAC consists of two networks: a selector network and a predictor network. The selector network uses previously selected observations to determine what should be observed in the future. The predictor network uses the observations selected by the selector network to predict a label, providing feedback to the selector network (well-selected variables should be predictive of the label). The goal of the selector network is then to select variables that balance the cost of observing the selected variables with their predictive power; we wish to preserve the conditional label distribution. During training, we use the actor-critic models to allow the loss of the selector to be âback-propagated" through the sampling process. The selector network âacts" by selecting future observations to make. The predictor network acts as a âcritic" by feeding predictive errors for the selected variables back to the selector network. In our experiments, we show that ASAC significantly outperforms state-of-the-arts in two real-world medical datasets.}
}
@InProceedings{pmlr-v106-zheng19a,
  title = 	 {Using Domain Knowledge to Overcome Latent Variables in Causal Inference from Time Series},
  author =       {Zheng, Min and Kleinberg, Samantha},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {474--489},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/zheng19a/zheng19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/zheng19a.html},
  abstract = 	 {Increasingly large observational datasets from healthcare and social media may allow new types of causal inference. However, these data are often missing key variables, increasing the chance of finding spurious causal relationships due to confounding. While methods exist for causal inference with latent variables in static cases, temporal relationships are more challenging, as varying time lags make latent causes more difficult to uncover and approaches often have significantly higher computational complexity. To address this, we make the key observation that while a variable may be latent in one dataset, it may be observed in another, or we may have domain knowledge about its effects. We propose a computationally efficient method that overcomes latent variables by using prior knowledge to reconstruct data for unobserved variables, while remaining robust to cases when the knowledge is wrong or does not apply. On simulated data, our approach outperforms the state of the art with a lower false discovery rate for causal inference. On real-world data from individuals with Type 1 diabetes, we show that our approach can discover causal relationships involving unmeasured meals and exercise.}
}
@InProceedings{pmlr-v106-zhang19a,
  title = 	 {The Medical Deconfounder: Assessing Treatment Effects with Electronic Health Records},
  author =       {Zhang, Linying and Wang, Yixin and Ostropolets, Anna and Mulgrave, Jami J. and Blei, David M. and Hripcsak, George},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {490--512},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/zhang19a/zhang19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/zhang19a.html},
  abstract = 	 {The treatment effects of medications play a key role in guiding medical prescriptions. They are usually assessed with randomized controlled trials (RCTs), which are expensive. Recently, large-scale electronic health records (EHRs) have become available, opening up new opportunities for more cost-effective assessments. However, assessing a treatment effect from EHRs is challenging: it is biased by unobserved confounders , unmeasured variables that affect both patientsâ medical prescription and their outcome, e.g. the patientsâ social economic status. To adjust for unobserved confounders, we develop the medical deconfounder , a machine learning algorithm that unbiasedly estimates treatment effects from EHRs. The medical deconfounder first constructs a substitute confounder by modeling which medications were prescribed to each patient; this substitute confounder is guaranteed to capture all multi-medication confounders, observed or unobserved (Wang and Blei , 2018 ). It then uses this substitute confounder to adjust for the confounding bias in the analysis. We validate the medical deconfounder on two simulated and two real medical data sets. Compared to classical approaches, the medical deconfounder produces closer-to-truth treatment effect estimates; it also identifies effective medications that are more consistent with the findings in the medical literature.}
}
@InProceedings{pmlr-v106-biswal19a,
  title = 	 {EEGtoText: Learning to Write Medical Reports from EEG Recordings},
  author =       {Biswal, Siddharth and Xiao, Cao and Westover, M. Brandon and Sun, Jimeng},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {513--531},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/biswal19a/biswal19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/biswal19a.html},
  abstract = 	 {Electroencephalography (EEG) is widely used in hospitals and clinics for the diagnosis of many neurological conditions. Such diagnoses require accurate and timely clinical reports to summarize the findings from raw EEG data. In this paper, we investigate whether it is possible to automatically generate text reports directly from EEG data. To address the challenges, we proposed EEGtoText , which first extracted shift invariant and temporal patterns using stacked convolutional neural networks and recurrent neural networks (RCNN). These temporal patterns are used to classify key phenotypes including EEG normality, sleep, generalized and focal slowing, epileptiform discharges, spindles, vertex waves and seizures. Based on these phenotypes, the impression section of the EEG report is generated. Next, we adopted a hierarchical long short-term memory network(LSTM) that comprises of paragraph-level and sentence-level LSTMs to generate the detail explanation of the impression. Within the hierarchical LSTM, we used an attention module to localize the abnormal areas in the EEG which provide another explanation and justification of the extracted phenotypes. We conducted large-scale evaluations on two different EEG datasets Dataset1 (n=12,980) and TUH (n=16,950). We achieved an area under the ROC curve (AUC) between .658 to .915 on phenotype classification, which is significantly higher than CRNN and RCNN with attention. We also conducted a quantitative evaluation of the detailed explanation, which achieved METEOR score .371 and BLEU score 4.583. Finally, our initial clinical reviews confirmed the effectiveness of the generated reports.}
}
@InProceedings{pmlr-v106-prabhu19a,
  title = 	 {Few-Shot Learning for Dermatological Disease Diagnosis},
  author =       {Prabhu, Viraj and Kannan, Anitha and Ravuri, Murali and Chaplain, Manish and Sontag, David and Amatriain, Xavier},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {532--552},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/prabhu19a/prabhu19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/prabhu19a.html},
  abstract = 	 {We consider the problem of clinical image classification for the purpose of aiding doctors in dermatological disease diagnosis. Diagnosis of dermatological conditions from images poses two major challenges for standard off-the-shelf techniques: First, the distribution of real-world dermatological datasets is typically long-tailed. Second, intra-class variability is large. To address the first issue, we formulate the problem as low-shot learning, where once deployed, a base classifier must rapidly generalize to diagnose novel conditions given very few labeled examples. To model intra-class variability effectively, we propose Prototypical Clustering Networks (PCN), an extension to Prototypical Networks (Snell et al. , 2017 ) that learns a mixture of âprototypesâ for each class. Prototypes are initialized for each class via clustering and refined via an online update scheme. Classification is performed by measuring similarity to a weighted combination of prototypes within a class, where the weights are the inferred cluster responsibilities. We demonstrate the strengths of our approach in effective diagnosis on a realistic dataset of dermatological conditions.}
}
@InProceedings{pmlr-v106-dov19a,
  title = 	 {Thyroid Cancer Malignancy Prediction From Whole Slide Cytopathology Images},
  author =       {Dov, David and Kovalsky, Shahar Z. and Cohen, Jonathan and Range, Danielle Elliott and Henao, Ricardo and Carin, Lawrence},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {553--570},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/dov19a/dov19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/dov19a.html},
  abstract = 	 {We consider preoperative prediction of thyroid cancer based on ultra-high-resolution whole-slide cytopathology images. Inspired by how human experts perform diagnosis, our approach first identifies and classifies diagnostic image regions containing informative thyroid cells, which only comprise a tiny fraction of the entire image. These local estimates are then aggregated into a single prediction of thyroid malignancy. Several unique characteristics of thyroid cytopathology guide our deep-learning-based approach. While our method is closely related to multiple-instance learning, it deviates from these methods by using a supervised procedure to extract diagnostically relevant regions. Moreover, we propose to simultaneously predict thyroid malignancy, as well as a diagnostic score assigned by a human expert, which further allows us to devise an improved training strategy. Experimental results show that the proposed algorithm achieves performance comparable to human experts, and demonstrate the potential of using the algorithm for screening and as an assistive tool for the improved diagnosis of indeterminate cases.}
}
@InProceedings{pmlr-v106-kyono19a,
  title = 	 {Multi-view Multi-task Learning for Improving Autonomous Mammogram Diagnosis},
  author =       {Kyono, Trent and Gilbert, Fiona J. and van der Schaar, Mihaela},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {571--591},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/kyono19a/kyono19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/kyono19a.html},
  abstract = 	 {The number of women requiring screening and diagnostic mammography is increasing. The recent promise of machine learning on medical images have led to an influx of studies using deep learning for autonomous mammogram diagnosis. We present a novel multi-view multi-task (MVMT) convolutional neural network (CNN) trained to predict the radiological assessments known to be associated with cancer, such as breast density, conspicuity, etc., in addition to cancer diagnosis. We show on full-eld mammograms that multi-task learning has three advantages: 1) learning refined feature representations associated with cancer improves the classification performance of the diagnosis task, 2) issuing radiological assessments provides an additional layer of model interpretability that a radiologist can use to debug and scrutinize the diagnoses provided by the CNN, and 3) improves the radiological workflow by providing automated annotation of radiological reports. Results obtained on a private dataset of over 7,000 patients show that our MVMT network attained an AUROC and AUPRC of 0.855 $\pm$ 0.021 and 0.646 $\pm$ 0.023, respectively, and improved on the performance of other state-of-the-art multi-view CNNs.}
}
@InProceedings{pmlr-v106-lee19a,
  title = 	 {Enhancing high-content imaging for studying microtubule networks at large-scale},
  author =       {Lee, Hao-Chih and Cherng, Sarah T. and Miotto, Riccardo and Dudley, Joel T.},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {592--613},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/lee19a/lee19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/lee19a.html},
  abstract = 	 {Given the crucial role of microtubules for cell survival, many researchers have found success using microtubule-targeting agents in the search for effective cancer therapeutics. Understanding microtubule responses to targeted interventions requires that the microtubule network within cells can be consistently observed across a large sample of images. However, fluorescence noise sources captured simultaneously with biological signals while using wide-held microscopes can obfuscate fine microtubule structures. Such requirements are particularly challenging for high-throughput imaging, where researchers must make decisions related to the trade-off between imaging quality and speed. Here, we propose a computational framework to enhance the quality of high-throughput imaging data to achieve fast speed and high quality simultaneously. Using CycleGAN, we learn an image model from low-throughput, high-resolution images to enhance features, such as microtubule networks in high-throughput low-resolution images. We show that CycleGAN is effective in identifying microtubules with 0.93+ AUC-ROC and that these results are robust to different kinds of image noise. We further apply CycleGAN to quantify the changes in microtubule density as a result of the application of drug compounds, and show that the quantified responses correspond well with known drug effects.}
}
@InProceedings{pmlr-v106-hamesse19a,
  title = 	 {Simultaneous Measurement Imputation and Outcome Prediction for Achilles Tendon Rupture Rehabilitation},
  author =       {Hamesse, Charles and Tu, Ruibo and Ackermann, Paul and Kjellstr{\"{o}}m, Hedvig and Zhang, Cheng},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {614--640},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/hamesse19a/hamesse19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/hamesse19a.html},
  abstract = 	 {Achilles Tendon Rupture (ATR) is one of the typical soft tissue injuries. Rehabilitation after such a musculoskeletal injury remains a prolonged process with a very variable outcome. Accurately predicting rehabilitation outcome is crucial for treatment decision support. However, it is challenging to train an automatic method for predicting the ATR rehabilitation outcome from treatment data, due to a massive amount of missing entries in the data recorded from ATR patients, as well as complex nonlinear relations between measurements and outcomes. In this work, we design an end-to-end probabilistic framework to impute missing data entries and predict rehabilitation outcomes simultaneously. We evaluate our model on a real-life ATR clinical cohort, comparing with various baselines. The proposed method demonstrates its clear superiority over traditional methods which typically perform imputation and prediction in two separate stages.}
}
@InProceedings{pmlr-v106-mirtchouk19a,
  title = 	 {Automated Estimation of Food Type from Body-worn Audio and Motion Sensors in Free-Living Environments},
  author =       {Mirtchouk, Mark and McGuire, Dana L. and Deierlein, Andrea L. and Kleinberg, Samantha},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {641--662},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/mirtchouk19a/mirtchouk19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/mirtchouk19a.html},
  abstract = 	 {Nutrition is fundamental to maintaining health, managing chronic diseases, and preventing illness, but unlike physical activity there is not yet a way to unobtrusively and automatically measure nutrition. While recent work has shown that body-worn sensors can be used to identify meal times, to have an impact on health and fully replace manual food logs, we need to identify not only when someone is eating, but what they are consuming. However, it is challenging to collect labeled data in daily life, while lab data does not always generalize to reality. To address this, we develop new algorithms for semi-supervised hierarchical classification that enable higher accuracy when training on data with weak labels. Using this approach, we present the first results on automated classification of foods consumed in data collected from body-worn audio and motion sensors in free-living environments. We show that by exploiting a mix of lab and free-living data, we can achieve a classification accuracy of 88% on unrestricted meals (e.g. stir fry, pizza, salad) in unrestricted environments such as home and restaurants. Ultimately, this lays the foundation for body-worn devices that can calculate calories and macronutrients by identifying food type and quantity.}
}
@InProceedings{pmlr-v106-lau19a,
  title = 	 {Embryo Staging with Weakly-Supervised Region Selection and Dynamically-Decoded Predictions},
  author =       {Lau, Tingfung and Ng, Nathan and Gingold, Julian and Desai, Nina and McAuley, Julian and Lipton, Zachary C.},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {663--679},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/lau19a/lau19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/lau19a.html},
  abstract = 	 {To optimize clinical outcomes, fertility clinics must strategically select which embryos to transfer. Common selection heuristics are formulas expressed in terms of the durations required to reach various developmental milestones, quantities historically annotated manually by experienced embryologists based on time-lapse EmbryoScope videos. We propose a new method for automatic embryo staging that exploits several sources of structure in this time-lapse data. First, noting that in each image the embryo occupies a small subregion, we jointly train a region proposal network with the downstream classier to isolate the embryo. Notably, because we lack ground-truth bounding boxes, our we weakly supervise the region proposal network optimizing its parameters via reinforcement learning to improve the downstream classierâs loss. Moreover, noting that embryos reaching the blastocyst stage progress monotonically through earlier stages, we develop a dynamic-programming-based decoder that post-processes our predictions to select the most likely monotonic sequence of developmental stages. Our methods outperform vanilla residual networks and rival the best numbers in contemporary papers, as measured by both per-frame accuracy and transition prediction error, despite operating on smaller data than many.}
}
@InProceedings{pmlr-v106-kaul19a,
  title = 	 {Measuring the Sympathetic Response to Intense Exercise in a Practical Setting},
  author =       {Kaul, Shiva and Falco, Anthony and Anthes, Karianne},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {680--703},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/kaul19a/kaul19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/kaul19a.html},
  abstract = 	 {Brief, intense exercise can improve health due to its acute effect on the autonomic nervous system, particularly the sympathetic nervous system. Salivary amylase is a marker of sympathetic activity during exercise, but it requires specialized equipment to measure. We investigate the feasibility of estimating the amylase response from heartbeat data recorded by commodity sensors. We collect heartbeat and amylase data for n = 71 sessions of intense exercise performed in a commercial setting. Our machine learning model exploits structure in the heartbeat signal: by identifying and removing the contribution of the parasympathetic nervous system, we obtain a residual with sympathetic information, to which we apply a convolutional neural network. This model has better accuracy than existing measures of exercise response, such as maximum heart rate, even though it doesnât use metadata such as age and gender. This suggests sympathetic activity may be (weakly) discerned from heartbeat data. With a larger dataset, a practical measure of sympathetic response to exercise could potentially be developed. Our quantification of parasympathetic activity is more powerful than existing approaches and may have independent value.}
}
@InProceedings{pmlr-v106-ortiz19a,
  title = 	 {Learning from Few Subjects with Large Amounts of Voice Monitoring Data},
  author =       {Ortiz, Jose Javier Gonzalez and Mehta, Daryush D. and Van Stan, Jarrad H. and Hillman, Robert and Guttag, John V. and Ghassemi, Marzeyeh},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {704--720},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/ortiz19a/ortiz19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/ortiz19a.html},
  abstract = 	 {Recently, researchers have started training high complexity machine learning models to clinical tasks, often improving upon previous benchmarks. However, more often than not, these methods require large amounts of supervision to provide good generalization guarantees. When applied to data coming from small cohorts and long monitoring periods these models are prone to overt to subject-identifying features. Since obtaining large amounts of labels is usually not practical in many scenarios, expert-driven knowledge of the task is a common technique to prevent overfitting. We present a two-step learning approach that is able to generalize under these circumstances when applied to a voice monitoring dataset. Our approach decouples the feature learning stage and performs it in an unsupervised manner, removing the need for laborious feature engineering. We show the effectiveness of our proposed model on two voice monitoring related tasks. We evaluate the extracted features for classifying between patients with vocal fold nodules and controls. We also demonstrate that the features capture pathology relevant information by showing that models trained on them are more accurate predicting vocal use for patients than for controls. Our proposed method is able to generalize to unseen subjects and across learning tasks while matching state-of-the-art results.}
}
@InProceedings{pmlr-v106-al-hussaini19a,
  title = 	 {SLEEPER: interpretable Sleep staging via Prototypes from Expert Rules},
  author =       {Al-Hussaini, Irfan and Xiao, Cao and Westover, M. Brandon and Sun, Jimeng},
  booktitle = 	 {Proceedings of the 4th Machine Learning for Healthcare Conference},
  pages = 	 {721--739},
  year = 	 {2019},
  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
  volume = 	 {106},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--10 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v106/al-hussaini19a/al-hussaini19a.pdf},
  url = 	 {https://proceedings.mlr.press/v106/al-hussaini19a.html},
  abstract = 	 {Sleep staging is a crucial task for diagnosing sleep disorders. It is tedious and complex as it can take a trained expert several hours to annotate just one patientâs polysomnogram (PSG) from a single night. Although deep learning models have demonstrated state-of-the-art performance in automating sleep staging, interpretability which defines other desiderata, has largely remained unexplored. In this study, we propose Sleep staging via Prototypes from Expert Rules (SLEEPER ), which combines deep learning models with expert defined rules using a prototype learning framework to generate simple interpretable models. In particular, SLEEPER utilizes sleep scoring rules and expert defined features to derive prototypes which are embeddings of PSG data fragments via convolutional neural networks. The final models are simple interpretable models like a shallow decision tree defined over those phenotypes. We evaluated SLEEPER using two PSG datasets collected from sleep studies and demonstrated that SLEEPER could provide accurate sleep stage classification comparable to human experts and deep neural networks with about 85% ROC-AUC and .7 $\kappa$.}
}



