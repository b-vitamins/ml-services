@proceedings{LIDTA2021,
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Nuno Moniz and Paula Branco and Luis Torgo and Nathalie Japkowicz and MichaÅ WoÅºniak and Shuo Wang},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 volume = {154}
}

@inproceedings{pmlr-v154-bougaham21a,
 abstract = {Industry 4.0 and recent deep learning progress make it possible to solve problems that traditional methods could not. This is the case for anomaly detection that received a particular attention from the machine learning community, and resulted in a use of generative adversarial networks (GANs). In this work, we propose to use intermediate patches for the inference step, after a WGAN training procedure suitable for highly imbalanced datasets, to make the anomaly detection possible on full size Printed Circuit Board Assembly (PCBA) images. We therefore show that our technique can be used to support or replace actual industrial image processing algorithms, as well as to avoid a waste of time for industries.},
 author = {Bougaham, Arnaud and Bibal, Adrien and Linden, Isabelle and Frenay, Benoit},
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Moniz, Nuno and Branco, Paula and Torgo, Luis and Japkowicz, Nathalie and WoÅºniak, MichaÅ and Wang, Shuo},
 month = {17 Sep},
 openalex = {W3210361533},
 pages = {104--117},
 pdf = {https://proceedings.mlr.press/v154/bougaham21a/bougaham21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {GanoDIP - GAN Anomaly Detection through Intermediate Patches: a PCBA Manufacturing Case},
 url = {https://proceedings.mlr.press/v154/bougaham21a.html},
 volume = {154},
 year = {2021}
}

@inproceedings{pmlr-v154-draghi21a,
 abstract = {Advanced synthetic data generators can model sensitive personal datasets by creating simulated samples of data with realistic correlation structures and distributions, but with a greatly reduced risk of identifying individuals. This has huge potential in medicine where sensitive patient data can be simulated and shared, enabling the development and robust validation of new AI technologies for diagnosis and disease management. However, even when massive ground truth datasets are available (such as UK-NHS databases which contain patient records in the order of millions) there is a high risk that biases still exist which are carried over to the data generators. For example, certain cohorts of patients may be under-represented due to cultural sensitivities amongst some communities, or due to institutionalised procedures in data collection. The under-representation of groups is one of the forms in which bias can manifest itself in machine learning, and it is the one we investigate in this work. These factors may also lead to structurally missing data or incorrect correlations and distributions which will be mirrored in the synthetic data generated from biased ground truth datasets. In this paper, we explore methods to improve synthetic data generators by using probabilistic methods to firstly identify the under-represented samples in ground truth data, and then to boost these types of data when generating synthetic samples. The paper explores attempts to create synthetic data that contain more realistic distributions and that lead to predictive models with better performance.},
 author = {Draghi, Barbara and Wang, Zhenchen and Myles, Puja and Tucker, Allan},
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Moniz, Nuno and Branco, Paula and Torgo, Luis and Japkowicz, Nathalie and WoÅºniak, MichaÅ and Wang, Shuo},
 month = {17 Sep},
 openalex = {W4225690829},
 pages = {49--62},
 pdf = {https://proceedings.mlr.press/v154/draghi21a/draghi21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Bayesboost: Identifying and Handling Bias Using Synthetic Data Generators},
 url = {https://proceedings.mlr.press/v154/draghi21a.html},
 volume = {154},
 year = {2021}
}

@inproceedings{pmlr-v154-limnios21a,
 abstract = {The ability to collect and store ever more massive databases has been accompanied by the need to process them efficiently. In many cases, most observations have the same behavior, while a probable small proportion of these observations are abnormal. Detecting the latter, defined as outliers, is one of the major challenges for machine learning applications (e.g. in fraud detection or in predictive maintenance). In this paper, we propose a methodology addressing the problem of outlier detection, by learning a data-driven scoring function defined on the feature space which reflects the degree of abnormality of the observations. This scoring function is learnt through a well-designed binary classification problem whose empirical criterion takes the form of a two-sample linear rank statistics on which theoretical results are available. We illustrate our methodology with preliminary encouraging numerical experiments.},
 author = {Limnios, Myrto and Noiry, Nathan and Cl\'emen\c{c}on, Stephan},
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Moniz, Nuno and Branco, Paula and Torgo, Luis and Japkowicz, Nathalie and WoÅºniak, MichaÅ and Wang, Shuo},
 month = {17 Sep},
 openalex = {W3201530074},
 pages = {63--75},
 pdf = {https://proceedings.mlr.press/v154/limnios21a/limnios21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning to Rank Anomalies: Scalar Performance Criteria and Maximization of Two-Sample Rank Statistics},
 url = {https://proceedings.mlr.press/v154/limnios21a.html},
 volume = {154},
 year = {2021}
}

@inproceedings{pmlr-v154-moniz21a,
 author = {Moniz, Nuno and Branco, Paula and Torgo, Lu\'{i}s and Japkowicz, Nathalie and Wo\'zniak, Micha\l and Wang, Shuo},
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Moniz, Nuno and Branco, Paula and Torgo, Luis and Japkowicz, Nathalie and WoÅºniak, MichaÅ and Wang, Shuo},
 month = {17 Sep},
 pages = {1--6},
 pdf = {https://proceedings.mlr.press/v154/moniz21a/moniz21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {3rd Workshop on Learning with Imbalanced Domains: Preface},
 url = {https://proceedings.mlr.press/v154/moniz21a.html},
 volume = {154},
 year = {2021}
}

@inproceedings{pmlr-v154-naklicka21a,
 abstract = {The number of rule-based classifiers specialized  for imbalanced data is quite small so far. In particular, there is no such classifier dedicated for multi-class imbalance data. Thus, in this work we considered two ways of extending BRACID, which is the effective algorithm for binary data. In the first approach, BRACID was used in the OVO ensemble along with modifications of the prediction aggregation strategy. The second approach modifies an induction of rules for multiple classes simultaneously, additionally combined with their post-pruning. Experiments showed that both approaches outperformed the baselines. Moreover, the second approach turned out to be better than OVO with respect to predictive results  and producing a smaller number of rules.},
 author = {Naklicka, Maria and Stefanowski, Jerzy},
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Moniz, Nuno and Branco, Paula and Torgo, Luis and Japkowicz, Nathalie and WoÅºniak, MichaÅ and Wang, Shuo},
 month = {17 Sep},
 pages = {90--103},
 pdf = {https://proceedings.mlr.press/v154/naklicka21a/naklicka21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Two Ways of Extending BRACID Rule-based Classifiers for Multi-class Imbalanced Data},
 url = {https://proceedings.mlr.press/v154/naklicka21a.html},
 volume = {154},
 year = {2021}
}

@inproceedings{pmlr-v154-nardi21a,
 abstract = {In this paper, we address the problem of anomaly detection in decentralised settings. We took inspiration from the current edge computing trend, pushing towards the development of decentralised ML algorithms, i.e., the devices that collected or generated data are in charge of collaborating to train the ML models without sharing raw data . The challenges connected to this scenario are (i) data distributions of local datasets might be different, (ii) data is very often unlabelled, and (iii) devices have limited computational resources. We address them by proposing an unsupervised ensemble method for decentralised anomaly detection where the base learners are lightweight autoencoders. We aim to investigate whether an ensemble of lightweight models trained in isolation on non-IID and unlabelled local data can compete with heavier models trained in centralised settings. In a task of multi-category anomaly detection, our results show that our method exploits the data imbalance successfully to make accurate predictions.},
 author = {Nardi, Mirko and Valerio, Lorenzo and Passarella, Andrea},
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Moniz, Nuno and Branco, Paula and Torgo, Luis and Japkowicz, Nathalie and WoÅºniak, MichaÅ and Wang, Shuo},
 month = {17 Sep},
 pages = {7--20},
 pdf = {https://proceedings.mlr.press/v154/nardi21a/nardi21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Centralised vs decentralised anomaly detection: when local and imbalanced data are beneficial},
 url = {https://proceedings.mlr.press/v154/nardi21a.html},
 volume = {154},
 year = {2021}
}

@inproceedings{pmlr-v154-nazari21a,
 abstract = {Over the last two decades, several approaches have been proposed to tackle the class imbalance problem which is characterized by the inability of a learner to focus on a relevant but scarcely represented class. The generation of synthetic examples to oversample the training set and thus force the learner to focus on the important cases is one of such solutions. Recently, generative adversarial networks (GANs) started to be explored as an oversampling alternative due to their capability of generating samples from an implicit distribution. Still, data difficulty factors such as class overlap, data dimensionality or sample size, and were shown to also negatively impact the learners performance under an imbalance setting. The ability of GANs to deal with the imbalance problem and other data difficulty factors has not yet been assessed. The main goal of this paper is to understand how data difficulty factors impact the performance of GANs when they are used as an oversampling method. Namely, we study the performance of conditioned GANs (CGANs) in an image dataset with controlled levels of the following data difficulty factors: sample size, data dimensionality, class overlap and imbalance ratio. We show that CGANs are effective for tackling tasks with multiple data difficulty factors, exhibiting increased gains on the most difficult tasks.},
 author = {Nazari, Ehsan and Branco, Paula},
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Moniz, Nuno and Branco, Paula and Torgo, Luis and Japkowicz, Nathalie and WoÅºniak, MichaÅ and Wang, Shuo},
 month = {17 Sep},
 pages = {76--89},
 pdf = {https://proceedings.mlr.press/v154/nazari21a/nazari21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {On Oversampling via Generative Adversarial Networks under Different Data Difficulty Factors},
 url = {https://proceedings.mlr.press/v154/nazari21a.html},
 volume = {154},
 year = {2021}
}

@inproceedings{pmlr-v154-pakrashi21a,
 abstract = {In multi-label classification, a datapoint can be assigned to more than one class simultaneously. Input space transformation methods can be used to transform the input space so that classification algorithms can perform better. Although existing algorithms used in binary or multi-class classifications can be used with multi-label datasets, this leads to one transformation per label and hence is very costly. Also, considering each label independently ignores consideration of any label associations in the transformation process which is a missed opportunity. In this work, a new input space transformation algorithm, Multi-label Neighbourhood Component Analysis (ML-NCA), is proposed. ML-NCA performs one single linear transformation of the input space in a supervised fashion, that transforms to a space in which $k$ nearest-neighbour based algorithms are expected to perform well. ML-NCA considers all the labels together while finding the single transformation of the input space, therefore omitting the need for per-label transformations. This also implicitly takes advantage of label associations. An extensive set of experiments and detailed analysis demonstrate that the transformation found by ML-NCA is able to significantly improve the performance of multi-label-specific $k$ nearest neighbour algorithms.},
 author = {Pakrashi, Arjun and Sadhukhan, Sayel and Namee, Brian Mac},
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Moniz, Nuno and Branco, Paula and Torgo, Luis and Japkowicz, Nathalie and WoÅºniak, MichaÅ and Wang, Shuo},
 month = {17 Sep},
 pages = {35--48},
 pdf = {https://proceedings.mlr.press/v154/pakrashi21a/pakrashi21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {ML-NCA: Multi-label Neighbourhood Component Analysis},
 url = {https://proceedings.mlr.press/v154/pakrashi21a.html},
 volume = {154},
 year = {2021}
}

@inproceedings{pmlr-v154-sadeghi21a,
 abstract = {Online supervised learning from fast-evolving data streams has application in many areas. The development of techniques with highly skewed class distributions (or âclass imbalanceâ) is an important area of research in domains such as manufacturing, the environment, and health. Solutions should not only be able to analyse large repositories in near real-time but also be capable of providing accurate models to describe rare classes that may appear infrequently or in bursts, while continuously accommodating new instances. Although online learning methods have been proposed to handle binary class imbalance, solutions suitable for multi-class streams with varying degrees of imbalance in evolving streams have received limited attention. In order to address this knowledge gap, this paper introduces the Online-MC-Queue (OMCQ) algorithm for online learning in multi-class imbalanced settings.  Our approach utilises a queue-based resampling method that dynamically creates an instance queue for each class. The number of instances is balanced by maintaining a queue threshold and removing older samples during training. In addition, new and rare classes are dynamically added to the training process as they appear.  Our experimental results confirm a noticeable improvement in minority-class detection and in classification performance.  A comparative evaluation shows that the OMCQ algorithm outperforms the state-of-the-art.},
 author = {Sadeghi, Farnaz and Viktor, Herna L.},
 booktitle = {Proceedings of the Third International Workshop on Learning with Imbalanced Domains: Theory and Applications},
 editor = {Moniz, Nuno and Branco, Paula and Torgo, Luis and Japkowicz, Nathalie and WoÅºniak, MichaÅ and Wang, Shuo},
 month = {17 Sep},
 pages = {21--34},
 pdf = {https://proceedings.mlr.press/v154/sadeghi21a/sadeghi21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Online-MC-Queue: Learning from Imbalanced Multi-Class Streams},
 url = {https://proceedings.mlr.press/v154/sadeghi21a.html},
 volume = {154},
 year = {2021}
}
