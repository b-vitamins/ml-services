
- title: 'Dual Likelihood for Causal Inference under Structure Uncertainty'
  abstract: 'Knowledge of the underlying causal relations is essential for inferring the effect of interventions in complex systems. In a widely studied approach, structural causal models postulate noisy functional relations among interacting variables, where the underlying causal structure is then naturally represented by a directed graph whose edges indicate direct causal dependencies. In the typical application, this underlying causal structure must be learned from data, and thus, the remaining structure uncertainty needs to be incorporated into causal inference in order to draw reliable conclusions. In recent work, test inversions provide an ansatz to account for this data-driven model choice and, therefore, combine structure learning with causal inference. In this article, we propose the use of dual likelihood to greatly simplify the treatment of the involved testing problem. Indeed, dual likelihood leads to a closed-form solution for constructing confidence regions for total causal effects that rigorously capture both sources of uncertainty: causal structure and numerical size of nonzero effects. The proposed confidence regions can be computed with a bottom-up procedure starting from sink nodes. To render the causal structure identifiable, we develop our ideas in the context of linear causal relations with equal error variances.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/strieder24a.html
  PDF: https://proceedings.mlr.press/v236/strieder24a/strieder24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-strieder24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: David
    family: Strieder
  - given: Mathias
    family: Drton
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1-17
  id: strieder24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1
  lastpage: 17
  published: 2024-03-15 00:00:00 +0000
- title: 'Ensembled Prediction Intervals for Causal Outcomes Under Hidden Confounding'
  abstract: 'Causal inference of exact individual treatment outcomes in the presence of hidden confounders is rarely possible. Recent work has extended prediction intervals with finite-sample guarantees to partially identifiable causal outcomes, by means of a sensitivity model for hidden confounding. In deep learning, predictors can exploit their inductive biases for better generalization out of sample. We argue that the structure inherent to a deep ensemble should inform a tighter partial identification of the causal outcomes that they predict. We therefore introduce an approach termed <b>Caus-Modens</b>, for characterizing <b>caus</b>al outcome intervals by <b>mod</b>ulated <b>ens</b>embles. We present a simple approach to partial identification using existing causal sensitivity models and show empirically that Caus-Modens gives tighter outcome intervals, as measured by the necessary interval size to achieve sufficient coverage. The last of our three diverse benchmarks is a novel usage of GPT-4 for observational experiments with unknown but probeable ground truth.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/marmarelis24a.html
  PDF: https://proceedings.mlr.press/v236/marmarelis24a/marmarelis24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-marmarelis24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Myrl G.
    family: Marmarelis
  - given: Greg
    prefix: Ver
    family: Steeg
  - given: Aram
    family: Galstyan
  - given: Fred
    family: Morstatter
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 18-40
  id: marmarelis24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 18
  lastpage: 40
  published: 2024-03-15 00:00:00 +0000
- title: 'An Interventional Perspective on Identifiability in Gaussian LTI Systems with Independent Component Analysis'
  abstract: 'We investigate the relationship between system identification and intervention design in dynamical systems. While previous research demonstrated how identifiable representation learning methods, such as Independent Component Analysis (ICA), can reveal cause-effect relationships, it relied on a passive perspective without considering how to collect data. Our work shows that in Gaussian Linear Time-Invariant (LTI) systems, the system parameters can be identified by introducing diverse intervention signals in a multi-environment setting. By harnessing appropriate diversity assumptions motivated by the ICA literature, our findings connect experiment design and representational identifiability in dynamical systems. We corroborate our findings on synthetic and (simulated) physical data. Additionally, we show that Hidden Markov Models, in general, and (Gaussian) LTI systems, in particular,  fulfil a generalization of the Causal de Finetti theorem with continuous parameters. The project’s repository is at [github.com/rpatrik96/lti-ica](https://github.com/rpatrik96/lti-ica).'
  volume: 236
  URL: https://proceedings.mlr.press/v236/rajendran24a.html
  PDF: https://proceedings.mlr.press/v236/rajendran24a/rajendran24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-rajendran24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Goutham
    family: Rajendran
  - given: Patrik
    family: Reizinger
  - given: Wieland
    family: Brendel
  - given: Pradeep Kumar
    family: Ravikumar
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 41-70
  id: rajendran24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 41
  lastpage: 70
  published: 2024-03-15 00:00:00 +0000
- title: 'Structure Learning with Continuous Optimization: A Sober Look and Beyond'
  abstract: 'This paper investigates in which cases continuous optimization for directed acyclic graph (DAG) structure learning can and cannot perform well and why this happens, and suggests possible directions to make the search procedure more reliable. Reisach et al. (2021) suggested that the remarkable performance of several continuous structure learning approaches is primarily driven by a high agreement between the order of increasing marginal variances and the topological order, and demonstrated that these approaches do not perform well after data standardization. We analyze this phenomenon for continuous approaches assuming equal and non-equal noise variances, and show that the statement may not hold in either case by providing counterexamples, justifications, and possible alternative explanations. We further demonstrate that nonconvexity may be a main concern especially for the non-equal noise variances formulation, while recent advances in continuous structure learning fail to achieve improvement in this case. Our findings suggest that future works should take into account the non-equal noise variances formulation to handle more general settings and for a more comprehensive empirical evaluation. Lastly, we provide insights into other aspects of the search procedure, including thresholding and sparsity, and show that they play an important role in the final solutions.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/ng24a.html
  PDF: https://proceedings.mlr.press/v236/ng24a/ng24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-ng24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Ignavier
    family: Ng
  - given: Biwei
    family: Huang
  - given: Kun
    family: Zhang
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 71-105
  id: ng24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 71
  lastpage: 105
  published: 2024-03-15 00:00:00 +0000
- title: 'Causal State Distillation for Explainable Reinforcement Learning'
  abstract: 'Reinforcement learning (RL) is a powerful technique for training intelligent agents, but understanding why these agents make specific decisions can be quite challenging. This lack of transparency in RL models has been a long-standing problem, making it difficult for users to grasp the reasons behind an agent’s behaviour. Various approaches have been explored to address this problem, with one promising avenue being reward decomposition (RD). RD is appealing as it sidesteps some of the concerns associated with other methods that attempt to rationalize an agent’s behaviour in a post-hoc manner. RD works by exposing various facets of the rewards that contribute to the agent’s objectives during training. However, RD alone has limitations as it primarily offers insights based on sub-rewards and does not delve into the intricate cause-and-effect relationships that occur within an RL agent’s neural model. In this paper, we present an extension of RD that goes beyond sub-rewards to provide more informative explanations. Our approach is centred on a causal learning framework that leverages information-theoretic measures for explanation objectives that encourage three crucial properties of causal factors: <em>causal sufficiency, sparseness,</em> and <em>orthogonality</em>. These properties help us distill the cause-and-effect relationships between the agent’s states and actions or rewards, allowing for a deeper understanding of its decision-making processes. Our framework is designed to generate local explanations and can be applied to a wide range of RL tasks with multiple reward channels. Through a series of experiments, we demonstrate that our approach offers more meaningful and insightful explanations for the agent’s action selections.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/lu24a.html
  PDF: https://proceedings.mlr.press/v236/lu24a/lu24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-lu24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Wenhao
    family: Lu
  - given: Xufeng
    family: Zhao
  - given: Thilo
    family: Fryen
  - given: Jae Hee
    family: Lee
  - given: Mengdi
    family: Li
  - given: Sven
    family: Magg
  - given: Stefan
    family: Wermter
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 106-142
  id: lu24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 106
  lastpage: 142
  published: 2024-03-15 00:00:00 +0000
- title: 'Cautionary Tales on Synthetic Controls in Survival Analyses'
  abstract: 'Synthetic control (SC) methods have gained rapid popularity in economics recently, where they have been applied in the context of inferring the effects of treatments on standard continuous outcomes assuming linear input-output relations. In medical applications, conversely, survival outcomes are often of primary interest, a setup in which both commonly assumed data-generating processes (DGPs) and target parameters are different. In this paper, we therefore investigate whether and when SCs could serve as an alternative to matching methods in survival analyses. We find that, because SCs rely on a linearity assumption, they will generally be biased for the true expected survival time in commonly assumed survival DGPs – even when taking into account the possibility of linearity on another scale as in accelerated failure time models. Additionally, we find that, because SC units follow distributions with lower variance than real control units, summaries of their distributions, such as survival curves,  will be biased for the parameters of interest in many survival analyses. Nonetheless, we also highlight that using SCs can still improve upon matching whenever the biases described above are outweighed by extrapolation biases exhibited by imperfect matches, and investigate the use of regularization to trade off the shortcomings of both approaches.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/curth24a.html
  PDF: https://proceedings.mlr.press/v236/curth24a/curth24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-curth24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Alicia
    family: Curth
  - given: Hoifung
    family: Poon
  - given: Aditya V.
    family: Nori
  - given: Javier
    family: González
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 143-159
  id: curth24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 143
  lastpage: 159
  published: 2024-03-15 00:00:00 +0000
- title: 'Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations'
  abstract: 'Causal abstraction is a promising theoretical framework for explainable artificial intelligence that defines when an interpretable high-level causal model is a faithful simplification of a low-level deep learning system. However, existing causal abstraction methods have two major limitations: they require a brute-force search over alignments between the high-level model and the low-level one, and they presuppose that variables in the high-level model will align with disjoint sets of neurons in the low-level one. In this paper, we present distributed alignment search (DAS), which overcomes these limitations. In DAS, we find the alignment between high-level and low-level models using gradient descent rather than conducting a brute-force search, and we allow individual neurons to play multiple distinct roles by analyzing representations in non-standard bases—distributed representations. Our experiments show that DAS can discover internal structure that prior approaches miss. Overall, DAS removes previous obstacles to uncovering conceptual structure in trained neural nets.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/geiger24a.html
  PDF: https://proceedings.mlr.press/v236/geiger24a/geiger24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-geiger24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Atticus
    family: Geiger
  - given: Zhengxuan
    family: Wu
  - given: Christopher
    family: Potts
  - given: Thomas
    family: Icard
  - given: Noah
    family: Goodman
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 160-187
  id: geiger24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 160
  lastpage: 187
  published: 2024-03-15 00:00:00 +0000
- title: 'Fundamental Properties of Causal Entropy and Information Gain'
  abstract: 'Recent developments enable the quantification of causal control given a structural causal model (SCM). This has been accomplished by introducing quantities which encode changes in the entropy of one variable when  intervening on another. These measures, named causal entropy and causal information gain, aim to address limitations in existing information theoretical approaches for machine learning tasks where causality plays a crucial role. They have not yet been properly mathematically studied. Our research contributes to the formal understanding of the notions of causal entropy and causal information gain by establishing and analyzing fundamental properties of these concepts, including bounds and chain rules. Furthermore, we elucidate the relationship between causal entropy and stochastic interventions. We also propose definitions for causal conditional entropy and causal conditional information gain. Overall, this exploration paves the way for enhancing causal machine learning tasks through the study of recently-proposed information theoretic quantities grounded in considerations about causality.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/simoes24a.html
  PDF: https://proceedings.mlr.press/v236/simoes24a/simoes24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-simoes24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Francisco N. F. Q.
    family: Simoes
  - given: Mehdi
    family: Dastani
  - given: Thijs van
    family: Ommen
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 188-208
  id: simoes24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 188
  lastpage: 208
  published: 2024-03-15 00:00:00 +0000
- title: 'Bicycle: Intervention-Based Causal Discovery with Cycles'
  abstract: 'While a growing number of algorithms for causal discovery of directed acyclic graphs from observational and interventional data have been proposed, the robust identification of cyclic causal graphs in particular remains an open problem. Solutions to this challenge would have a considerable impact in various application domains, including single-cell genomics, where gene regulatory networks are known to contain feedback loops. Recent work has shown promise to address this challenge by describing the expression states in a population of cells as the steady-state solution of a stochastic dynamical system. However, this formulation cannot account for information on interventions in the population, and consequently, it ignores the associated causal inductive biases, which are key assets to obtain meaningful results and improve identifiability. In this work, we propose a novel method, Bicycle, which (i) infers cyclic causal relationships from i.i.d. data, (ii) explicitly accounts for information on the perturbation state of cells by a realization of the independent causal mechanism principle and (iii) models causal effects in a latent space rather than on observed data. We benchmark Bicycle in the context of existing approaches, demonstrating improved recovery of simulated causal graphs and improved out-of-distribution prediction performance on unseen perturbations in real single-cell datasets.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/rohbeck24a.html
  PDF: https://proceedings.mlr.press/v236/rohbeck24a/rohbeck24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-rohbeck24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Martin
    family: Rohbeck
  - given: Brian
    family: Clarke
  - given: Katharina
    family: Mikulik
  - given: Alexandra
    family: Pettet
  - given: Oliver
    family: Stegle
  - given: Kai
    family: Ueltzhöffer
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 209-242
  id: rohbeck24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 209
  lastpage: 242
  published: 2024-03-15 00:00:00 +0000
- title: 'Pragmatic Fairness: Developing Policies with Outcome Disparity Control'
  abstract: 'We introduce a causal framework for designing optimal policies that satisfy classes of fairness constraints. We take a pragmatic approach asking what we can do with an action space available from historical data, with no further experimentation and novel actions immediately available. We propose two different fairness constraints: a "moderation breaking" constraint which aims at reducing disparity in outcome levels across sensitive attributes to the extent the provided action space permits; and an "equal benefit" constraint which aims at distributing gain from the new and maximized policy equally across sensitive attribute levels, and thus at keeping pre-existing preferential treatment in place or avoiding the introduction of new disparity. We introduce practical methods for implementing the constraints and illustrate their uses on experiments with semi-synthetic models.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/gultchin24a.html
  PDF: https://proceedings.mlr.press/v236/gultchin24a/gultchin24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-gultchin24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Limor
    family: Gultchin
  - given: Siyuan
    family: Guo
  - given: Alan
    family: Malek
  - given: Silvia
    family: Chiappa
  - given: Ricardo
    family: Silva
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 243-264
  id: gultchin24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 243
  lastpage: 264
  published: 2024-03-15 00:00:00 +0000
- title: 'Extracting the Multiscale Causal Backbone of Brain Dynamics'
  abstract: 'The bulk of the research effort on brain connectivity revolves around statistical associations among brain regions, which do not directly relate to the causal mechanisms governing brain dynamics. Here we propose the multiscale causal backbone (MCB) of brain dynamics shared by a set of individuals across multiple temporal scales, and devise a principled methodology to extract it. Our approach leverages recent advances in multiscale causal structure learning and optimizes the trade-off between the model fitting and its complexity. Empirical assessment on synthetic data shows the superiority of our methodology over a baseline based on canonical functional connectivity networks. When applied to resting-state fMRI data, we find sparse MCBs for both the left and right brain hemispheres. Thanks to its multiscale nature, our approach shows that at low-frequency bands, causal dynamics are driven by brain regions associated with high-level cognitive functions; at higher frequencies instead, nodes related to sensory processing play a crucial role. Finally, our analysis of individuals’ multiscale causal structures confirms the existence of a causal fingerprint of brain connectivity, thus supporting from a causal perspective the existing extensive research in brain connectivity fingerprinting.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/d-textsc-char13acunto24a.html
  PDF: https://proceedings.mlr.press/v236/d-textsc-char13acunto24a/d-textsc-char13acunto24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-d-textsc-char13acunto24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Gabriele
    family: D\textsc\char13Acunto
  - given: Francesco
    family: Bonchi
  - given: Gianmarco De Francisci
    family: Morales
  - given: Giovanni
    family: Petri
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 265-295
  id: d-textsc-char13acunto24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 265
  lastpage: 295
  published: 2024-03-15 00:00:00 +0000
- title: 'Towards the Reusability and Compositionality of Causal Representations'
  abstract: 'Causal Representation Learning (CRL) aims at identifying high-level causal factors and their relationships from high-dimensional observations, e.g., images. While most CRL works focus on learning causal representations in a single environment, in this work we instead propose a first step towards learning causal representations from temporal sequences of images that can be adapted in a new environment, or composed across multiple related environments. In particular, we introduce DECAF, a framework that detects which causal factors can be reused and which need to be adapted from previously learned causal representations. Our approach is based on the availability of intervention targets, that indicate which variables are perturbed at each time step. Experiments on three benchmark datasets show that integrating our framework with four state-of-the-art CRL approaches leads to accurate representations in a new environment with only a few samples.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/talon24a.html
  PDF: https://proceedings.mlr.press/v236/talon24a/talon24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-talon24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Davide
    family: Talon
  - given: Phillip
    family: Lippe
  - given: Stuart
    family: James
  - given: Alessio Del
    family: Bue
  - given: Sara
    family: Magliacane
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 296-324
  id: talon24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 296
  lastpage: 324
  published: 2024-03-15 00:00:00 +0000
- title: 'Causal Discovery Under Local Privacy'
  abstract: 'Differential privacy is a widely adopted framework designed to safeguard the sensitive information of data providers within a data set. It is based on the application of controlled noise at the interface between the server that stores and processes the data, and the data consumers. Local differential privacy is a variant that allows data providers to apply the privatization mechanism themselves on their data individually. Therefore, it provides protection also in contexts in which the server, or even the data collector, cannot be trusted. The introduction of noise, however, inevitably affects the utility of the data, particularly by distorting the correlations between individual data components. This distortion can prove detrimental to tasks such as causal structure learning. In this paper, we consider various well-known locally differentially private mechanisms and compare the trade-off between the privacy they provide, and the accuracy of the causal structure produced by algorithms for causal learning when applied to data obfuscated by these mechanisms. Our analysis yields valuable insights for selecting appropriate local differentially private protocols for causal discovery tasks. We foresee that our findings will aid researchers and practitioners in conducting locally private causal discovery.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/binkyte24a.html
  PDF: https://proceedings.mlr.press/v236/binkyte24a/binkyte24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-binkyte24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Ruta
    family: Binkyte
  - given: Carlos Antonio
    family: Pinzón
  - given: Szilvia
    family: Lestyán
  - given: Kangsoo
    family: Jung
  - given: Héber Hwang
    family: Arcolezi
  - given: Catuscia
    family: Palamidessi
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 325-383
  id: binkyte24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 325
  lastpage: 383
  published: 2024-03-15 00:00:00 +0000
- title: 'On the Identifiability of Quantized Factors'
  abstract: 'Disentanglement  aims to recover meaningful latent ground-truth factors from the observed distribution solely, and is formalized through the theory of identifiability. The identifiability of independent latent factors is proven to be impossible in the unsupervised i.i.d. setting under a general nonlinear map from factors to observations. In this work, however, we demonstrate that it is possible to recover <em>quantized</em> latent factors under a generic nonlinear diffeomorphism. We only assume that the latent factors have <em>independent discontinuities</em> in their density, without requiring the factors to be statistically independent. We introduce this novel form of identifiability, termed <em>quantized factor identifiability</em>, and provide a comprehensive proof of the recovery of the quantized factors.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/barin-pacela24a.html
  PDF: https://proceedings.mlr.press/v236/barin-pacela24a/barin-pacela24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-barin-pacela24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Vitória
    family: Barin-Pacela
  - given: Kartik
    family: Ahuja
  - given: Simon
    family: Lacoste-Julien
  - given: Pascal
    family: Vincent
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 384-422
  id: barin-pacela24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 384
  lastpage: 422
  published: 2024-03-15 00:00:00 +0000
- title: 'Confounded Budgeted Causal Bandits'
  abstract: 'We study the problem of learning "good" interventions in a stochastic environment modeled by its underlying causal graph. Good interventions refer to interventions that maximize rewards. Specifically, we consider the setting of a pre-specified budget constraint, where interventions can have non-uniform costs.  We show that this problem can be formulated as maximizing the expected reward for a stochastic multi-armed bandit with side information.  We propose an algorithm to minimize the cumulative regret in general causal graphs. This algorithm trades off observations and interventions based on their costs to achieve the optimal reward.  This algorithm generalizes the state-of-the-art methods by allowing non-uniform costs and hidden confounders in the causal graph. Furthermore, we develop an algorithm to minimize the simple regret in the budgeted setting with non-uniform costs and also general causal graphs. We provide theoretical guarantees, including both upper and lower bounds, as well as empirical evaluations of our algorithms. Our empirical results showcase that our algorithms outperform the state of the art.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/jamshidi24a.html
  PDF: https://proceedings.mlr.press/v236/jamshidi24a/jamshidi24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-jamshidi24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Fateme
    family: Jamshidi
  - given: Jalal
    family: Etesami
  - given: Negar
    family: Kiyavash
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 423-461
  id: jamshidi24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 423
  lastpage: 461
  published: 2024-03-15 00:00:00 +0000
- title: 'Causal Optimal Transport of Abstractions'
  abstract: 'Causal abstraction (CA) theory establishes formal criteria for relating multiple structural causal models (SCMs) at different levels of granularity by defining maps between them. These maps have significant relevance for real-world challenges such as synthesizing causal evidence from multiple experimental environments, learning causally consistent representations at different resolutions, and linking interventions across multiple SCMs. In this work, we propose COTA, the first method to learn abstraction maps from observational and interventional data without assuming complete knowledge of the underlying SCMs. In particular, we introduce a multi-marginal Optimal Transport (OT) formulation that enforces do-calculus causal constraints, together with a cost function that relies on interventional information. We extensively evaluate COTA on synthetic and real world problems, and showcase its advantages over non-causal, independent and aggregated OT formulations. Finally, we demonstrate the efficiency of our method as a data augmentation tool by comparing it against prior art of CA learning, which assumes fully specified SCMs, on a real-world downstream task.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/felekis24a.html
  PDF: https://proceedings.mlr.press/v236/felekis24a/felekis24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-felekis24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Yorgos
    family: Felekis
  - given: Fabio Massimo
    family: Zennaro
  - given: Nicola
    family: Branchini
  - given: Theodoros
    family: Damoulas
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 462-498
  id: felekis24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 462
  lastpage: 498
  published: 2024-03-15 00:00:00 +0000
- title: 'Implicit and Explicit Policy Constraints for Offline Reinforcement Learning'
  abstract: 'Offline reinforcement learning (RL) aims to improve the target policy over the behavior policy based on historical data. A major problem of offline RL is the distribution shift that causes overestimation of the Q-value due to out-of-distribution actions. Most existing works focus on either behavioral cloning (BC) or maximizing Q-Learning methods to suppress distribution shift. BC methods try to mitigate the shift by constraining the target policy to be close to the offline data, but it makes the learned policy highly conservative. On the other hand, maximizing Q-Learning methods adopt pessimism mechanism to generate actions by maximizing Q-value and penalizing Q-value according to the uncertainty of actions. However, the generated actions might be arbitrary, resulting in the predicted Q-values highly uncertain, which will in turn misguide the policy to generate the next action. To alleviate the adverse effect of the distribution shift, we propose to constrain the policy implicitly and explicitly by unifying Q-Learning and behavior cloning to tackle the exploration and exploitation dilemma.  For the implicit constraint approach, we propose to unify the action space by generative adversarial networks that dedicate to make the actions of the target policy and behavior policy indistinguishable. For the explicit constraint approach, we propose multiple importance sampling (MIS) to learn an advantage weight for each state-action pair which is then used to suppress or make full use of each state-action pair. Extensive experiments on the D4RL dataset indicate that our approaches can achieve superior performance. The results on the Maze2D data indicate that MIS addresses heterogeneous data better than single importance sampling. We also found that MIS can stabilize the reward curve effectively.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/liu24a.html
  PDF: https://proceedings.mlr.press/v236/liu24a/liu24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-liu24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Yang
    family: Liu
  - given: Marius
    family: Hofert
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 499-513
  id: liu24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 499
  lastpage: 513
  published: 2024-03-15 00:00:00 +0000
- title: 'On the Lasso for Graphical Continuous Lyapunov Models'
  abstract: 'Graphical continuous Lyapunov models offer a new perspective on modeling causally interpretable dependence structure in multivariate data by treating each independent observation as a one-time cross-sectional snapshot of a temporal process. Specifically, the models assume that the observations are cross-sections of independent multivariate Ornstein-Uhlenbeck processes in equilibrium. The Gaussian equilibrium exists under a stability assumption on the drift matrix, and the equilibrium covariance matrix is determined by the continuous Lyapunov equation. Each graphical continuous Lyapunov model assumes the drift matrix to be sparse, with a support determined by a directed graph. A natural approach to model selection in this setting is to use an $\ell_1$-regularization technique that, based on a given sample covariance matrix, seeks to find a sparse approximate solution to the Lyapunov equation. We study the model selection properties of the resulting lasso technique to arrive at a consistency result.  Our detailed analysis reveals that the involved irrepresentability condition is surprisingly difficult to satisfy. While this may prevent asymptotic consistency in model selection, our numerical experiments indicate that even if the theoretical requirements for consistency are not met, the lasso approach is able to recover relevant structure of the drift matrix and is robust to aspects of model misspecification.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/dettling24a.html
  PDF: https://proceedings.mlr.press/v236/dettling24a/dettling24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-dettling24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Philipp
    family: Dettling
  - given: Mathias
    family: Drton
  - given: Mladen
    family: Kolar
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 514-550
  id: dettling24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 514
  lastpage: 550
  published: 2024-03-15 00:00:00 +0000
- title: 'Evaluating and Correcting Performative Effects of Decision Support Systems via Causal Domain Shift'
  abstract: 'When predicting a target variable $Y$ from features $X$, the prediction $\hat{Y}$ can be performative: an agent might act on this prediction, affecting the value of $Y$ that we eventually observe. Performative predictions are deliberately prevalent in algorithmic decision support, where a decision support system (DSS) provides a prediction for an agent to affect the value of the target variable. When deploying a DSS in high-stakes settings (e.g. healthcare, law, predictive policing, or child welfare screening) it is imperative to carefully assess the performative effects of the DSS. In the case that the DSS serves as an alarm for a predicted negative outcome, naive retraining of the prediction model is bound to result in a model that underestimates the risk, due to effective workings of the previous model. In this work, we propose to model the deployment of a DSS as causal domain shift and provide novel cross-domain identification results for the conditional expectation $E[Y|X]$, allowing for pre- and post-hoc assessment of the deployment of the DSS, and for re-training of a model that assesses the risk under a baseline policy where the DSS is not deployed. Using a running example, we empirically show that a repeated regression procedure provides a practical framework for estimating these quantities, even when the data is affected by sample selection bias and selective labelling, offering for a practical, unified solution for multiple forms of target variable bias.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/boeken24a.html
  PDF: https://proceedings.mlr.press/v236/boeken24a/boeken24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-boeken24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Philip
    family: Boeken
  - given: Onno
    family: Zoeter
  - given: Joris
    family: Mooij
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 551-569
  id: boeken24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 551
  lastpage: 569
  published: 2024-03-15 00:00:00 +0000
- title: 'On the Impact of Neighbourhood Sampling to Satisfy Sufficiency and Necessity Criteria in Explainable AI'
  abstract: 'In the context of Machine Learning(ML) and Artificial Intelligence (AI), the concepts of sufficiency and necessity of features offer nuanced perspectives on the cause-and-effect relationships underlying a model’s outputs. These concepts are, therefore, essential in Explainable AI (XAI) as they can provide a more holistic understanding of a “black-box" AI model. Addressing this need, our study explored the relationships between the XAI’s explanations and the sufficiency and necessity of features in data. This is achieved by emphasising the impact of neighbourhoods, which are central in generating explanations. By analysing a diverse set of neighbourhoods, we highlighted how they influence the alignment between the feature rankings by XAI and the measures of sufficiency and necessity. This work offers two contributions. First, it provides a comprehensive discussion on how XAI frameworks relate to sufficiency and necessity with respect to their operating neighbourhoods; and second, it empirically demonstrates the effectiveness of these neighbourhoods in conveying the sufficiency and necessity of features by the XAI frameworks.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/pawar24a.html
  PDF: https://proceedings.mlr.press/v236/pawar24a/pawar24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-pawar24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Urja
    family: Pawar
  - given: Christian
    family: Beder
  - given: Ruairi
    family: O\textsc\char13Reilly
  - given: Donna
    family: O\textsc\char13Shea
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 570-586
  id: pawar24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 570
  lastpage: 586
  published: 2024-03-15 00:00:00 +0000
- title: 'Designing monitoring strategies for deployed machine learning algorithms: navigating performativity through a causal lens'
  abstract: 'After a machine learning (ML)-based system is deployed, monitoring its performance is important to ensure the safety and effectiveness of the algorithm over time. When an ML algorithm interacts with its environment, the algorithm can affect the data-generating mechanism and be a major source of bias when evaluating its standalone performance, an issue known as performativity. Although prior work has shown how to <em>validate</em> models in the presence of performativity using causal inference techniques, there has been little work on how to <em>monitor</em> models in the presence of performativity. Unlike the setting of model validation, there is much less agreement on which performance metrics to monitor. Different monitoring criteria impact how interpretable the resulting test statistic is, what assumptions are needed for identifiability, and the speed of detection. When this choice is further coupled with the decision to use observational versus interventional data, ML deployment teams are faced with a multitude of monitoring options. The aim of this work is to highlight the relatively under-appreciated complexity of designing a monitoring strategy and how causal reasoning can provide a systematic framework for choosing between these options. As a motivating example, we consider an ML-based risk prediction algorithm for predicting unplanned readmissions. Bringing together tools from causal inference and statistical process control, we consider six monitoring procedures (three candidate monitoring criteria and two data sources) and investigate their operating characteristics in simulation studies. Results from this case study emphasize the seemingly simple (and obvious) fact that <em>not all monitoring systems are created equal</em>, which has real-world impacts on the design and documentation of ML monitoring systems.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/feng24a.html
  PDF: https://proceedings.mlr.press/v236/feng24a/feng24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-feng24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Jean
    family: Feng
  - given: Adarsh
    family: Subbaswamy
  - given: Alexej
    family: Gossmann
  - given: Harvineet
    family: Singh
  - given: Berkman
    family: Sahiner
  - given: Mi-Ok
    family: Kim
  - given: Gene Anthony
    family: Pennello
  - given: Nicholas
    family: Petrick
  - given: Romain
    family: Pirracchio
  - given: Fan
    family: Xia
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 587-608
  id: feng24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 587
  lastpage: 608
  published: 2024-03-15 00:00:00 +0000
- title: '`causalAssembly`: Generating Realistic Production Data for Benchmarking Causal Discovery'
  abstract: 'Algorithms for causal discovery have recently undergone rapid advances and increasingly draw on flexible nonparametric methods to process complex data. With these advances comes a need for adequate empirical validation of the causal relationships learned by different algorithms. However, for most real and complex data sources true causal relations remain unknown. This issue is further compounded by privacy concerns surrounding the release of suitable high-quality data. To tackle these challenges, we introduce $\texttt{causalAssembly}$, a semisynthetic data generator designed to facilitate the benchmarking of causal discovery methods. The tool is built using a complex real-world dataset comprised of measurements collected along an assembly line in a manufacturing setting. For these measurements, we establish a partial set of ground truth causal relationships through a detailed study of the physics underlying the processes carried out in the assembly line. The partial ground truth is sufficiently informative to allow for estimation of a full causal graph by mere nonparametric regression. To overcome potential confounding and privacy concerns, we use distributional random forests to estimate and represent conditional distributions implied by the ground truth causal graph. These conditionals are combined into a joint distribution that strictly adheres to a causal model over the observed variables. Sampling from this distribution, $\texttt{causalAssembly}$ generates data that are guaranteed to be Markovian with respect to the ground truth. Using our tool, we showcase how to benchmark several well-known causal discovery algorithms.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/gobler24a.html
  PDF: https://proceedings.mlr.press/v236/gobler24a/gobler24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-gobler24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Konstantin
    family: Göbler
  - given: Tobias
    family: Windisch
  - given: Mathias
    family: Drton
  - given: Tim
    family: Pychynski
  - given: Martin
    family: Roth
  - given: Steffen
    family: Sonntag
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 609-642
  id: gobler24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 609
  lastpage: 642
  published: 2024-03-15 00:00:00 +0000
- title: 'Expediting Reinforcement Learning by Incorporating Knowledge About Temporal Causality in the Environment'
  abstract: 'Reinforcement learning (RL) algorithms struggle with learning optimal policies for tasks where reward feedback is sparse and depends on a complex sequence of events in the environment. Probabilistic reward machines (PRMs) are finite-state formalisms that can capture temporal dependencies in the reward signal, along with nondeterministic task outcomes. While special RL algorithms can exploit this finite-state structure to expedite learning, PRMs remain difficult to modify and design by hand. This hinders the already difficult tasks of utilizing high-level causal knowledge about the environment, and transferring the reward formalism into a new domain with a different causal structure. This paper proposes a novel method to incorporate causal information in the form of Temporal Logic-based Causal Diagrams into the reward formalism, thereby expediting policy learning and aiding the transfer of task specifications to new environments. Furthermore, we provide a theoretical result about convergence to optimal policy for our method, and demonstrate its strengths empirically.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/corazza24a.html
  PDF: https://proceedings.mlr.press/v236/corazza24a/corazza24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-corazza24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Jan
    family: Corazza
  - given: Hadi Partovi
    family: Aria
  - given: Daniel
    family: Neider
  - given: Zhe
    family: Xu
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 643-664
  id: corazza24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 643
  lastpage: 664
  published: 2024-03-15 00:00:00 +0000
- title: 'Causality for Functional Longitudinal Data'
  abstract: '“Treatment-confounder feedback” is the central complication to resolve in longitudinal studies, to infer causality. The existing frameworks of identifying causal effects for longitudinal studies with repeated measures hinge heavily on assuming that time advances in discrete time steps or data change as a jumping process, rendering the number of “feedbacks” finite. However, medical studies nowadays with real-time monitoring involve functional time-varying outcomes, treatment, and confounders, which leads to an uncountably infinite number of “feedbacks”. Therefore more general and advanced theory is needed. We generalize the definition of causal effects under user-specified stochastic treatment regimes to functional longitudinal studies with continuous monitoring and develop an identification framework for a end-of-study outcome. We provide sufficient identification assumptions including a generalized consistency assumption, a sequential randomization assumption, a positivity assumption, and a novel “intervenable” assumption designed for the continuous-time case. Under these assumptions, we propose a g-computation process and an inverse probability weighting process, which suggest a g-computation formula and an inverse probability weighting formula for identification. For practical purposes, we also construct two classes of population estimating equations to identify these two processes, respectively, which further suggest a doubly robust identification formula with extra robustness against process misspecification.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/ying24a.html
  PDF: https://proceedings.mlr.press/v236/ying24a/ying24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-ying24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Andrew
    family: Ying
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 665-687
  id: ying24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 665
  lastpage: 687
  published: 2024-03-15 00:00:00 +0000
- title: 'Causal Matching using Random Hyperplane Tessellations'
  abstract: 'Matching is one of the simplest approaches for estimating causal effects from observational data. Matching techniques compare the observed outcomes across pairs of individuals with similar covariate values but different treatment statuses in order to estimate causal effects. However, traditional matching techniques are unreliable given high-dimensional covariates due to the infamous curse of dimensionality. To overcome this challenge, we propose a simple, fast, yet highly effective approach to matching using Random Hyperplane Tessellations (RHPT). First, we prove that the RHPT representation is an approximate balancing score – thus maintaining the strong ignorability assumption – and provide empirical evidence for this claim. Second, we report results of extensive experiments showing that matching using RHPT outperforms traditional matching techniques and is competitive with state-of-the-art deep learning methods for causal effect estimation. In addition, RHPT avoids the need for computationally expensive training of deep neural networks.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/dalvi24a.html
  PDF: https://proceedings.mlr.press/v236/dalvi24a/dalvi24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-dalvi24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Abhishek
    family: Dalvi
  - given: Neil
    family: Ashtekar
  - given: Vasant G
    family: Honavar
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 688-702
  id: dalvi24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 688
  lastpage: 702
  published: 2024-03-15 00:00:00 +0000
- title: 'Robustness of Algorithms for Causal Structure Learning to Hyperparameter Choice'
  abstract: 'Hyperparameters play a critical role in machine learning. Hyperparameter tuning can make the difference between state-of-the-art and poor prediction performance for any algorithm, but it is particularly challenging for structure learning due to its unsupervised nature. As a result, hyperparameter tuning is often neglected in favour of using the default values provided by a particular implementation of an algorithm. While there have been numerous studies on performance evaluation of causal discovery algorithms, how hyperparameters affect individual algorithms, as well as the choice of the best algorithm for a specific problem, has not been studied in depth before. This work addresses this gap by investigating the influence of hyperparameters on causal structure learning tasks. Specifically, we perform an empirical evaluation of hyperparameter selection for some seminal learning algorithms on datasets of varying levels of complexity. We find that, while the choice of algorithm remains crucial to obtaining state-of-the-art performance, hyperparameter selection in ensemble settings strongly influences the choice of algorithm, in that a poor choice of hyperparameters can lead to analysts using algorithms which do not give state-of-the-art performance for their data.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/machlanski24a.html
  PDF: https://proceedings.mlr.press/v236/machlanski24a/machlanski24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-machlanski24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Damian
    family: Machlanski
  - given: Spyridon
    family: Samothrakis
  - given: Paul S
    family: Clarke
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 703-739
  id: machlanski24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 703
  lastpage: 739
  published: 2024-03-15 00:00:00 +0000
- title: 'DiConStruct: Causal Concept-based Explanations through Black-Box Distillation'
  abstract: 'Model interpretability plays a central role in human-AI decision-making systems. Ideally, explanations should be expressed using human-interpretable semantic concepts. Moreover, the causal relations between these concepts should be captured by the explainer to allow for reasoning about the explanations. Lastly, explanation methods should be efficient and not compromise the predictive task performance. Despite the recent rapid advances in AI explainability, as far as we know, no method yet fulfills these three desiderata. Indeed, mainstream methods for local concept explainability do not yield causal explanations and incur a trade-off between explainability and prediction accuracy. We present DiConStruct, an explanation method that is both concept-based and causal, which produces more interpretable local explanations in the form of structural causal models and concept attributions. Our explainer works as a distillation model to any black-box machine learning model by approximating its predictions while producing the respective explanations. Consequently, DiConStruct generates explanations efficiently while not impacting the black-box prediction task. We validate our method on an image dataset and a tabular dataset, showing that DiConStruct approximates the black-box models with higher fidelity than other concept explainability baselines, while providing explanations that include the causal relations between the concepts.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/moreira24a.html
  PDF: https://proceedings.mlr.press/v236/moreira24a/moreira24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-moreira24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Ricardo Miguel de Oliveira
    family: Moreira
  - given: Jacopo
    family: Bono
  - given: Mário
    family: Cardoso
  - given: Pedro
    family: Saleiro
  - given: Mário A. T.
    family: Figueiredo
  - given: Pedro
    family: Bizarro
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 740-768
  id: moreira24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 740
  lastpage: 768
  published: 2024-03-15 00:00:00 +0000
- title: 'A causality-inspired  plus-minus model for player evaluation in team sports'
  abstract: 'We present a causality-inspired adjusted plus-minus model for evaluating individual players from their performance on a team. We take an explicitly causal approach to this problem, defining the value of a player to be the expected change in the score had we substituted the player for one who has zero value. (This quantity is “causal” in the sense that it is an inference about a hypothetical intervention.) We adapt recent ideas of factor modeling to handle the indirectly measured confounding in estimating player values, considering each player to be a “treatment” who contributes to the outcome of the game. We demonstrate the behavior of the model on data about soccer and basketball.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/bacco24a.html
  PDF: https://proceedings.mlr.press/v236/bacco24a/bacco24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-bacco24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Caterina De
    family: Bacco
  - given: Yixin
    family: Wang
  - given: David
    family: Blei
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 769-792
  id: bacco24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 769
  lastpage: 792
  published: 2024-03-15 00:00:00 +0000
- title: 'Inference of nonlinear causal effects with application to TWAS with GWAS summary data'
  abstract: 'Large-scale genome-wide association studies (GWAS) have offered an exciting opportunity to discover putative causal genes or risk factors associated with diseases by using SNPs as instrumental variables (IVs). However, conventional approaches assume linear causal relations partly for simplicity and partly for the availability of GWAS summary data. In this work, we propose a novel model for transcriptome-wide association studies (TWAS) to incorporate nonlinear relationships across IVs, an exposure/gene, and an outcome, which is robust against violations of the valid IV assumptions, permits the use of GWAS summary data, and covers two-stage least squares (2SLS) as a special case.  We decouple the estimation of a marginal causal effect and a nonlinear transformation, where the former is estimated via sliced inverse regression and a sparse instrumental variable regression, and the latter is estimated by a ratio-adjusted inverse regression. On this ground, we propose an inferential procedure. An application of the proposed method to the ADNI gene expression data and the IGAP GWAS summary data identifies 18 causal genes associated with Alzheimer’s disease, including APOE and TOMM40, in addition to 7 other genes missed by 2SLS considering only linear relationships. Our findings suggest that nonlinear modeling is required to unleash the power of IV regression for identifying potentially nonlinear gene-trait associations. The source code and accompanying software *nl-causal* can be accessed through the link: [https://github.com/statmlben/nonlinear-causal](https://github.com/statmlben/nonlinear-causal).'
  volume: 236
  URL: https://proceedings.mlr.press/v236/dai24a.html
  PDF: https://proceedings.mlr.press/v236/dai24a/dai24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-dai24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Ben
    family: Dai
  - given: Chunlin
    family: Li
  - given: Haoran
    family: Xue
  - given: Wei
    family: Pan
  - given: Xiaotong
    family: Shen
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 793-826
  id: dai24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 793
  lastpage: 826
  published: 2024-03-15 00:00:00 +0000
- title: 'Lifted Causal Inference in Relational Domains'
  abstract: 'Lifted inference exploits symmetries in probabilistic graphical models by using a representative for indistinguishable objects, thereby speeding up query answering while maintaining exact answers. Even though lifting is a well-established technique for the task of probabilistic inference in relational domains, it has not yet been applied to the task of causal inference. In this paper, we show how lifting can be applied to efficiently compute causal effects in relational domains. More specifically, we introduce parametric causal factor graphs as an extension of parametric factor graphs incorporating causal knowledge and give a formal semantics of interventions therein. We further present the lifted causal inference algorithm to compute causal effects on a lifted level, thereby drastically speeding up causal inference compared to propositional inference, e.g., in causal Bayesian networks. In our empirical evaluation, we demonstrate the effectiveness of our approach.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/luttermann24a.html
  PDF: https://proceedings.mlr.press/v236/luttermann24a/luttermann24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-luttermann24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Malte
    family: Luttermann
  - given: Mattis
    family: Hartwig
  - given: Tanya
    family: Braun
  - given: Ralf
    family: Möller
  - given: Marcel
    family: Gehrke
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 827-842
  id: luttermann24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 827
  lastpage: 842
  published: 2024-03-15 00:00:00 +0000
- title: 'Identifying Linearly-Mixed Causal Representations from Multi-Node Interventions'
  abstract: 'The task of inferring high-level causal variables from low-level observations, commonly referred to as <em>causal representation learning</em>, is fundamentally underconstrained. As such, recent works to address this problem focus on various assumptions that lead to identifiability of the underlying latent causal variables. A large corpus of these preceding approaches consider multi-environment data collected under different interventions on the causal model. What is common to virtually all of these works is the restrictive assumption that in each environment, only a single variable is intervened on. In this work, we relax this assumption and provide the first identifiability result for causal representation learning that allows for multiple variables to be targeted by an intervention within one environment. Our approach hinges on a general assumption on the coverage and diversity of interventions across environments, which also includes the shared assumption of single-node interventions of previous works. The main idea behind our approach is to exploit the trace that interventions leave on the variance of the ground truth causal variables and regularizing for a specific notion of sparsity with respect to this trace. In addition to and inspired by our theoretical contributions, we present a practical algorithm to learn causal representations from multi-node interventional data and provide empirical evidence that validates our identifiability results.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/bing24a.html
  PDF: https://proceedings.mlr.press/v236/bing24a/bing24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-bing24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Simon
    family: Bing
  - given: Urmi
    family: Ninad
  - given: Jonas
    family: Wahl
  - given: Jakob
    family: Runge
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 843-867
  id: bing24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 843
  lastpage: 867
  published: 2024-03-15 00:00:00 +0000
- title: 'Toward the Identifiability of Comparative Deep Generative Models'
  abstract: 'Deep Generative Models (DGMs) are versatile tools for learning data representations while adequately incorporating domain knowledge such as the specification of conditional probability distributions. Recently proposed DGMs tackle the important task of comparing data sets from different sources. One such example is the setting of contrastive analysis that focuses on describing patterns that are enriched in a target data set compared to a background data set. The practical deployment of those models often assumes that DGMs naturally infer interpretable and modular latent representations, which is known to be an issue in practice.  Consequently, existing methods often rely on ad-hoc regularization schemes, although without any theoretical grounding. Here, we propose a theory of identifiability for comparative DGMs by extending recent advances in the field of non-linear independent component analysis. We show that, while these models lack identifiability across a general class of mixing functions, they surprisingly become identifiable when the mixing function is piece-wise affine (e.g., parameterized by a ReLU neural network).  We also investigate the impact of model misspecification, and empirically show that previously proposed regularization techniques for fitting comparative DGMs help with identifiability when the number of latent variables is not known in advance. Finally, we introduce a novel methodology for fitting comparative DGMs that improves the treatment of multiple data sources via multi-objective optimization and that helps adjust the hyperparameter for the regularization in an interpretable manner, using constrained optimization. We empirically validate our theory and new methodology using simulated data as well as a recent data set of genetic perturbations in cells profiled via single-cell RNA sequencing.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/lopez24a.html
  PDF: https://proceedings.mlr.press/v236/lopez24a/lopez24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-lopez24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Romain
    family: Lopez
  - given: Jan-Christian
    family: Huetter
  - given: Ehsan
    family: Hajiramezanali
  - given: Jonathan K
    family: Pritchard
  - given: Aviv
    family: Regev
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 868-912
  id: lopez24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 868
  lastpage: 912
  published: 2024-03-15 00:00:00 +0000
- title: 'Estimating the Causal Effect of Early ArXiving on Paper Acceptance'
  abstract: 'What is the effect of releasing a preprint of a paper before it is submitted for peer review?   No randomized controlled trial has been conducted, so we turn to observational data to answer this question. We use data from the ICLR conference (2018–2022) and apply methods from causal inference to estimate the effect of arXiving a paper before the reviewing period (<em>early arXiving</em>) on its acceptance to the conference. Adjusting for confounders such as topic, authors, and quality, we may estimate the causal effect. However, since quality is a challenging construct to estimate, we use the <em>negative outcome control</em> method, using <em>paper citation count</em> as a control variable to debias the quality confounding effect. Our results suggest that early arXiving may have a small effect on a paper’s chances of acceptance. However, this effect (when existing) does not differ significantly across different groups of authors, as grouped by author citation count and institute rank. This suggests that early arXiving does not provide an advantage to any particular group.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/elazar24a.html
  PDF: https://proceedings.mlr.press/v236/elazar24a/elazar24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-elazar24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Yanai
    family: Elazar
  - given: Jiayao
    family: Zhang
  - given: David
    family: Wadden
  - given: Bo
    family: Zhang
  - given: Noah A.
    family: Smith
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 913-933
  id: elazar24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 913
  lastpage: 933
  published: 2024-03-15 00:00:00 +0000
- title: 'Sequential Deconfounding for Causal Inference with Unobserved Confounders'
  abstract: 'Observational data is often used to estimate the effect of a treatment when randomized experiments are infeasible or costly. However, observational data often yields biased estimates of treatment effects, since treatment assignment can be confounded by unobserved variables. A remedy is offered by deconfounding methods that adjust for such unobserved confounders. In this paper, we develop the Sequential Deconfounder, a method that enables estimating individualized treatment effects over time in presence of unobserved confounders. This is the first deconfounding method that can be used with a single treatment assigned at each timestep. The Sequential Deconfounder uses a novel Gaussian process latent variable model to infer substitutes for the unobserved confounders, which are then used in conjunction with an outcome model to estimate treatment effects over time. We prove that using our method yields unbiased estimates of individualized treatment responses over time. Using simulated and real medical data, we demonstrate the efficacy of our method in deconfounding the estimation of treatment responses over time.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/hatt24a.html
  PDF: https://proceedings.mlr.press/v236/hatt24a/hatt24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-hatt24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Tobias
    family: Hatt
  - given: Stefan
    family: Feuerriegel
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 934-956
  id: hatt24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 934
  lastpage: 956
  published: 2024-03-15 00:00:00 +0000
- title: 'The PetShop Dataset — Finding Causes of Performance Issues across Microservices'
  abstract: 'Identifying root causes for unexpected or undesirable behavior in complex systems is a prevalent challenge. This issue becomes especially crucial in modern cloud applications that employ numerous microservices. Although the machine learning and systems research communities have proposed various techniques to tackle this problem, there is currently a lack of standardized datasets for quantitative benchmarking. Consequently, research groups are compelled to create their own datasets for experimentation. This paper introduces a dataset specifically designed for evaluating root cause analyses in microservice-based applications. The dataset encompasses latency, requests, and availability metrics emitted in 5-minute intervals from a distributed application.  In addition to normal operation metrics, the dataset includes 68 injected performance issues, which increase latency and reduce availability throughout the system. We showcase how this dataset can be used to evaluate the accuracy of a variety of methods spanning different causal and non-causal characterisations of the root cause analysis problem.  We hope the new dataset, available at https://github.com/amazon-science/petshop-root-cause-analysis, enables further development of techniques in this important area.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/hardt24a.html
  PDF: https://proceedings.mlr.press/v236/hardt24a/hardt24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-hardt24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Michaela
    family: Hardt
  - given: William Roy
    family: Orchard
  - given: Patrick
    family: Blöbaum
  - given: Elke
    family: Kirschbaum
  - given: Shiva
    family: Kasiviswanathan
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 957-978
  id: hardt24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 957
  lastpage: 978
  published: 2024-03-15 00:00:00 +0000
- title: 'Bootstrap aggregation and confidence measures to improve time series causal discovery'
  abstract: 'Learning causal graphs from multivariate time series is an ubiquitous challenge in all application domains dealing with time-dependent systems, such as in Earth sciences, biology, or engineering, to name a few. Recent developments for this causal discovery learning task have shown considerable skill, notably the specific time-series adaptations of the popular conditional independence-based learning framework. However, uncertainty estimation is challenging for conditional independence- based methods. Here, we introduce a novel bootstrap approach designed for time series causal discovery that preserves the temporal dependencies and lag-structure. It can be combined with a range of time series causal discovery methods and provides a measure of confidence for the links of the time series graphs. Furthermore, next to confidence estimation, an aggregation, also called bagging, of the bootstrapped graphs by majority voting results in bagged causal discovery methods. In this work, we combine this approach with the state-of-the-art conditional-independence-based algorithm PCMCI+. With extensive numerical experiments we empirically demonstrate that, in addition to providing confidence measures for links, Bagged-PCMCI+ improves in precision and recall as compared to its base algorithm PCMCI+, at the cost of higher computational demands. These statistical performance improvements are especially pronounced in the more challenging settings (short time sample size, large number of variables, high autocorrelation). Our bootstrap approach can also be combined with other time series causal discovery algorithms and can be of considerable use in many real-world applications.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/debeire24a.html
  PDF: https://proceedings.mlr.press/v236/debeire24a/debeire24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-debeire24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Kevin
    family: Debeire
  - given: Andreas
    family: Gerhardus
  - given: Jakob
    family: Runge
  - given: Veronika
    family: Eyring
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 979-1007
  id: debeire24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 979
  lastpage: 1007
  published: 2024-03-15 00:00:00 +0000
- title: 'Low-Rank Approximation of Structural Redundancy for Self-Supervised Learning'
  abstract: 'We study the data-generating mechanism for reconstructive SSL to shed light on its effectiveness. With an infinite amount of labeled samples, we provide a sufficient and necessary condition for perfect linear approximation. The condition reveals a full-rank component that preserves the label classes of $Y$, along with a redundant component. Motivated by the condition, we propose to approximate the redundant component by a low-rank factorization and measure the approximation quality by introducing a new measure, $\epsilon_s$, parameterized by the rank of factorization $s$. We incorporate $\epsilon_s$ into the excess risk analysis under both linear regression and ridge regression settings, where the latter regularization approach is to handle scenarios when the dimension of the learned features is much larger than the number of labeled samples $n$ for downstream tasks. We design two stylized experiments to compare SSL with supervised learning (SL) under different settings to support our theoretical findings.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/du24a.html
  PDF: https://proceedings.mlr.press/v236/du24a/du24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-du24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Kang
    family: Du
  - given: Yu
    family: Xiang
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1008-1032
  id: du24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1008
  lastpage: 1032
  published: 2024-03-15 00:00:00 +0000
- title: 'Semiparametric Efficient Inference in Adaptive Experiments'
  abstract: 'We consider the problem of efficient inference of the <em>Average Treatment Effect</em> in a sequential experiment where the policy governing the assignment of subjects to treatment or control can change over time. We first provide a central limit theorem for the Adaptive Augmented Inverse-Probability Weighted estimator, which is semiparametric efficient, under weaker assumptions than those previously made in the literature. This central limit theorem enables efficient inference at fixed sample sizes. We then consider a sequential inference setting, deriving both asymptotic and nonasymptotic confidence sequences that are considerably tighter than previous methods. These anytime-valid methods enable inference under data-dependent stopping times (sample sizes). Additionally, we use propensity score truncation techniques from the recent off-policy estimation literature to reduce the finite sample variance of our estimator without affecting the asymptotic variance. Empirical results demonstrate that our methods yield narrower confidence sequences than those previously developed in the literature while maintaining time-uniform error control.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/cook24a.html
  PDF: https://proceedings.mlr.press/v236/cook24a/cook24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-cook24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Thomas
    family: Cook
  - given: Alan
    family: Mishler
  - given: Aaditya
    family: Ramdas
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1033-1064
  id: cook24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1033
  lastpage: 1064
  published: 2024-03-15 00:00:00 +0000
- title: 'Hyperparameter Tuning for Causal Inference with Double Machine Learning: A Simulation Study'
  abstract: 'Proper hyperparameter tuning is essential for achieving optimal performance of modern machine learning (ML) methods in predictive tasks. While there is an extensive literature on tuning ML learners for prediction, there is only littleguidance available on tuning ML learners for causal machine learning. In this paper, we investigate the role of hyperparameter tuning and other practical decisions for causal estimation as based on the Double Machine Learning approach by Chernozhukov et al. (2018). Double Machine Learning relies on estimating so-called nuisance parameters by treating them as supervised learning problems and using them as plug-in estimates to solve for the (causal) parameter. We conduct an extensive simulation study using data from the 2019 Atlantic Causal Inference Conference Data Challenge. We provide empirical insights on the selection and calibration of the ML methods for the performance of causal estimation. First, we assess the importance of data splitting schemes for tuning ML learners within Double Machine Learning. Second, we investigate the choice of ML methods and hyperparameters, including recent AutoML frameworks, and consider the relationship between their predictive power and the estimation performance for a causal parameter of interest. Third, we investigate to what extent the choice of a particular causal model, as characterized by incorporated parametric assumptions, can be based on predictive performance metrics.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/bach24a.html
  PDF: https://proceedings.mlr.press/v236/bach24a/bach24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-bach24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Philipp
    family: Bach
  - given: Oliver
    family: Schacht
  - given: Victor
    family: Chernozhukov
  - given: Sven
    family: Klaassen
  - given: Martin
    family: Spindler
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1065-1117
  id: bach24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1065
  lastpage: 1117
  published: 2024-03-15 00:00:00 +0000
- title: 'Scalable Counterfactual Distribution Estimation in Multivariate Causal Models'
  abstract: 'We consider the problem of estimating the counterfactual joint distribution of multiple quantities of interests (e.g., outcomes) in a multivariate causal model extended from the classical difference-in-difference design. Existing methods for this task either ignore the correlation structures among dimensions of the multivariate outcome by considering univariate causal models on each dimension separately and hence produce incorrect counterfactual distributions, or poorly scale even for moderate-size datasets when directly dealing with such a multivariate causal model. We propose a method that alleviates both issues simultaneously by leveraging a robust latent one-dimensional subspace of the original high-dimension space and exploiting the efficient estimation from the univariate causal model on such space. Since the construction of the one-dimensional subspace uses information from all the dimensions, our method can capture the correlation structures and produce good estimates of the counterfactual distribution. We demonstrate the advantages of our approach over existing methods on both synthetic and real-world data.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/pham24a.html
  PDF: https://proceedings.mlr.press/v236/pham24a/pham24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-pham24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Thong
    family: Pham
  - given: Shohei
    family: Shimizu
  - given: Hideitsu
    family: Hino
  - given: Tam
    family: Le
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1118-1140
  id: pham24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1118
  lastpage: 1140
  published: 2024-03-15 00:00:00 +0000
- title: 'Causal Imputation for Counterfactual SCMs:  Bridging Graphs and Latent Factor Models'
  abstract: 'We consider the task of <em>causal imputation</em>, where we aim to predict the outcomes of some set of actions across a wide range of possible contexts. As a running example, we consider predicting how different drugs affect cells from different cell types. We study the index-only setting, where the actions and contexts are categorical variables with a finite number of possible values. Even in this simple setting, a practical challenge arises, since often only a small subset of possible action-context pairs have been studied. Thus, models must extrapolate to novel action-context pairs, which can be framed as a form of matrix completion with rows indexed by actions, columns indexed by contexts, and matrix entries corresponding to outcomes. We introduce a novel SCM-based model class, where the outcome is expressed as a counterfactual, actions are expressed as interventions on an instrumental variable, and contexts are defined based on the initial state of the system. We show that, under a linearity assumption, this setup induces a <em>latent factor model</em> over the matrix of outcomes, with an additional fixed effect term. To perform causal prediction based on this model class, we introduce simple extension to the Synthetic Interventions estimator (Agarwal et al., 2020). We evaluate several matrix completion approaches on the PRISM drug repurposing dataset, showing that our method outperforms all other considered matrix completion approaches.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/ribot24a.html
  PDF: https://proceedings.mlr.press/v236/ribot24a/ribot24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-ribot24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Álvaro
    family: Ribot
  - given: Chandler
    family: Squires
  - given: Caroline
    family: Uhler
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1141-1175
  id: ribot24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1141
  lastpage: 1175
  published: 2024-03-15 00:00:00 +0000
- title: 'Causal Layering via Conditional Entropy'
  abstract: 'Causal discovery aims to recover information about an unobserved causal graph from the observable data it generates. Layerings are orderings of the variables which place causes before effects. In this paper, we provide ways to recover layerings of a graph by accessing the data via a conditional entropy oracle, when distributions are discrete. Our algorithms work by repeatedly removing sources or sinks from the graph. Under appropriate assumptions and conditioning, we can separate the sources or sinks from the remainder of the nodes by comparing their conditional entropy to the unconditional entropy of their noise. Our algorithms are provably correct and run in worst-case quadratic time. The main assumptions are faithfulness and injective noise, and either known noise entropies or weakly monotonically increasing noise entropies along directed paths. In addition, we require one of either a very mild extension of faithfulness, or strictly monotonically increasing noise entropies, or expanding noise injectivity to include an additional single argument in the structural functions.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/feigenbaum24a.html
  PDF: https://proceedings.mlr.press/v236/feigenbaum24a/feigenbaum24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-feigenbaum24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Itai
    family: Feigenbaum
  - given: Devansh
    family: Arpit
  - given: Shelby
    family: Heinecke
  - given: Juan Carlos
    family: Niebles
  - given: Weiran
    family: Yao
  - given: Caiming
    family: Xiong
  - given: Silvio
    family: Savarese
  - given: Huan
    family: Wang
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1176-1191
  id: feigenbaum24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1176
  lastpage: 1191
  published: 2024-03-15 00:00:00 +0000
- title: 'Meaningful Causal Aggregation and Paradoxical Confounding'
  abstract: 'In aggregated variables the impact of interventions is typically ill-defined because different micro-realizations of the same macro-intervention can result in different changes of downstream macro-variables. We show that this ill-definedness of causality on aggregated variables can turn unconfounded causal relations into confounded ones and vice versa, depending on the respective micro-realization. We argue that it is practically infeasible to only use aggregated causal systems when we are free from this ill-definedness.  Instead, we need to accept that macro causal relations are typically defined only with reference to the micro states. On the positive side, we show that cause-effect relations can be aggregated when the macro interventions are such that the distribution of micro states is the same as in the observational distribution; we term this natural macro interventions. We also discuss generalizations of this observation.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/zhu24a.html
  PDF: https://proceedings.mlr.press/v236/zhu24a/zhu24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-zhu24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Yuchen
    family: Zhu
  - given: Kailash
    family: Budhathoki
  - given: Jonas M.
    family: Kübler
  - given: Dominik
    family: Janzing
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1192-1217
  id: zhu24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1192
  lastpage: 1217
  published: 2024-03-15 00:00:00 +0000
- title: 'Causal discovery in a complex industrial system: A time series benchmark'
  abstract: 'Causal discovery outputs a causal structure, represented by a graph, from observed data. For time series data, there is a variety of methods, however, it is difficult to evaluate these on real data as realistic use cases very rarely come with a known causal graph to which output can be compared. In this paper, we present a dataset from an industrial subsystem at the European Spallation Source along with its causal graph which has been constructed from expert knowledge. This provides a testbed for causal discovery from time series observations of complex systems, and we believe this can help inform the development of causal discovery methodology.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/mogensen24a.html
  PDF: https://proceedings.mlr.press/v236/mogensen24a/mogensen24a.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-mogensen24a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Søren Wengel
    family: Mogensen
  - given: Karin
    family: Rathsman
  - given: Per
    family: Nilsson
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1218-1236
  id: mogensen24a
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1218
  lastpage: 1236
  published: 2024-03-15 00:00:00 +0000
- title: 'Causal Discovery with Mixed Linear and Nonlinear Additive Noise Models: A Scalable Approach'
  abstract: 'Estimating the structure of directed acyclic graphs (DAGs) from observational data is challenging due to the super-exponential growth of the search space with the number of nodes. Previous research primarily focuses on identifying a unique DAG under specific model constraints in linear or nonlinear scenarios. However, real-world scenarios often involve causal mechanisms with a mixture of linear and nonlinear characteristics, which has received limited attention in existing literature. Due to unidentifiability, existing algorithms relying on fully identifiable conditions may produce erroneous results. Although traditional methods like the PC algorithm can be employed to uncover such graphs, they typically yield only a Markov equivalence class. This paper introduces a novel causal discovery approach that extends beyond the Markov equivalence class, aiming to uncover as many edge directions as possible when the causal graph is not fully identifiable. Our approach exploits the second derivative of the log-likelihood in observational data, harnessing scalable machine learning approaches to approximate the score function. Overall, our approach demonstrates competitive accuracy comparable to current state-of-the-art techniques while offering a significant improvement in computational speed.'
  volume: 236
  URL: https://proceedings.mlr.press/v236/liu24b.html
  PDF: https://proceedings.mlr.press/v236/liu24b/liu24b.pdf
  edit: https://github.com/mlresearch//v236/edit/gh-pages/_posts/2024-03-15-liu24b.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of the Third Conference on Causal Learning and Reasoning'
  publisher: 'PMLR'
  author: 
  - given: Wenqin
    family: Liu
  - given: Biwei
    family: Huang
  - given: Erdun
    family: Gao
  - given: Qiuhong
    family: Ke
  - given: Howard
    family: Bondell
  - given: Mingming
    family: Gong
  editor: 
  - given: Francesco
    family: Locatello
  - given: Vanessa
    family: Didelez
  page: 1237-1263
  id: liu24b
  issued:
    date-parts: 
      - 2024
      - 3
      - 15
  firstpage: 1237
  lastpage: 1263
  published: 2024-03-15 00:00:00 +0000
