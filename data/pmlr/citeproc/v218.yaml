
- title: 'Preface: The 2023 ACM SIGKDD Workshop on Causal Discovery, Prediction and Decision '
  abstract: 'Preface to the 2023 KDD Workshop on Causal Discovery, Prediction and Decision (CDPD 2023)'
  volume: 218
  URL: https://proceedings.mlr.press/v218/le23a.html
  PDF: https://proceedings.mlr.press/v218/le23a/le23a.pdf
  edit: https://github.com/mlresearch//v218/edit/gh-pages/_posts/2023-07-25-le23a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The KDD''23 Workshop on Causal Discovery, Prediction and Decision'
  publisher: 'PMLR'
  author: 
  - given: Thuc
    family: Le
  - given: Jiuyong
    family: Li
  - given: Robert
    family: Ness
  - given: Sofia
    family: Triantafillou
  - given: Shohei
    family: Shimizu
  - given: Peng
    family: Cui
  - given: Kun
    family: Kuang
  - given: Jian
    family: Pei
  - given: Fei
    family: Wang
  - given: Mattia
    family: Prosperi
  editor: 
  - given: Thuc
    family: Le
  - given: Jiuyong
    family: Li
  - given: Robert
    family: Ness
  - given: Sofia
    family: Triantafillou
  - given: Shohei
    family: Shimizu
  - given: Peng
    family: Cui
  - given: Kun
    family: Kuang
  - given: Jian
    family: Pei
  - given: Fei
    family: Wang
  - given: Mattia
    family: Prosperi
  page: 1-2
  id: le23a
  issued:
    date-parts: 
      - 2023
      - 7
      - 25
  firstpage: 1
  lastpage: 2
  published: 2023-07-25 00:00:00 +0000
- title: 'Causally Learning an Optimal Rework Policy '
  abstract: ' In manufacturing, rework refers to an optional step of a production process which aims to eliminate errors or remedy products that do not meet the desired quality standards. Reworking a production lot involves repeating a previous production stage with adjustments to ensure that the final product meets the required specifications. While offering the chance to improve the yield and thus increase the revenue of a production lot, a rework step also incurs additional costs. Additionally, the rework of parts that already meet the target specifications may damage them and decrease the yield. In this paper, we apply double/debiased machine learning (DML) to estimate the conditional treatment effect of a rework step during the color conversion process in optoelectronic semiconductor manufacturing on the final product yield. We utilize the implementation DoubleML to develop policies for the rework of components and estimate their value empirically. From our causal machine learning analysis we derive implications for the coating of monochromatic LEDs with conversion layers.'
  volume: 218
  URL: https://proceedings.mlr.press/v218/schacht23a.html
  PDF: https://proceedings.mlr.press/v218/schacht23a/schacht23a.pdf
  edit: https://github.com/mlresearch//v218/edit/gh-pages/_posts/2023-07-25-schacht23a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The KDD''23 Workshop on Causal Discovery, Prediction and Decision'
  publisher: 'PMLR'
  author: 
  - given: Oliver
    family: Schacht
  - given: Sven
    family: Klaassen
  - given: Philipp
    family: Schwarz
  - given: Martin
    family: Spindler
  - given: Daniel
    family: Grunbaum
  - given: Sebastian
    family: Imhof
  editor: 
  - given: Thuc
    family: Le
  - given: Jiuyong
    family: Li
  - given: Robert
    family: Ness
  - given: Sofia
    family: Triantafillou
  - given: Shohei
    family: Shimizu
  - given: Peng
    family: Cui
  - given: Kun
    family: Kuang
  - given: Jian
    family: Pei
  - given: Fei
    family: Wang
  - given: Mattia
    family: Prosperi
  page: 3-24
  id: schacht23a
  issued:
    date-parts: 
      - 2023
      - 7
      - 25
  firstpage: 3
  lastpage: 24
  published: 2023-07-25 00:00:00 +0000
- title: 'Leveraging covariate adjustments at scale in online A/B testing'
  abstract: 'Companies offering web services routinely run randomized online experiments to estimate the “causal impact” associated with the adoption of new features and policies on key performance metrics of interest. These experiments are used to estimate a variety of effects: the increase in click rate due to the repositioning of a banner, the impact on subscription rate as a consequence of a discount or special offer, etc. In these settings, even effects whose sizes are very small can have large downstream impacts. The simple difference in means estimator (Splawa-Neyman et al., 1923/1990) is still the standard estimator of choice for many online A/B testing platforms due to its simplicity. This method, however, can fail to detect small effects, even when the experiment contains thousands or millions of observational units. As a byproduct of these experiments, however, large amounts of additional data (covariates) are collected. In this paper, we discuss benefits, costs and risks of allowing experimenters to leverage more complicated estimators that make use of covariates when estimating causal effects of interest. We adapt a recently proposed general-purpose algorithm for the estimation of causal effects with covariates to the setting of online A/B testing. Through this paradigm, we implement several covariate-adjusted causal estimators. We thoroughly evaluate their performance at scale, highlighting benefits and shortcomings of different methods. We show on real experiments how “covariate- adjusted” estimators can (i) lead to more precise quantification of the causal effects of interest and (ii) fix issues related to imbalance across treatment arms — a practical concern often overlooked in the literature. In turn, (iii) these more precise estimates can reduce experimentation time, cutting cost and helping to streamline decision-making processes, allowing for faster adoption of beneficial interventions.'
  volume: 218
  URL: https://proceedings.mlr.press/v218/masoero23a.html
  PDF: https://proceedings.mlr.press/v218/masoero23a/masoero23a.pdf
  edit: https://github.com/mlresearch//v218/edit/gh-pages/_posts/2023-07-25-masoero23a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The KDD''23 Workshop on Causal Discovery, Prediction and Decision'
  publisher: 'PMLR'
  author: 
  - given: Lorenzo
    family: Masoero
  - given: Doug
    family: Hains
  - given: James
    family: McQueen
  editor: 
  - given: Thuc
    family: Le
  - given: Jiuyong
    family: Li
  - given: Robert
    family: Ness
  - given: Sofia
    family: Triantafillou
  - given: Shohei
    family: Shimizu
  - given: Peng
    family: Cui
  - given: Kun
    family: Kuang
  - given: Jian
    family: Pei
  - given: Fei
    family: Wang
  - given: Mattia
    family: Prosperi
  page: 25-48
  id: masoero23a
  issued:
    date-parts: 
      - 2023
      - 7
      - 25
  firstpage: 25
  lastpage: 48
  published: 2023-07-25 00:00:00 +0000
- title: 'Stable Prediction on Graphs with Agnostic Distribution Shifts'
  abstract: 'Most graph neural networks (GNNs) are proposed and evaluated under independent and identically distributed (IID) training and testing data. In real-world applications, however, agnostic distribution shifts from training to testing naturally exist, leading to unstable prediction of traditional GNNs. To bridge the gap, we pursue stable prediction on graphs, i.e., to achieve high average performance and low performance variance (stability) across non-IID testing graphs. The key to stable prediction lies in capturing stable properties that are resilient to distribution shifts. In this light, we aim to identify neighbor nodes (properties) in neighborhood aggregation that are consistently important for prediction under heterogeneous distribution shifts. To achieve this target, we propose a model-agnostic stable learning framework for GNNs. The framework performs biased selection on the observed training graph, resulting in multiple non-IID graph subsets. We train one weight predictor per subset to measure the importance of properties under a particular distribution shift, and multiple predictors could tell the properties that are consistently important. An important property should contribute to high average performance and also stability (low performance variance) across non-IID subsets. In this regard, in training importance predictors, we introduce a globally stable regularizer to reduce the variance of training losses across non-IID graph datasets. Based on the importance weights of properties across non- IID subsets, a locally stable regularizer down-weights unstable properties in prediction. We conduct extensive experiments on several graph benchmarks and a noisy industrial recommendation dataset where distribution shifts exist. The results demonstrate that our method outperforms various state-of-the-art GNNs for stable prediction on graphs with agnostic distribution shifts.'
  volume: 218
  URL: https://proceedings.mlr.press/v218/zhang23a.html
  PDF: https://proceedings.mlr.press/v218/zhang23a/zhang23a.pdf
  edit: https://github.com/mlresearch//v218/edit/gh-pages/_posts/2023-07-25-zhang23a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The KDD''23 Workshop on Causal Discovery, Prediction and Decision'
  publisher: 'PMLR'
  author: 
  - given: Shengyu
    family: Zhang
  - given: Yunze
    family: Tong
  - given: Kun
    family: Kuang
  - given: Fuli
    family: Feng
  - given: Jiezhong
    family: Qiu
  - given: Jin
    family: Yu
  - given: Zhou
    family: Zhao
  - given: Hongxia
    family: Yang
  - given: Zhongfei
    family: Zhang
  - given: Fei
    family: Wu
  editor: 
  - given: Thuc
    family: Le
  - given: Jiuyong
    family: Li
  - given: Robert
    family: Ness
  - given: Sofia
    family: Triantafillou
  - given: Shohei
    family: Shimizu
  - given: Peng
    family: Cui
  - given: Kun
    family: Kuang
  - given: Jian
    family: Pei
  - given: Fei
    family: Wang
  - given: Mattia
    family: Prosperi
  page: 49-74
  id: zhang23a
  issued:
    date-parts: 
      - 2023
      - 7
      - 25
  firstpage: 49
  lastpage: 74
  published: 2023-07-25 00:00:00 +0000
- title: 'Towards Optimization and Model Selection for Domain Generalization: A Mixup-guided Solution'
  abstract: 'The distribution shifts between training and test data typically undermine the performance of deep learning models. In recent years, lots of work pays attention to domain generaliza- tion (DG) where distribution shift exists and target data are unseen. Despite the progress in algorithm design, two foundational factors have long been ignored: 1) the optimization for regularization-based objectives (e.g., distribution alignment), and 2) the model selection for DG since no knowledge about the target domain can be utilized. In this paper, we pro- pose Mixup guided optimization and selection techniques for domain generalization. For optimization, we utilize an adapted Mixup to generate an out-of-distribution dataset that can guide the preference direction and optimize with Pareto optimization. For model selec- tion, we generate a validation dataset with a closer distance to the target distribution, and thereby it can better represent the target data. We also present some theoretical insights behind our proposals. Comprehensive experiments on one visual classification benchmark and three time-series benchmarks demonstrate that our model optimization and selection techniques can largely improve the performance of existing domain generalization algo- rithms and even achieve new state-of-the-art results.'
  volume: 218
  URL: https://proceedings.mlr.press/v218/lu23a.html
  PDF: https://proceedings.mlr.press/v218/lu23a/lu23a.pdf
  edit: https://github.com/mlresearch//v218/edit/gh-pages/_posts/2023-07-25-lu23a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The KDD''23 Workshop on Causal Discovery, Prediction and Decision'
  publisher: 'PMLR'
  author: 
  - given: Wang
    family: Lu
  - given: Wang
    family: Wang
  - given: Jindong
    family: Yidong
  - given: Xing
    family: Xie
  editor: 
  - given: Thuc
    family: Le
  - given: Jiuyong
    family: Li
  - given: Robert
    family: Ness
  - given: Sofia
    family: Triantafillou
  - given: Shohei
    family: Shimizu
  - given: Peng
    family: Cui
  - given: Kun
    family: Kuang
  - given: Jian
    family: Pei
  - given: Fei
    family: Wang
  - given: Mattia
    family: Prosperi
  page: 75-97
  id: lu23a
  issued:
    date-parts: 
      - 2023
      - 7
      - 25
  firstpage: 75
  lastpage: 97
  published: 2023-07-25 00:00:00 +0000
- title: 'Optimizing Dynamic Antibiotic Treatment Strategies against Invasive Methicillin-Resistant Staphylococcus Aureus Infections using Causal Survival Forests and G-Formula on Statewide Electronic Health Record Data'
  abstract: 'Developing models for individualized, time-varying treatment optimization from observational data with large variable spaces, e.g., electronic health records (EHR), is problematic because of inherent, complex bias that can change over time. Traditional methods such as the g-formula are robust, but must identify critical subsets of variables due to combinatorial issues. Machine learning approaches such as causal survival forests have fewer constraints and can provide fine-tuned, individualized counterfactual predictions. In this study, we aimed to optimize time-varying antibiotic treatment –identifying treatment heterogeneity and conditional treatment effects– against invasive methicillin-resistant Staphylococcus Aureus (MRSA) infections, using statewide EHR data collected in Florida, USA. While many previous studies focused on measuring the effects of the first empiric treatment (i.e., usually vancomycin), our study focuses on dynamic sequential treatment changes, comparing possible vancomycin switches with other antibiotics at clinically relevant time points, e.g., after obtaining a bacterial culture and susceptibility testing. Our study population included adult individuals admitted to the hospital with invasive MRSA. We collected demographic, clinical, medication, and laboratory information from the EHR for these patients. Then, we followed three sequential antibiotic choices (i.e., their empiric treatment, subsequent directed treatment, and final sustaining treatment), evaluating 30-day mortality as the outcome. We applied both causal survival forests and g-formula using different clinical intervention policies. We found that switching from vancomycin to another antibiotic im- proved survival probability, yet there was a benefit from initiating vancomycin compared to not using it at any time point. These findings show consistency with the empiric choice of vancomycin before confirmation of MRSA and shed light on how to manage switches on course. In conclusion, this application of causal machine learning on EHR demonstrates utility in modeling dynamic, heterogeneous treatment effects that cannot be evaluated precisely using randomized clinical trials.'
  volume: 218
  URL: https://proceedings.mlr.press/v218/jun23a.html
  PDF: https://proceedings.mlr.press/v218/jun23a/jun23a.pdf
  edit: https://github.com/mlresearch//v218/edit/gh-pages/_posts/2023-07-25-jun23a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The KDD''23 Workshop on Causal Discovery, Prediction and Decision'
  publisher: 'PMLR'
  author: 
  - given: Inyoung
    family: Jun
  - given: Scott A.
    family: Cohen
  - given: Sarah E.
    family: Ser
  - given: Simone
    family: Marini
  - given: Robert J.
    family: Lucero
  - given: Jiang
    family: Bian
  - given: Mattia
    family: Prosperi
  editor: 
  - given: Thuc
    family: Le
  - given: Jiuyong
    family: Li
  - given: Robert
    family: Ness
  - given: Sofia
    family: Triantafillou
  - given: Shohei
    family: Shimizu
  - given: Peng
    family: Cui
  - given: Kun
    family: Kuang
  - given: Jian
    family: Pei
  - given: Fei
    family: Wang
  - given: Mattia
    family: Prosperi
  page: 98-115
  id: jun23a
  issued:
    date-parts: 
      - 2023
      - 7
      - 25
  firstpage: 98
  lastpage: 115
  published: 2023-07-25 00:00:00 +0000
- title: 'Bias-Variance Tradeoffs for Designing Simultaneous Temporal Experiments'
  abstract: 'We study the analysis and design of simultaneous temporal experiments, where a set of interventions are applied concurrently in continuous time, and outcomes are measured on a sequence of events observed in time. As a motivating setting, suppose multiple data science teams are conducting experiments simultaneously and independently on a ride- hailing platform to test changes to marketplace algorithms such as pricing and matching, and estimating effects from observed event outcomes such as the rate at which ride requests are completed. The design problem involves partitioning a continuous space of time into intervals and assigning treatments at the interval level. Design and analysis must account for three factors: carryover effects from interventions at earlier times, correlation in event outcomes, and effects of interventions tested simultaneously. We provide simulations to build intuition and guidance for practitioners.'
  volume: 218
  URL: https://proceedings.mlr.press/v218/xiong23a.html
  PDF: https://proceedings.mlr.press/v218/xiong23a/xiong23a.pdf
  edit: https://github.com/mlresearch//v218/edit/gh-pages/_posts/2023-07-25-xiong23a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The KDD''23 Workshop on Causal Discovery, Prediction and Decision'
  publisher: 'PMLR'
  author: 
  - given: Ruoxuan
    family: Xiong
  - given: Alex
    family: Chin
  - given: Sean
    family: Taylor
  editor: 
  - given: Thuc
    family: Le
  - given: Jiuyong
    family: Li
  - given: Robert
    family: Ness
  - given: Sofia
    family: Triantafillou
  - given: Shohei
    family: Shimizu
  - given: Peng
    family: Cui
  - given: Kun
    family: Kuang
  - given: Jian
    family: Pei
  - given: Fei
    family: Wang
  - given: Mattia
    family: Prosperi
  page: 115-131
  id: xiong23a
  issued:
    date-parts: 
      - 2023
      - 7
      - 25
  firstpage: 115
  lastpage: 131
  published: 2023-07-25 00:00:00 +0000
