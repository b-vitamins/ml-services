
- title: 'Preface'
  abstract: 'Preface to MIDL 2022'
  volume: 172
  URL: https://proceedings.mlr.press/v172/konukoglu22a.html
  PDF: https://proceedings.mlr.press/v172/konukoglu22a/konukoglu22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-konukoglu22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1-4
  id: konukoglu22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1
  lastpage: 4
  published: 2022-12-04 00:00:00 +0000
- title: 'Explainability Guided COVID-19 Detection in CT Scans'
  abstract: 'Radiological examination of chest CT is an effective method for screening COVID-19 cases. In this work, we overcome three challenges in the automation of this process: (i) the limited number of supervised positive cases, (ii) the lack of region-based supervision, and (iii) variability across acquisition sites. These challenges are met by incorporating a recent augmentation solution called SnapMix, a novel explainability-driven contrastive loss for patch embedding, and by performing  test-time augmentation that masks out the most relevant patches in order to  analyse the prediction stability. The three techniques are complementary and are all based on utilizing the heatmaps produced by the Class Activation Mapping (CAM) explainability method. State-of-the-art performance is obtained on three different datasets for COVID detection in CT scans.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/ali22a.html
  PDF: https://proceedings.mlr.press/v172/ali22a/ali22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-ali22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Ameen
    family: Ali
  - given: Tal
    family: Shaharabany
  - given: Lior
    family: Wolf
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 5-21
  id: ali22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 5
  lastpage: 21
  published: 2022-12-04 00:00:00 +0000
- title: 'Learning Shape Reconstruction from Sparse Measurements with Neural Implicit Functions'
  abstract: 'Reconstructing anatomical shapes from sparse or partial measurements relies on prior knowledge of shape variations that occur within a given population. Such shape priors are learned from example shapes, obtained by segmenting volumetric medical images. For existing models, the resolution of a learned shape prior is limited to the resolution of the training data. However, in clinical practice, volumetric images are often acquired with highly anisotropic voxel sizes, e.g. to reduce image acquisition time in MRI or radiation exposure in CT imaging. The missing shape information between the slices prohibits existing methods to learn a high-resolution shape prior. We introduce a method for high-resolution shape reconstruction from sparse measurements without relying on high-resolution ground truth for training. Our method is based on neural implicit shape representations and learns a continuous shape prior only from highly anisotropic segmentations. Furthermore, it is able to learn from shapes with a varying field of view and can reconstruct from various sparse input configurations. We demonstrate its effectiveness on two anatomical structures: vertebra and distal femur, and successfully reconstruct high-resolution shapes from sparse segmentations, using as few as three orthogonal slices.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/amiranashvili22a.html
  PDF: https://proceedings.mlr.press/v172/amiranashvili22a/amiranashvili22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-amiranashvili22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Tamaz
    family: Amiranashvili
  - given: David
    family: Lüdke
  - given: Hongwei Bran
    family: Li
  - given: Bjoern
    family: Menze
  - given: Stefan
    family: Zachow
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 22-34
  id: amiranashvili22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 22
  lastpage: 34
  published: 2022-12-04 00:00:00 +0000
- title: 'ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation'
  abstract: 'Automatic segmentation of lung lesions associated with COVID-19 in CT images requires large amount of annotated volumes. Annotations mandate expert knowledge and are time-intensive to obtain through fully manual segmentation methods. Additionally, lung lesions have large inter-patient variations, with some pathologies having similar visual appearance as healthy lung tissues. This poses a challenge when applying existing semi-automatic interactive segmentation techniques for data labelling. To address these challenges, we propose an efficient convolutional neural networks (CNNs) that can be learned online while the annotator provides scribble-based interaction. To accelerate learning from only the samples labelled through user-interactions, a patch-based approach is used for training the network. Moreover, we use weighted cross-entropy loss to address the class imbalance that may result from user-interactions. During online inference, the learned network is applied to the whole input volume using a fully convolutional approach. We compare our proposed method with state-of-the-art using synthetic scribbles and show that it outperforms existing methods on the task of annotating lung lesions associated with COVID-19, achieving 16% higher Dice score while reducing execution time by 3× and requiring 9000 lesser scribble-sbased labelled voxels. Due to the online learning aspect, our approach adapts quickly to user input, resulting in high quality segmentation labels. Source code for ECONet is available at: https://github.com/masadcv/ECONet-MONAILabel.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/asad22a.html
  PDF: https://proceedings.mlr.press/v172/asad22a/asad22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-asad22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Muhammad
    family: Asad
  - given: Lucas
    family: Fidon
  - given: Tom
    family: Vercauteren
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 35-47
  id: asad22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 35
  lastpage: 47
  published: 2022-12-04 00:00:00 +0000
- title: 'SMU-Net: Style matching U-Net for brain tumor segmentation with missing modalities'
  abstract: 'Gliomas are one of the most prevalent types of primary brain tumors, accounting for more than 30% of all cases and they develop from the glial stem or progenitor cells. In theory, the majority of brain tumors could well be identified exclusively by the use of Magnetic Resonance Imaging (MRI). Each MRI modality delivers distinct information on the soft tissue of the human brain and integrating all of them would provide comprehensive data for the accurate segmentation of the glioma, which is crucial for the patient’s prognosis, diagnosis, and determining the best follow-up treatment. Unfortunately, MRI is prone to artifacts for a variety of reasons, which might result in missing one or more MRI modalities. Various strategies have been proposed over the years to synthesize the missing modality or compensate for the influence it has on automated segmentation models. However, these methods usually fail to model the underlying missing information. In this paper, we propose a style matching U-Net (SMU-Net) for brain tumour segmentation on MRI images. Our co-training approach utilizes a content and style-matching mechanism to distill the informative features from the full-modality network into a missing modality network. To do so, we encode both full-modality and missing-modality data into a latent space, then we decompose the representation space into a style and content representation.  Our style matching module adaptively recalibrates the representation space by learning a matching function to transfer the informative and textural features from full-modality path into a missing-modality path. Moreover, by modelling the mutual information, our content module surpasses the less informative features and re-calibrates the representation space based on discriminative semantic features. The evaluation process on the BraTS 2018 dataset shows the significance of the proposed method on the missing modality scenario.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/azad22a.html
  PDF: https://proceedings.mlr.press/v172/azad22a/azad22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-azad22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Reza
    family: Azad
  - given: Nika
    family: Khosravi
  - given: Dorit
    family: Merhof
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 48-62
  id: azad22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 48
  lastpage: 62
  published: 2022-12-04 00:00:00 +0000
- title: 'On learning adaptive acquisition policies for undersampled multi-coil MRI reconstruction'
  abstract: 'Most current approaches to undersampled multi-coil MRI reconstruction focus on learning the reconstruction model for a fixed, equidistant acquisition trajectory. In this paper, we study the problem of joint learning of the reconstruction model together with acquisition policies. To this end, we extend the End-to-End Variational Network with learnable acquisition policies that can adapt to different data points. We validate our model on a coil-compressed version of the large scale undersampled multi-coil fastMRI dataset using two undersampling factors: $4\times$ and $8\times$. Our experiments show on-par performance with the learnable non-adaptive and handcrafted equidistant strategies at $4\times$, and an observed improvement of more than $2%$ in SSIM at $8\times$ acceleration, suggesting that potentially-adaptive $k$-space acquisition trajectories can improve reconstructed image quality for larger acceleration factors. However, and perhaps surprisingly, our best performing policies learn to be explicitly non-adaptive.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/bakker22a.html
  PDF: https://proceedings.mlr.press/v172/bakker22a/bakker22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-bakker22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Tim
    family: Bakker
  - given: Matthew
    family: Muckley
  - given: Adriana
    family: Romero-Soriano
  - given: Michal
    family: Drozdzal
  - given: Luis
    family: Pineda
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 63-85
  id: bakker22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 63
  lastpage: 85
  published: 2022-12-04 00:00:00 +0000
- title: 'Learning to Automatically Generate Accurate ECG Captions'
  abstract: 'The electrocardiogram (ECG) is an affordable, non-invasive and quick method to gain essential information about the electrical activity of the heart. Interpreting ECGs is a time-consuming process even for experienced cardiologists, which motivates the current usage of rule-based methods in clinical practice to automatically describe ECGs. However, in comparison with descriptions created by experts, ECG-descriptions generated by such rule-based methods show considerable limitations. Inspired by image captioning methods, we instead propose a data-driven approach for ECG description generation. We introduce a label-guided Transformer model, and show that it is possible to automatically generate relevant and readable ECG descriptions with a data-driven captioning model. We incorporate prior ECG labels into our model design, and show this improves the overall quality of generated descriptions. We find that training these models on free-text annotations of ECGs - instead of the clinically-used computer generated ECG descriptions - greatly improves performance. Moreover, we perform a human expert evaluation study of our best system, which shows that our data-driven approach improves upon existing rule-based methods.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/bartels22a.html
  PDF: https://proceedings.mlr.press/v172/bartels22a/bartels22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-bartels22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Mathieu G. G.
    family: Bartels
  - given: Ivona
    family: Najdenkoska
  - given: Rutger R
    prefix: van de
    family: Leur
  - given: Arjan
    family: Sammani
  - given: Karim
    family: Taha
  - given: David M
    family: Knigge
  - given: Pieter A
    family: Doevendans
  - given: Marcel
    family: Worring
  - given: René
    prefix: van
    family: Es
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 86-102
  id: bartels22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 86
  lastpage: 102
  published: 2022-12-04 00:00:00 +0000
- title: 'Negative Evidence Matters in Interpretable Histology Image Classification'
  abstract: 'Using only global image-class labels, weakly-supervised learning methods, such as class activation mapping, allow training CNNs to jointly classify an image, and locate regions of interest associated with the predicted class. However, without any guidance at the pixel level, such methods may yield inaccurate regions. This problem is known to be more challenging with histology images than with natural ones, since objects are less salient, structures have more variations, and foreground and background regions have stronger similarities. Therefore, computer vision methods for visual interpretation of CNNs may not directly apply. In this paper, a simple yet efficient method based on a composite loss is proposed to learn information from the fully negative samples (i.e., samples without positive regions), and thereby reduce false positives/negatives. Our new loss function contains two complementary terms: the first exploits positive evidence collected from the CNN classifier, while the second leverages the fully negative samples from training data. In particular, a pre-trained CNN is equipped with a decoder that allows refining the regions of interest. The CNN is exploited to collect both positive and negative evidence at the pixel level to train the decoder. Our method called NEGEV benefits from the fully negative samples that naturally occur in the data, without any additional supervision signals beyond image-class labels. Extensive experiments show that our proposed method can substantial outperform related state-of-art methods on GlaS (public benchmark for colon cancer), and Camelyon16 (patch-based benchmark for breast cancer using three different backbones). Our results highlight the benefits of using both positive and negative evidence, the first obtained from a classifier, and the other naturally available in datasets.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/belharbi22a.html
  PDF: https://proceedings.mlr.press/v172/belharbi22a/belharbi22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-belharbi22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Soufiane
    family: Belharbi
  - given: Marco
    family: Pedersoli
  - given: Ismail
    family: Ben Ayed
  - given: Luck
    family: McCaffrey
  - given: Eric
    family: Granger
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 103-129
  id: belharbi22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 103
  lastpage: 129
  published: 2022-12-04 00:00:00 +0000
- title: 'Interpretable and Interactive Deep Multiple Instance Learning for Dental Caries Classification in Bitewing X-rays'
  abstract: 'We propose a simple and efficient image classification architecture based on deep multiple instance learning, and apply it to the challenging task of caries detection in dental radiographs. Technically, our approach contributes in two ways: First, it outputs a heatmap of local patch classification probabilities despite being trained with weak image-level labels. Second, it is amenable to learning from segmentation labels to guide training. In contrast to existing methods, the human user can faithfully interpret predictions and interact with the model to decide which regions to attend to. Experiments are conducted on a large clinical dataset of 38k bitewings (316k teeth), where we achieve competitive performance compared to various baselines. When guided by an external caries segmentation model, a significant improvement in classification and localization performance is observed.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/bergner22a.html
  PDF: https://proceedings.mlr.press/v172/bergner22a/bergner22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-bergner22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Benjamin
    family: Bergner
  - given: Csaba
    family: Rohrer
  - given: Aiham
    family: Taleb
  - given: Martha
    family: Duchrau
  - given: Guilherme
    family: De Leon
  - given: Jonas
    family: Rodrigues
  - given: Falk
    family: Schwendicke
  - given: Joachim
    family: Krois
  - given: Christoph
    family: Lippert
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 130-149
  id: bergner22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 130
  lastpage: 149
  published: 2022-12-04 00:00:00 +0000
- title: 'Bridging the Gap: Point Clouds for Merging Neurons in Connectomics'
  abstract: 'In the field of connectomics, a primary problem is that of 3D neuron segmentation. Although deep learning-based methods have achieved remarkable accuracy, errors still exist, especially in regions with image defects. One common type of defect is that of consecutive missing image sections. Here, data is lost along some axis, and the resulting neuron segmentations are split across the gap. To address this problem, we propose a novel method based on point cloud representations of neurons. We formulate the problem as a classification problem and train CurveNet, a state-of-the-art point cloud classification model, to identify which neurons should be merged. We show that our method not only performs well but scales reasonably to large gaps which no other automated method as attempted to solve. Additionally, our point cloud representations are robust to downsampling, allowing us to maintain strong performance with significantly faster training and less GPU memory usage. We believe that this is an indicator of the viability of using point cloud representations for other proofreading tasks.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/berman22a.html
  PDF: https://proceedings.mlr.press/v172/berman22a/berman22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-berman22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Jules
    family: Berman
  - given: Dmitri B.
    family: Chklovskii
  - given: Jingpeng
    family: Wu
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 150-159
  id: berman22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 150
  lastpage: 159
  published: 2022-12-04 00:00:00 +0000
- title: 'Position Regression for Unsupervised Anomaly Detection'
  abstract: 'In recent years, anomaly detection has become an essential field in medical image  analysis. Most current anomaly detection methods for medical images are based on image reconstruction. In this work, we propose a novel anomaly detection approach based on coordinate regression. Our method  estimates the position of patches within a volume, and is trained only on data of healthy subjects. During inference, we can detect and localize anomalies by considering the error of the position estimate of a given patch. We apply our method to 3D CT volumes and evaluate it on patients with intracranial haemorrhages and cranial fractures. The results show that our method performs well in detecting these anomalies. Furthermore, we show that our method requires less memory than comparable approaches that involve image reconstruction. This is highly relevant for processing large 3D volumes, for instance, CT or MRI scans.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/bieder22a.html
  PDF: https://proceedings.mlr.press/v172/bieder22a/bieder22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-bieder22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Florentin
    family: Bieder
  - given: Julia
    family: Wolleb
  - given: Robin
    family: Sandkühler
  - given: Philippe C.
    family: Cattin
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 160-172
  id: bieder22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 160
  lastpage: 172
  published: 2022-12-04 00:00:00 +0000
- title: 'Domain adaptation through anatomical constraints for 3d human pose estimation under the cover'
  abstract: 'Domain adaptation has the potential to overcome the expensive or even infeasible labeling of target data by transferring knowledge from a labeled source domain. In this work, we address domain adaptation in the context of point cloud-based 3D human pose estimation, whose clinical applicability is severely limited by a lack of labeled training data. Unlike the mainstream approach of domain-invariant feature learning, we propose to guide the learning process in the target domain through weak supervision, based on prior knowledge about human anatomy. We embed this prior knowledge into a novel loss function that encourages network predictions to match the statistics of an anatomically plausible skeleton. Specifically, we formulate three loss functions that penalize asymmetric limb lengths, implausible joint angles, and implausible bone lengths. We evaluate the method on a public lying pose dataset (SLP), adapting from uncovered patients in the source to covered patients in the target domain. Our method outperforms diverse state-of-the-art domain adaptation techniques and improves the baseline model by 26% while reducing the gap to a fully supervised model by 54%. Source code is available at https://github.com/multimodallearning/da-3dhpe-anatomy.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/bigalke22a.html
  PDF: https://proceedings.mlr.press/v172/bigalke22a/bigalke22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-bigalke22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Alexander
    family: Bigalke
  - given: Lasse
    family: Hansen
  - given: Jasper
    family: Diesel
  - given: Mattias P
    family: Heinrich
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 173-187
  id: bigalke22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 173
  lastpage: 187
  published: 2022-12-04 00:00:00 +0000
- title: 'Differentiable Boundary Point Extraction for Weakly Supervised Star-shaped Object Segmentation'
  abstract: 'Although Deep Learning is the new gold standard in medical image segmentation,
the annotation burden limits its expansion to clinical practice. We also observe a mismatch between
annotations required by deep learning methods designed with pixel-wise optimization in
mind and clinically relevant annotations designed for biomarkers extraction (diameters,
counts, etc.). Our study proposes a first step toward bridging this gap, optimizing vessel
segmentation based on its diameter annotations. To do so we propose to extract bound-
ary points from a star-shaped segmentation in a differentiable manner. This differentiable
extraction allows reducing annotation burden as instead of the pixel-wise segmentation
only the two annotated points required for diameter measurement are used for training
the model. Our experiments show that training based on diameter is efficient; produces
state-of-the-art weakly supervised segmentation; and performs reasonably compared to full
supervision.

Our code is publicly available:
https://gitlab.com/radiology/aim/carotid-artery-image-analysis/diameter-learning
'
  volume: 172
  URL: https://proceedings.mlr.press/v172/camarasa22a.html
  PDF: https://proceedings.mlr.press/v172/camarasa22a/camarasa22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-camarasa22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Robin
    family: Camarasa
  - given: Hoel
    family: Kervadec
  - given: Daniel
    family: Bos
  - given: Marleen
    prefix: de
    family: Bruijne
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 188-198
  id: camarasa22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 188
  lastpage: 198
  published: 2022-12-04 00:00:00 +0000
- title: 'Holistic Modeling In Medical Image Segmentation Using Spatial Recurrence'
  abstract: 'In clinical practice, regions of interest in medical imaging (MI) often need to be identified through a process of precise image segmentation. For MI segmentation to generalize, we need two components: to identify local descriptions, but at the same time to develop a holistic representation of the image that captures long-range spatial dependencies. Unfortunately, we demonstrate that the start of the art does not achieve the latter. In particular, it does not provide a modeling that yields a global, contextual model. To improve accuracy, and enable holistic modeling, we introduce a novel deep neural network architecture endowed with spatial recurrence. The implementation relies on gated recurrent units that directionally traverse the feature map, greatly increasing each layers receptive field and explicitly modeling non-adjacent relationships between pixels. Our method is evaluated in four different segmentation tasks: nuclei segmentation in microscopy images, colorectal polyp segmentation in colonoscopy videos, liver segmentation in abdominal CT scans, and aorta artery segmentation in thoracic CT scans. Our experiments demonstrate an average increase in performance of 4.72 Dice points and 0.68 Hausdorff distance units comparing to U-Net and U-Net++, and a performance better or on par when compared to transformer-based architectures. Code available at https://github.com/JoaoCarv/holistic-seg.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/carvalho22a.html
  PDF: https://proceedings.mlr.press/v172/carvalho22a/carvalho22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-carvalho22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: João BS
    family: Carvalho
  - given: João
    family: Santinha
  - given: Djordje
    family: Miladinovic
  - given: Carlos
    family: Cotrini
  - given: Joachim M
    family: Buhmann
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 199-218
  id: carvalho22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 199
  lastpage: 218
  published: 2022-12-04 00:00:00 +0000
- title: 'Automatic planning of liver tumor thermal ablation using deep reinforcement learning'
  abstract: 'Thermal ablation is a promising minimally invasive intervention to treat liver tumors. It requires a meticulous planning phase where the electrode trajectory from the skin surface to the tumor inside the liver as well as the ablation protocol are defined to reach a complete tumor ablation while considering multiple clinical constraints such as avoiding too much damage to healthy tissue. The planning is usually done manually based on 2D views of pre-operative CT images and can be extremely challenging for large or irregularly shaped tumors. Conventional optimization methods have been proposed to automate this complex task, but they suffer from high computation time. To alleviate this drawback, we propose to leverage a deep reinforcement learning (DRL) approach to find the optimal electrode trajectory that satisfies all the clinical constraints and does not require any labels in training. Here, we define a custom environment as the 3D mask with tumor, surrounding organs, skin labels along with an electrode line and ablation zone. An agent, represented by a neural network, interacts with the custom environment by displacing the electrode and therefore can learn an optimal policy. The reward assignment is done based on the clinical constraints. We explore discrete and continuous action-based approaches with double deep Q networks and proximal policy optimization (PPO), respectively. We perform an evaluation on the publicly available liver tumor segmentation (LITs) challenge dataset and obtain solutions that satisfy all clinical constraints comparable to the conventional method. The DRL method does not need any post-processing steps, allowing a mean inference time of 13.3 seconds per subject compared to the conventional optimization method’s mean time of 135 seconds. Moreover, the best DRL method (PPO) yields a valid solution irrespective of the tumor location within the liver that demonstrates its robustness.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/chaitanya22a.html
  PDF: https://proceedings.mlr.press/v172/chaitanya22a/chaitanya22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-chaitanya22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Krishna
    family: Chaitanya
  - given: Chloé
    family: Audigier
  - given: Laura Elena
    family: Balascuta
  - given: Tommaso
    family: Mansi
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 219-230
  id: chaitanya22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 219
  lastpage: 230
  published: 2022-12-04 00:00:00 +0000
- title: 'TorchXRayVision: A library of chest X-ray datasets and models'
  abstract: 'TorchXRayVision is an open source software library for working with chest X-ray datasets and deep learning models. It provides a common interface and common pre-processing chain for a wide set of publicly available chest X-ray datasets. In addition, a number of classification and representation learning models with different architectures, trained on different data combinations, are available through the library to serve as baselines or feature extractors.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/cohen22a.html
  PDF: https://proceedings.mlr.press/v172/cohen22a/cohen22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-cohen22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Joseph Paul
    family: Cohen
  - given: Joseph D.
    family: Viviano
  - given: Paul
    family: Bertin
  - given: Paul
    family: Morrison
  - given: Parsa
    family: Torabian
  - given: Matteo
    family: Guarrera
  - given: Matthew P
    family: Lungren
  - given: Akshay
    family: Chaudhari
  - given: Rupert
    family: Brooks
  - given: Mohammad
    family: Hashir
  - given: Hadrien
    family: Bertrand
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 231-249
  id: cohen22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 231
  lastpage: 249
  published: 2022-12-04 00:00:00 +0000
- title: 'Explainable Weakly-Supervised Cell Segmentation by Canonical Shape Learning and Transformation'
  abstract: 'Microscopy images have been increasingly analyzed quantitatively in biomedical research. Segmenting individual cell nucleus is an important step as many research studies involve counting cell nuclei and analysing their shape. We propose a novel weakly supervised instance segmentation method trained with image segmentation masks only. Our system comprises two models: an  implicit shape Multi-Layer Perceptron (MLP) that learns the shape of the nuclei in canonical coordinates; and 2) an encoder that predicts the parameters of the affine transformation to deform the canonical shape into the correct location, scale, and orientation in the image. To further improve the performance of the model, we propose a loss that uses the total number of nuclei in an image as supervision. Our system is explainable, as the implicit shape MLP learns that the canonical shape of the cell nuclei is a circle, and interpretable as the output of the encoder are parameters of affine transformations. We obtain image segmentation performance close to DeepLabV3 and, additionally, obtain an F1-score$_{IoU=0.5}$ of $68.47%$ at the instance segmentation task, even though the system was trained with image segmentations.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/costa22a.html
  PDF: https://proceedings.mlr.press/v172/costa22a/costa22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-costa22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Pedro
    family: Costa
  - given: Alex
    family: Gaudio
  - given: Aurélio
    family: Campilho
  - given: Jaime S.
    family: Cardoso
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 250-260
  id: costa22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 250
  lastpage: 260
  published: 2022-12-04 00:00:00 +0000
- title: 'SZLoc: A Multi-resolution Architecture for Automated Epileptic Seizure Localization from Scalp EEG'
  abstract: 'We propose an end-to-end deep learning framework for epileptic seizure localization from scalp electroencephalography (EEG). Our architecture, SZLoc, extracts multi-resolution information via local (single channel) and global (cross-channel) CNN encodings. These interconnected representations are fused using a transformer layer. Leveraging its multi-resolution outputs, SZLoc derives three clinically interpretable outputs: electrode-level seizure activity, seizure onset zone localization, and identification of the EEG signal intervals that contribute to the final localization.  From an optimization standpoint, we formulate a novel ensemble of loss functions to train SZLoc using inexact spatial and temporal labels of seizure onset.  In this manner, SZLoc automatically learns phenomena at finer resolutions than the training labels. We validate our SZLoc framework and training paradigm on a clinical EEG dataset of 34 focal epilepsy patients.  As compared to other deep learning baseline models, SZLoc achieves robust inter-patient seizure localization performance.  We also demonstrate generalization of SZLoc to a second cohort of 16 epilepsy patients with different seizure characteristics and recorded at a different site. Taken together, SZLoc extends beyond the traditional paradigm of seizure detection by providing clinically relevant seizure localization information from coarse and inexact training labels.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/craley22a.html
  PDF: https://proceedings.mlr.press/v172/craley22a/craley22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-craley22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Jeff
    family: Craley
  - given: Emily
    family: Johnson
  - given: Christophe
    family: Jouny
  - given: David
    family: Hsu
  - given: Raheel
    family: Ahmed
  - given: Archana
    family: Venkataraman
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 261-281
  id: craley22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 261
  lastpage: 281
  published: 2022-12-04 00:00:00 +0000
- title: 'Surface Vision Transformers: Attention-Based Modelling applied to Cortical Analysis'
  abstract: 'The extension of convolutional neural networks (CNNs) to non-Euclidean geometries has led to multiple frameworks for studying manifolds. Many of those methods have shown design limitations resulting in poor modelling of long-range associations, as the generalisation of convolutions to irregular surfaces is non-trivial. Motivated by the success of attention-modelling in computer vision, we translate  convolution-free vision transformer approaches to surface data, to introduce a domain-agnostic architecture to study any surface data projected onto a spherical manifold. Here, surface patching is achieved by representing spherical data as a sequence of triangular patches, extracted from a subdivided icosphere. A transformer model encodes the sequence of patches via successive multi-head self-attention layers while preserving the sequence resolution. We validate the performance of the proposed Surface Vision Transformer (<em>SiT</em>) on the task of phenotype regression from cortical surface metrics derived from the Developing Human Connectome Project (dHCP). Experiments show that the <em>SiT</em> generally outperforms surface CNNs, while performing comparably on registered and unregistered data. Analysis of transformer attention maps offers strong potential to characterise subtle cognitive developmental patterns.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/dahan22a.html
  PDF: https://proceedings.mlr.press/v172/dahan22a/dahan22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-dahan22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Simon
    family: Dahan
  - given: Abdulah
    family: Fawaz
  - given: Logan Z. J.
    family: Williams
  - given: Chunhui
    family: Yang
  - given: Timothy S.
    family: Coalson
  - given: Matthew F.
    family: Glasser
  - given: A. David
    family: Edwards
  - given: Daniel
    family: Rueckert
  - given: Emma C.
    family: Robinson
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 282-303
  id: dahan22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 282
  lastpage: 303
  published: 2022-12-04 00:00:00 +0000
- title: 'Single Dynamic Network for Multi-label Renal Pathology Image Segmentation'
  abstract: 'Computer-assisted quantitative analysis on Giga-pixel pathology images has provided a new avenue in histology examination. The innovations have been largely focused on cancer pathology (i.e., tumor segmentation and characterization). In non-cancer pathology, the learning algorithms can be asked to examine more comprehensive tissue types simultaneously, as a multi-label setting. The prior arts typically needed to train multiple segmentation networks in order to match the domain-specific knowledge for heterogeneous tissue types (e.g., glomerular tuft, glomerular unit, proximal tubular, distal tubular, peritubular capillaries, and arteries). In this paper, we propose a dynamic single segmentation network (Omni-Seg) that learns to segment multiple tissue types using partially labeled images (i.e., only one tissue type is labeled for each training image) for renal pathology.  By learning from  150,000 patch-wise pathological images from six tissue types, the proposed Omni-Seg network achieved superior segmentation accuracy and less resource consumption when compared to the previous the multiple-network and multi-head design. In the testing stage, the proposed method obtains “completely labeled" tissue segmentation results using only “partially labeled" training images. The source code is available at  \url{https://github.com/ddrrnn123/Omni-Seg}'
  volume: 172
  URL: https://proceedings.mlr.press/v172/deng22a.html
  PDF: https://proceedings.mlr.press/v172/deng22a/deng22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-deng22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Ruining
    family: Deng
  - given: Quan
    family: Liu
  - given: Can
    family: Cui
  - given: Zuhayr
    family: Asad
  - given: Haichun
    prefix: and
    family: Yang
  - given: Yuankai
    family: Huo
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 304-314
  id: deng22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 304
  lastpage: 314
  published: 2022-12-04 00:00:00 +0000
- title: 'CAD-RADS Scoring using Deep Learning and Task-Specific Centerline Labeling'
  abstract: 'With coronary artery disease (CAD) persisting to be one of the leading causes of death worldwide, interest in supporting physicians with algorithms to speed up and improve diagnosis is high.  In clinical practice, the severeness of CAD is often assessed with a coronary CT angiography (CCTA) scan and manually graded with the CAD-Reporting and Data System (CAD-RADS) score.  The clinical questions this score assesses are whether patients have CAD or not (rule-out) and whether they have severe CAD or not (hold-out). In this work, we reach new state-of-the-art performance for automatic CAD-RADS scoring. We propose using severity-based label encoding, test time augmentation (TTA) and model ensembling for a task-specific deep learning architecture. Furthermore, we introduce a novel task- and model-specific, heuristic coronary segment labeling, which subdivides coronary trees into consistent parts across patients. It is fast, robust, and easy to implement. We were able to raise the previously reported area under the receiver operating characteristic curve (AUC) from 0.914 to \textbf{0.942} in the rule-out and from 0.921 to \textbf{0.950} in the hold-out task respectively.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/denzinger22a.html
  PDF: https://proceedings.mlr.press/v172/denzinger22a/denzinger22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-denzinger22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Felix
    family: Denzinger
  - given: Michael
    family: Wels
  - given: Oliver
    family: Taubmann
  - given: Mehmet A.
    family: Gülsün
  - given: Max
    family: Schöbinger
  - given: Florian
    family: André
  - given: Sebastian J.
    family: Buss
  - given: Johannes
    family: Görich
  - given: Michael
    family: Sühling
  - given: Andreas
    family: Maier
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 315-324
  id: denzinger22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 315
  lastpage: 324
  published: 2022-12-04 00:00:00 +0000
- title: 'VORTEX: Physics-Driven Data Augmentations Using Consistency Training for Robust Accelerated MRI Reconstruction'
  abstract: 'Deep neural networks have enabled improved image quality and fast inference times for various inverse problems, including accelerated magnetic resonance imaging (MRI) reconstruction. However, such models require a large number of fully-sampled ground truth datasets, which are difficult to curate, and are sensitive to distribution drifts. In this work, we propose applying physics-driven data augmentations for consistency training that leverage our domain knowledge of the forward MRI data acquisition process and MRI physics to achieve improved label efficiency and robustness to clinically-relevant distribution drifts. Our approach, termed VORTEX, (1) demonstrates strong improvements over supervised baselines with and without data augmentation in robustness to signal-to-noise ratio change and motion corruption in data-limited regimes; (2) considerably outperforms state-of-the-art purely image-based data augmentation techniques and self-supervised reconstruction methods on both in-distribution and out-of-distribution data; and (3) enables composing heterogeneous image-based and physics-driven data augmentations.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/desai22a.html
  PDF: https://proceedings.mlr.press/v172/desai22a/desai22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-desai22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Arjun D.
    family: Desai
  - given: Beliz
    family: Gunel
  - given: Batu M.
    family: Ozturkler
  - given: Harris
    family: Beg
  - given: Shreyas
    family: Vasanawala
  - given: Brian A.
    family: Hargreaves
  - given: Christopher
    family: Ré
  - given: John M
    family: Pauly
  - given: Akshay S.
    family: Chaudhari
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 325-352
  id: desai22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 325
  lastpage: 352
  published: 2022-12-04 00:00:00 +0000
- title: 'Comparing representations of biological data learned with different AI paradigms, augmenting and cropping strategies'
  abstract: 'Recent advances in computer vision and robotics enabled automated large-scale biological image analysis. Various machine learning approaches have been successfully applied to phenotypic profiling. However, it remains unclear how they compare in terms of biological feature extraction. In this study, we propose a simple CNN architecture and implement 4 different representation learning approaches. We train 16 deep learning setups on the 770k cancer cell images dataset under identical conditions, using different augmenting and cropping strategies. We compare the learned representations by evaluating multiple metrics for each of three downstream tasks: i) distance-based similarity analysis of known drugs, ii) classification of drugs versus controls, iii) clustering within cell lines. We also compare training times and memory usage. Among all tested setups, multi-crops and random augmentations generally improved performance across tasks, as expected. Strikingly, self-supervised (implicit contrastive learning) models showed competitive performance being up to 11 times faster to train. Self-supervised regularized learning required the most of memory and computation to deliver arguably the most informative features. We observe that no single combination of augmenting and cropping strategies consistently results in top performance across tasks and recommend prospective research directions.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/dmitrenko22a.html
  PDF: https://proceedings.mlr.press/v172/dmitrenko22a/dmitrenko22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-dmitrenko22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Andrei
    family: Dmitrenko
  - given: Mauro M.
    family: Masiero
  - given: Nicola
    family: Zamboni
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 353-369
  id: dmitrenko22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 353
  lastpage: 369
  published: 2022-12-04 00:00:00 +0000
- title: 'Self-supervised learning for analysis of temporal and morphological drug effects in cancer cell imaging data'
  abstract: 'In this work, we propose two novel methodologies to study temporal and morphological phenotypic effects caused by different experimental conditions using imaging data. As a proof of concept, we apply them to analyze drug effects in 2D cancer cell cultures. We train a convolutional autoencoder on 1M images dataset with random augmentations and multi-crops to use as feature extractor. We systematically compare it to the pretrained state-of-the-art models. We further use the feature extractor in two ways. First, we apply distance-based analysis and dynamic time warping to cluster temporal patterns of 31 drugs. We identify clusters allowing annotation of drugs as having cytotoxic, cytostatic, mixed or no effect. Second, we implement an adversarial/regularized learning setup to improve classification of 31 drugs and visualize image regions that contribute to the improvement. We increase top-3 classification accuracy by 8% on average and mine examples of morphological feature importance maps. We provide the feature extractor and the weights to foster transfer learning applications in biology. We also discuss utility of other pretrained models and applicability of our methods to other types of biomedical data.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/dmitrenko22b.html
  PDF: https://proceedings.mlr.press/v172/dmitrenko22b/dmitrenko22b.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-dmitrenko22b.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Andrei
    family: Dmitrenko
  - given: Mauro M.
    family: Masiero
  - given: Nicola
    family: Zamboni
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 370-386
  id: dmitrenko22b
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 370
  lastpage: 386
  published: 2022-12-04 00:00:00 +0000
- title: 'Personalized Prediction of Future Lesion Activity and Treatment Effect in Multiple Sclerosis from Baseline MRI'
  abstract: 'Precision medicine for chronic diseases such as multiple sclerosis (MS) involves choosing a treatment which best balances efficacy and side effects/preferences for individual patients. Making this choice as early as possible is important, as delays in finding an effective therapy can lead to irreversible disability accrual. To this end, we present the first deep neural network model for individualized treatment decisions from baseline magnetic resonance imaging (MRI) (with clinical information if available) for MS patients which (a) predicts future new and enlarging T2 weighted (NE-T2) lesion counts on follow-up MRI on multiple treatments and (b) estimates the conditional average treatment effect (CATE), as defined by the predicted future suppression of NE-T2 lesions, between different treatment options relative to placebo. Our model is validated on a proprietary federated dataset of 1817 multi-sequence MRIs acquired from MS patients during four multi-centre randomized clinical trials. Our framework achieves high average precision in the binarized regression of future NE-T2 lesions on five different treatments, identifies heterogeneous treatment effects, and provides a personalized treatment recommendation that accounts for treatment-associated risk (side effects, patient preference, administration difficulties,...).'
  volume: 172
  URL: https://proceedings.mlr.press/v172/durso-finley22a.html
  PDF: https://proceedings.mlr.press/v172/durso-finley22a/durso-finley22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-durso-finley22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Joshua
    family: Durso-Finley
  - given: Jean-Pierre
    family: Falet
  - given: Brennan
    family: Nichyporuk
  - given: Arnold
    family: Douglas
  - given: Tal
    family: Arbel
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 387-406
  id: durso-finley22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 387
  lastpage: 406
  published: 2022-12-04 00:00:00 +0000
- title: 'Practical uncertainty quantification for brain tumor segmentation'
  abstract: 'Despite U-Nets being the de-facto standard for medical image segmentation, researchers have identified shortcomings of U-Nets, such as overconfidence and poor out-of-distribution generalization. Several methods for uncertainty quantification try to solve such problems by relying on well-known approximations such as Monte-Carlo Drop-Out, Probabilistic U-Net, and Stochastic Segmentation Networks. We introduce a novel multi-headed Variational U-Net. The proposed approach combines the global exploration capabilities of deep ensembles with the out-of-distribution robustness of Variational Inference. An efficient training strategy and an expressive yet general design ensure superior uncertainty quantification within a reasonable compute requirement. We thoroughly analyze the performance and properties of our approach on the publicly available BRATS2018 dataset. Further, we test our model on four commonly observed distribution shifts. The proposed approach has good uncertainty calibration and is robust to out-of-distribution shifts.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/fuchs22a.html
  PDF: https://proceedings.mlr.press/v172/fuchs22a/fuchs22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-fuchs22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Moritz
    family: Fuchs
  - given: Camila
    family: González
  - given: Anirban
    family: Mukhopadhyay
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 407-422
  id: fuchs22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 407
  lastpage: 422
  published: 2022-12-04 00:00:00 +0000
- title: 'Weakly-supervised learning for image-based classification of primary melanomas into genomic immune subgroups'
  abstract: 'Determining early-stage prognostic markers and stratifying patients for effective treatment are two key challenges for improving outcomes for melanoma patients. Previous studies have used tumour transcriptome data to stratify patients into immune subgroups, which were associated with differential melanoma specific survival and potential treatment strategies. However, acquiring transcriptome data is a time-consuming and costly process. Moreover, it is not routinely used in the current clinical workflow. Here we attempt to overcome this by developing deep learning models to classify gigapixel H&E stained pathology slides, which are well established in clinical workflows, into these immune subgroups. Previous subtyping approaches have employed supervised learning which requires fully annotated data, or have only examined single genetic mutations in melanoma patients. We leverage a multiple-instance learning approach, which only requires slide-level labels and uses an attention mechanism to highlight regions of high importance to the classification. Moreover, we show that pathology-specific self-supervised models generate better representations compared to pathology-agnostic models for improving our model performance, achieving a mean AUC of 0.76 for classifying histopathology images as high or low immune subgroups. We anticipate that this method may allow us to find new biomarkers of high importance and could act as a tool for clinicians to infer the immune landscape of tumours and stratify patients, without needing to carry out additional expensive genetic tests.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/godson22a.html
  PDF: https://proceedings.mlr.press/v172/godson22a/godson22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-godson22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Lucy
    family: Godson
  - given: Navid
    family: Alemi
  - given: Jérémie
    family: Nsengimana
  - given: Graham P.
    family: Cook
  - given: Emily L.
    family: Clarke
  - given: Darren
    family: Treanor
  - given: D. Timothy
    family: Bishop
  - given: Newton-Bishop
    family: Julia
  - given: Ali
    family: Gooya
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 423-440
  id: godson22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 423
  lastpage: 440
  published: 2022-12-04 00:00:00 +0000
- title: 'i3Deep: Efficient 3D interactive segmentation with the nnU-Net'
  abstract: '3D interactive segmentation is highly relevant in reducing the annotation time for experts. However, current methods often achieve only small segmentation improvements per interaction as lightweight models are a requirement to ensure near-realtime usage. Models with better predictive performance such as the nnU-Net cannot be employed for interactive segmentation due to their high computational demands, which result in long inference times. To solve this issue, we propose the 3D interactive segmentation framework i3Deep. Slices are selected through uncertainty estimation in an offline setting and afterwards corrected by an expert. The slices are then fed to a refinement nnU-Net, which significantly improves the global 3D segmentation from the local corrections. This approach bypasses the issue of long inference times by moving expensive computations into an offline setting that does not include the expert. For three different anatomies, our approach reduces the workload of the expert by 80.3%, while significantly improving the Dice by up to 39.5%, outperforming other state-of-the-art methods by a clear margin. Even on out-of-distribution data i3Deep is able to improve the segmentation by 19.3%.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/gotkowski22a.html
  PDF: https://proceedings.mlr.press/v172/gotkowski22a/gotkowski22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-gotkowski22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Karol
    family: Gotkowski
  - given: Camila
    family: Gonzalez
  - given: Isabel
    family: Kaltenborn
  - given: Ricarda
    family: Fischbach
  - given: Andreas
    family: Bucher
  - given: Anirban
    family: Mukhopadhyay
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 441-456
  id: gotkowski22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 441
  lastpage: 456
  published: 2022-12-04 00:00:00 +0000
- title: 'Transformer-based out-of-distribution detection for clinically safe segmentation'
  abstract: 'In a clinical setting it is essential that deployed image processing systems are robust to the full range of inputs they might encounter and, in particular, do not make confidently wrong predictions. The most popular approach to safe processing is to train networks that can provide a measure of their uncertainty, but these tend to fail for inputs that are far outside the training data distribution. Recently, generative modelling approaches have been proposed as an alternative; these can quantify the likelihood of a data sample explicitly, filtering out any out-of-distribution (OOD) samples before further processing is performed. In this work, we focus on image segmentation and evaluate several approaches to network uncertainty in the far-OOD and near-OOD cases for the task of segmenting haemorrhages in head CTs. We find all of these approaches are unsuitable for safe segmentation as they provide confidently wrong predictions when operating OOD. We propose performing full 3D OOD detection using a VQ-GAN to provide a compressed latent representation of the image and a transformer to estimate the data likelihood. Our approach successfully identifies images in both the far- and near-OOD cases. We find a strong relationship between image likelihood and the quality of a model’s segmentation, making this approach viable for filtering images unsuitable for segmentation. To our knowledge, this is the first time transformers have been applied to perform OOD detection on 3D image data.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/graham22a.html
  PDF: https://proceedings.mlr.press/v172/graham22a/graham22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-graham22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Mark S
    family: Graham
  - given: Petru-Daniel
    family: Tudosiu
  - given: Paul
    family: Wright
  - given: Walter Hugo Lopez
    family: Pinaya
  - given: Jean-Marie
    family: U-King-Im
  - given: Yee H
    family: Mah
  - given: James T
    family: Teo
  - given: Rolf
    family: Jager
  - given: David
    family: Werring
  - given: Parashkev
    family: Nachev
  - given: Sebastien
    family: Ourselin
  - given: M. Jorge
    family: Cardoso
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 457-476
  id: graham22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 457
  lastpage: 476
  published: 2022-12-04 00:00:00 +0000
- title: 'JOINED : Prior Guided Multi-task Learning for Joint Optic Disc/Cup Segmentation and Fovea Detection'
  abstract: 'Fundus photography has been routinely used to document the presence and severity of various retinal degenerative diseases such as age-related macula degeneration, glaucoma,and diabetic retinopathy, for which the fovea, optic disc (OD), and optic cup (OC) are important anatomical landmarks. Identification of those anatomical landmarks is of greatclinical importance. However, the presence of lesions, drusen, and other abnormalities during retinal degeneration severely complicates automatic landmark detection and segmentation. Most existing works treat the identification of each landmark as a single task and typically do not make use of any clinical prior information. In this paper, we present a novel method, named JOINED, for prior guided multi-task learning for joint OD/OC segmentation and fovea detection. An auxiliary branch for distance prediction, in addition to a segmentation branch and a detection branch, is constructed to effectively utilize the distance information from each image pixel to landmarks of interest. Our proposed JOINED pipeline consists of a coarse stage and a fine stage. At the coarse stage, we obtain the OD/OC coarse segmentation and the heatmap localization of fovea through a joint segmentation and detection module. Afterwards, we crop the regions of interest for subsequent fine processing and use predictions obtained at the coarse stage as additional information for better performance and faster convergence. Experimental results reveal that our proposed JOINED outperforms existing state-of-the-art approaches on the publicly-available GAMMA, PALM, and REFUGE datasets of fundus images. Furthermore, JOINED ranked the 5th on the OD/OC segmentation and fovea detection tasks in the GAMMA challenge hosted by the MICCAI2021 workshop OMIA8.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/he22a.html
  PDF: https://proceedings.mlr.press/v172/he22a/he22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-he22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Huaqing
    family: He
  - given: Li
    family: Lin
  - given: Zhiyuan
    family: Cai
  - given: Xiaoying
    family: Tang
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 477-492
  id: he22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 477
  lastpage: 492
  published: 2022-12-04 00:00:00 +0000
- title: 'Unsupervised Pre-training Improves Tooth Segmentation in 3-Dimensional Intraoral Mesh Scans'
  abstract: 'Accurate tooth segmentation in 3-Dimensional (3D) intraoral scanned (IOS) mesh data is an essential step for many practical dental applications. Recent research highlights the success of deep learning based methods for end-to-end 3D tooth segmentation, yet most of them are only trained or validated with a small dataset as annotating 3D IOS dental surfaces requires complex pipelines and intensive human efforts. In this paper, we propose a novel method to boost the performance of 3D tooth segmentation leveraging large-scale unlabeled IOS data. Our tooth segmentation network is first pre-trained with an unsupervised learning framework and point-wise contrastive learning loss on the large-scale unlabeled dataset and subsequently fine-tuned on a small labeled dataset. With the same amount of annotated samples, our method can achieve a mIoU of 89.38%, significantly outperforming the supervised counterpart. Moreover, our method can achieve better performance with only 40% of the annotated samples as compared to the fully supervised baselines. To the best of our knowledge, we present the first attempt of unsupervised pretraining for 3D tooth segmentation, demonstrating its strong potential in reducing human efforts for annotation and verification.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/he22b.html
  PDF: https://proceedings.mlr.press/v172/he22b/he22b.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-he22b.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Xiaoxuan
    family: He
  - given: Hualiang
    family: Wang
  - given: Haoji
    family: Hu
  - given: Jianfei
    family: Yang
  - given: Yang
    family: Feng
  - given: Gaoang
    family: Wang
  - given: Liu
    family: Zuozhu
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 493-507
  id: he22b
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 493
  lastpage: 507
  published: 2022-12-04 00:00:00 +0000
- title: 'TopoFit: Rapid Reconstruction of Topologically-Correct Cortical Surfaces'
  abstract: 'Mesh-based reconstruction of the cerebral cortex is a fundamental component in brain image analysis. Classical, iterative pipelines for cortical modeling are robust but often time-consuming, mostly due to expensive procedures that involve topology correction and spherical mapping. Recent attempts to address reconstruction with machine learning methods have accelerated some components in these pipelines, but these methods still require slow processing steps to enforce topological constraints that comply with known anatomical structure. In this work, we introduce a novel learning-based strategy, TopoFit, which rapidly fits a topologically-correct surface to the white-matter tissue boundary. We design a joint network, with image and graph convolutions, and an efficient symmetric distance loss to learn to predict accurate deformations that map a template mesh to subject-specific anatomy. This technique encompasses the work of current mesh correction, fine-tuning, and inflation processes and, as a result, offers a 150x faster solution to cortical surface reconstruction compared to traditional approaches. We demonstrate that TopoFit is 1.8x more accurate than the current state-of-the-art deep-learning strategy, and it is robust to common failure modes, such as white-matter tissue hypointensities.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/hoopes22a.html
  PDF: https://proceedings.mlr.press/v172/hoopes22a/hoopes22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-hoopes22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Andrew
    family: Hoopes
  - given: Juan Eugenio
    family: Iglesias
  - given: Bruce
    family: Fischl
  - given: Douglas
    family: Greve
  - given: Adrian V
    family: Dalca
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 508-520
  id: hoopes22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 508
  lastpage: 520
  published: 2022-12-04 00:00:00 +0000
- title: 'Orientation Estimation of Abdominal Ultrasound Images with Multi-Hypotheses Networks'
  abstract: 'Ultrasound imaging can provide valuable information to clinicians during interventions, in particular when fused with other modalities. Multi-modal image registration algorithms however require a somewhat accurate initialization, which is particularly difficult to estimate for ultrasound images as their orientation is arbitrary and their content ambiguous (limited field of view, artifacts, etc.). In this work, we not only train neural networks to predict the absolute orientation of ultrasound frames, but also to produce a confidence for each prediction. This allows us to select only the most confident frames in the clip. Our networks are trained to produce multiple hypotheses using a simple yet overlooked meta-loss that is specifically designed to capture the ambiguity of the input data. We show on several abdominal ultrasound datasets that multi-hypotheses networks provide better uncertainty estimates than Monte-Carlo dropout while being more efficient than network ensembling. Generic, easy to implement and able to quantify both data ambiguity and out-of-distribution samples, they represent a preferable alternative to traditional baselines for uncertainty estimation. On a clinical test our method produces estimates within $20^{\circ}$ of the true orientation, which we can use to improve the accuracy of a subsequent registration algorithm down to less than $10^{\circ}$.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/horstmann22a.html
  PDF: https://proceedings.mlr.press/v172/horstmann22a/horstmann22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-horstmann22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Timo
    family: Horstmann
  - given: Oliver
    family: Zettinig
  - given: Wolfgang
    family: Wein
  - given: Raphael
    family: Prevost
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 521-534
  id: horstmann22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 521
  lastpage: 534
  published: 2022-12-04 00:00:00 +0000
- title: 'CAiD: Context-Aware Instance Discrimination for Self-supervised Learning in Medical Imaging'
  abstract: 'Recently, self-supervised instance discrimination methods have achieved significant success in learning visual representations from unlabeled photographic images. However, given the marked differences between photographic and medical images, the efficacy of instance-based objectives, focusing on learning the most discriminative global features in the image (i.e., wheels in bicycle), remains unknown in medical imaging. Our preliminary analysis showed that high global similarity of medical images in terms of anatomy hampers instance discrimination methods for capturing a set of distinct features, negatively impacting their performance on medical downstream tasks. To alleviate this limitation, we have developed a simple yet effective self-supervised framework, called Context-Aware instance Discrimination (CAiD). CAiD aims to improve instance discrimination learning by providing finer and more discriminative information encoded from a diverse local context of unlabeled medical images. We conduct a systematic analysis to investigate the utility of the learned features from a three-pronged perspective: (i) generalizability and transferability, (ii) separability in the embedding space, and (iii) reusability. Our extensive experiments demonstrate that CAiD (1) enriches representations learned from existing instance discrimination methods; (2)  delivers more discriminative features by adequately capturing finer contextual information from individual medial images; and (3) improves reusability of low/mid-level features compared to standard instance discriminative methods. As open science, all codes and pre-trained models are available on our GitHub page: https://github.com/JLiangLab/CAiD.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/hosseinzadeh-taher22a.html
  PDF: https://proceedings.mlr.press/v172/hosseinzadeh-taher22a/hosseinzadeh-taher22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-hosseinzadeh-taher22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Mohammad Reza
    family: Hosseinzadeh Taher
  - given: Fatemeh
    family: Haghighi
  - given: Michael B.
    family: Gotway
  - given: Jianming
    family: Liang
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 535-551
  id: hosseinzadeh-taher22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 535
  lastpage: 551
  published: 2022-12-04 00:00:00 +0000
- title: 'Domain Generalization for Retinal Vessel Segmentation with Vector Field Transformer'
  abstract: 'Domain generalization has great impact on medical image analysis as data distribution inconsistencies are prevalent in most of the medical data modalities due to the image acquisition techniques. In this study, we investigate a novel pipeline that generalizes the retinal vessel segmentation across color fundus photography and OCT angiography images. We hypothesize that the scaled minor eigenvector of the Hessian matrix can sufficiently represent the vessel by vector flow. This vector field can be regarded as a common domain for different modalities as it is very similar even for data that follows vastly different intensity distributions. Next, we leverage the uncertainty in the latent space of the auto-encoder to synthesize enhanced vessel maps to augment the training data. Finally, we propose a transformer network to extract features from the vector field. We show the performance of our model in cross-modality experiments.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/hu22a.html
  PDF: https://proceedings.mlr.press/v172/hu22a/hu22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-hu22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Dewei
    family: Hu
  - given: Hao
    family: Li
  - given: Han
    family: Liu
  - given: Ipek
    family: Oguz
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 552-564
  id: hu22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 552
  lastpage: 564
  published: 2022-12-04 00:00:00 +0000
- title: 'Breathing Freely: Self-supervised Liver T1rho Mapping from A Single T1rho-weighted Image'
  abstract: 'Quantitative T1rho imaging is a promising technique for assessment of chronic liver disease. The standard approach requires acquisition of multiple T1rho-weighted images of the liver to quantify T1rho relaxation time. The quantification accuracy can be affected by respiratory motion if the subjects cannot hold the breath during the scan. To tackle this problem, we propose a self-supervised mapping method by taking only one T1rho-weighted image to do the mapping. Our method takes into account of signal scale variations in MR scan when performing T1rho quantification. Preliminary experimental results show that our method can achieve better mapping performance than the traditional fitting method, particularly in free-breathing scenarios.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/huang22a.html
  PDF: https://proceedings.mlr.press/v172/huang22a/huang22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-huang22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Chaoxing
    family: Huang
  - given: Yurui
    family: Qian
  - given: Jian
    family: Hou
  - given: Baiyan
    family: Jiang
  - given: Queenie
    family: Chan
  - given: Vincent
    family: Wong
  - given: Winne
    family: Chu
  - given: Weitian
    family: Chen
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 565-575
  id: huang22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 565
  lastpage: 575
  published: 2022-12-04 00:00:00 +0000
- title: 'AdwU-Net: Adaptive Depth and Width U-Net for Medical Image Segmentation by Differentiable Neural Architecture Search'
  abstract: 'The U-Net and its variants are proved as the most successful architectures in the medical image segmentation domain. However, the optimal configuration of the hyperparameters in U-Net structure such as depth and width remain challenging to adjust manually due to the diversity of medical image segmentation tasks. In this paper, we propose AdwU-Net, which is an efficient neural architecture search framework to search the optimal task-specific depth and width in the U-Net backbone. Specifically, an adaptive depth and width block is designed and applied hierarchically in U-Net. In each block, the optimal number of convolutional layers and channels in each layer are directly learned from data. To reduce the computational costs and alleviate the memory pressure, we conduct an efficient architecture search and reuse the network weights of different depth and width options in a differentiable manner. Extensive experiments on the Medical Segmentation Decathlon (MSD) dataset show that our method outperforms not only the manually scaled U-Net but also other state-of-the-art architectures. Our code is publicly available at \href{https://github.com/Ziyan-Huang/AdwU-Net}{https://github.com/Ziyan-Huang/AdwU-Net}.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/huang22b.html
  PDF: https://proceedings.mlr.press/v172/huang22b/huang22b.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-huang22b.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Ziyan
    family: Huang
  - given: Zehua
    family: Wang
  - given: Zhikai
    family: Yang
  - given: Lixu
    family: Gu
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 576-589
  id: huang22b
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 576
  lastpage: 589
  published: 2022-12-04 00:00:00 +0000
- title: 'Deep Learning Radiographic Assessment of Pulmonary Edema: Training with Serum Biomarkers'
  abstract: 'A major obstacle faced when developing convolutional neural networks (CNNs) for medical imaging is the acquisition of training labels: most current approaches rely on manually prescribed labels from physicians, which are time consuming and labor intensive to attain. Clinical biomarkers, often measured alongside medical images and used in diagnostic workup, may provide a rich set of data that can be collected retrospectively and utilized to train diagnostic models. In this work, we focused on the blood serum biomarkers BNP and BNPP, indicative of acute heart failure (HF) and cardiogenic pulmonary edema, paired with the chest X-ray imaging modality. We investigated the potential for inferring BNP and BNPP from chest radiographs. For this purpose, a CNN was trained using \textcolor{black}{27748} radiographs to automatically infer BNP and BNPP, and achieved strong performance ($AUC=0.90$, \textcolor{black}{${SEN}=0.88$}, \textcolor{black}{${SPEC}=0.81$}, $r=0.79$). Since radiographic features of pulmonary edema may not be visible on low resolution images, we also assessed the impact of image resolution on model learning and performance, comparing CNNs trained at five image sizes ($64\times64$ to $1024\times1024$). With comparable AUC values obtained at different resolutions, our experiments using three activation mapping techniques (saliency, Grad-CAM, XRAI) revealed considerable in-lung attention growth with increased resolution. The highest resolution models focus attention on the lungs, necessary for radiographic diagnosis of pulmonary edema. Our results emphasize the need to utilize radiographs of near-native resolution for optimal CNN performance, not fully captured by summary metrics like AUC.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/huynh22a.html
  PDF: https://proceedings.mlr.press/v172/huynh22a/huynh22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-huynh22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Justin
    family: Huynh
  - given: Samira
    family: Masoudi
  - given: Abraham
    family: Noorbaksh
  - given: Kyle
    family: Hasenstab
  - given: Michael
    family: Pazzani
  - given: Albert
    family: Hsiao
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 590-604
  id: huynh22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 590
  lastpage: 604
  published: 2022-12-04 00:00:00 +0000
- title: 'Diffeomorphic Image Registration Using Lipschitz Continuous Residual Networks'
  abstract: 'Image registration is an essential task in medical image analysis. We propose two novel unsupervised diffeomorphic image registration networks, which use deep Residual Networks (ResNets) as numerical approximations of the underlying continuous diffeomorphic setting governed by ordinary differential equations (ODEs), viewed as an Eulerian discretization scheme. While considering the ODE-based parameterizations of diffeomorphisms, we consider both stationary and non-stationary (time varying) velocity fields as the driving velocities to solve the ODEs, which gives rise to our two proposed architectures for diffeomorphic registration. We also employ Lipschitz-continuity on the Residual Networks in both architectures to define the admissible Hilbert space of velocity fields as a Reproducing Kernel Hilbert Spaces (RKHS) and regularize the smoothness of the velocity fields. We apply both registration networks to align and segment the OASIS brain MRI dataset. Experimental results demonstrate that our models are computation efficient and achieve comparable registration results with a smoother deformation field.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/joshi22a.html
  PDF: https://proceedings.mlr.press/v172/joshi22a/joshi22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-joshi22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Ankita
    family: Joshi
  - given: Yi
    family: Hong
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 605-617
  id: joshi22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 605
  lastpage: 617
  published: 2022-12-04 00:00:00 +0000
- title: 'FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain Network Generation'
  abstract: 'Functional magnetic resonance imaging (fMRI) is one of the most common imaging modalities to investigate brain functions. Recent studies in neuroscience stress the great potential of functional brain networks constructed from fMRI data for clinical predictions. Traditional functional brain networks, however, are noisy and unaware of downstream prediction tasks, while also incompatible with the deep graph neural network (GNN) models. In order to fully unleash the power of GNNs in network-based fMRI analysis, we develop FBNETGEN, a task-aware and interpretable fMRI analysis framework via deep brain network generation. In particular, we formulate (1) prominent region of interest (ROI) features extraction, (2) brain networks generation, and (3) clinical predictions with GNNs, in an end-to-end trainable model under the guidance of particular prediction tasks. Along with the process, the key novel component is the graph generator which learns to transform raw time-series features into task-oriented brain networks. Our learnable graphs also provide unique interpretations by highlighting prediction-related brain regions. Comprehensive experiments on two datasets, i.e., the recently released and currently largest publicly available fMRI dataset Adolescent Brain Cognitive Development (ABCD), and the widely-used fMRI dataset PNC, prove the superior effectiveness and interpretability of FBNETGEN. The implementation is available at https://github.com/Wayfear/FBNETGEN.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/kan22a.html
  PDF: https://proceedings.mlr.press/v172/kan22a/kan22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-kan22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Xuan
    family: Kan
  - given: Hejie
    family: Cui
  - given: Joshua
    family: Lukemire
  - given: Ying
    family: Guo
  - given: Carl
    family: Yang
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 618-637
  id: kan22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 618
  lastpage: 637
  published: 2022-12-04 00:00:00 +0000
- title: 'A Flexible Meta Learning Model for Image Registration'
  abstract: 'We propose a trainable architecture for affine image registration to produce robust starting points for conventional image registration methods. Learning-based methods for image registration often require networks with many parameters and heavily engineered cost functions and thus are complex and computationally expensive. Despite their success in recent years, these methods often lack the accuracy of classical iterative image registration and struggle with large deformations. On the other hand, iterative methods depend on good initial estimates and tuned hyperparameters. We tackle this problem by combining effective shallow networks and classical optimization algorithms using strategies from the field of meta-learning. The architecture presented in this work incorporates only first-order gradient information of the given registration problems, making it highly flexible and particularly well-suited as an initialization step for classical image registration.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/kanter22a.html
  PDF: https://proceedings.mlr.press/v172/kanter22a/kanter22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-kanter22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Frederic
    family: Kanter
  - given: Jan
    family: Lellmann
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 638-652
  id: kanter22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 638
  lastpage: 652
  published: 2022-12-04 00:00:00 +0000
- title: 'Denoising Autoencoders for Unsupervised Anomaly Detection in Brain MRI'
  abstract: 'Pathological brain lesions exhibit diverse appearance in brain images, making it difficult to train supervised detection solutions due to the lack of comprehensive data and annotations. Thus, in this work we tackle unsupervised anomaly detection, using only healthy data for training with the aim of detecting unseen anomalies at test time. Many current approaches employ autoencoders with restrictive architectures (i.e. containing information bottlenecks) that tend to give poor reconstructions of not only the anomalous but also the normal parts of the brain. Instead, we investigate classical denoising autoencoder models that do not require bottlenecks and can employ skip connections to give high resolution fidelity. We design a simple noise generation method of upscaling low-resolution noise that enables high-quality reconstructions. We find that with appropriate noise generation, denoising autoencoder reconstruction errors generalize to hyperintense lesion segmentation and reach state of the art performance for unsupervised tumor detection in brain MRI data, beating more complex methods such as variational autoencoders. We believe this provides a strong and easy-to-implement baseline for further research into unsupervised anomaly detection.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/kascenas22a.html
  PDF: https://proceedings.mlr.press/v172/kascenas22a/kascenas22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-kascenas22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Antanas
    family: Kascenas
  - given: Nicolas
    family: Pugeault
  - given: Alison Q.
    family: O’Neil
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 653-664
  id: kascenas22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 653
  lastpage: 664
  published: 2022-12-04 00:00:00 +0000
- title: 'Deep Learning for Model Correction in Cardiac Electrophysiological Imaging'
  abstract: 'Imaging the electrical activity of the heart can be achieved with invasive catheterisation. However, the resulting data are sparse and noisy. Mathematical modelling of cardiac electrophysiology can help the analysis but solving the associated mathematical systems can become unfeasible. It is often computationally demanding, for instance when solving for different patient conditions. We present a new framework to model the dynamics of cardiac electrophysiology at lower cost. It is based on the integration of a low-fidelity physical model and a learning component implemented here via neural networks. The latter acts as a complement to the physical part, and handles all quantities and dynamics that the simplified physical model neglects. We demonstrate that this framework allows us to reproduce the complex dynamics of the transmembrane potential and to correctly identify the relevant physical parameters, even when only partial measurements are available. This combined model-based and data-driven approach could improve cardiac electrophysiological imaging and provide predictive tools.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/kashtanova22a.html
  PDF: https://proceedings.mlr.press/v172/kashtanova22a/kashtanova22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-kashtanova22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Victoriya
    family: Kashtanova
  - given: Ibrahim
    family: Ayed
  - given: Andony
    family: Arrieula
  - given: Mark
    family: Potse
  - given: Patrick
    family: Gallinari
  - given: Maxime
    family: Sermesant
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 665-675
  id: kashtanova22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 665
  lastpage: 675
  published: 2022-12-04 00:00:00 +0000
- title: 'PILLET-GAN: Pixel-Level Lesion Traversal Generative Adversarial Network for Pneumonia Localization'
  abstract: 'he study of pneumonia localization focus on the problem of accurate lesion localization in the thoracic X-ray image. It is crucial to provide precisely localized regions to users. It can lay out the basis of the model decision by comparing the X-ray image between the ‘Healthy’ and ‘Disease’ classes. In particular, for the medical image analysis, it is essential not only to make a correct prediction for the disease but also to provide evidence to support accurate predictions. Many generative adversarial networks (GAN) based approaches are employed to show the pixel-level changes via domain translation technique to address this issue. Although previous research tried to improve localization performance by understanding the domain’s attributes for better image translation, it remains challenging to capture the specific category’s pixel-level changes. For this reason, we focus on the stage of understanding the category attributes. We propose a Pixel-Level Lesion Traversal Generative Adversarial Network (PILLET-GAN) that mines spatial features for the category via spatial attention technique and fuses them into an original feature map extracted from the generator for better domain translation. Our experimental results show that PILLET-GAN achieves superior performance compared to the state-of-the-art models on qualitative and quantitative results on the RSNA-pneumonia dataset. and quantitative results on the RSNA-pneumonia dataset'
  volume: 172
  URL: https://proceedings.mlr.press/v172/kim22a.html
  PDF: https://proceedings.mlr.press/v172/kim22a/kim22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-kim22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: HyunWoo
    family: Kim
  - given: HanBin
    family: Ko
  - given: JungJun
    family: Kim
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 676-688
  id: kim22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 676
  lastpage: 688
  published: 2022-12-04 00:00:00 +0000
- title: 'Improving Explainability of Disentangled Representations using Multipath-Attribution Mappings'
  abstract: 'Explainable AI aims to render model behavior understandable by humans, which can be seen as an intermediate step in extracting causal relations from correlative patterns. Due to the high risk of possible fatal decisions in image-based clinical diagnostics, it is necessary to integrate explainable AI into these safety-critical systems. Current explanatory methods typically assign attribution scores to pixel regions in the input image, indicating their importance for a model’s decision. However, they fall short when explaining why a visual feature is used. We propose a framework that utilizes interpretable disentangled representations for downstream-task prediction. Through visualizing the disentangled representations, we enable experts to investigate possible causation effects by leveraging their domain knowledge. Additionally, we deploy a multi-path attribution mapping for enriching and validating explanations. We demonstrate the effectiveness of our approach on a synthetic benchmark suite and two medical datasets. We show that the framework not only acts as a catalyst for causal relation extraction but also enhances model robustness by enabling shortcut detection without the need for testing under distribution shifts. Code available at https://github.com/IML-DKFZ/m-pax_lib.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/klein22a.html
  PDF: https://proceedings.mlr.press/v172/klein22a/klein22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-klein22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Lukas
    family: Klein
  - given: João B. S.
    family: Carvalho
  - given: Mennatallah
    family: El-Assady
  - given: Paolo
    family: Penna
  - given: Joachim M.
    family: Buhmann
  - given: Paul F.
    family: Jaeger
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 689-712
  id: klein22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 689
  lastpage: 712
  published: 2022-12-04 00:00:00 +0000
- title: 'Warmstart Approach for Accelerating Deep Image Prior Reconstruction in Dynamic Tomography'
  abstract: 'Deep image prior (DIP) has been successfully used in the field of tomography to obtain high-quality images from under-sampled and noisy measurements. The key advantage of DIP compared to conventional deep-learning based image reconstruction techniques is that it requires no training data and thus can be used in a flexible manner without incorporating domain specific knowledge. The downside of DIP is that it shifts the training step to reconstruction time where usually fast algorithms are required to reduced the latency between acquisition and display of the reconstructed image. In this work we tackle this problem for dynamic tomography scenarios in which a large number of temporally resolved images are taken over time. By initializing the DIP network using a previous frame of the time series, it is possible to significantly reduce the overall reconstruction time. To cope with abrupt changes in the captured time-series, we propose to use an adaptive restart method having the ability to switch between warm- and coldstart depending on the amount of inter-frame changes.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/knopp22a.html
  PDF: https://proceedings.mlr.press/v172/knopp22a/knopp22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-knopp22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Tobias
    family: Knopp
  - given: Mirco
    family: Grosser
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 713-725
  id: knopp22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 713
  lastpage: 725
  published: 2022-12-04 00:00:00 +0000
- title: 'Hidden in Plain Sight: Subgroup Shifts Escape OOD Detection'
  abstract: 'The safe application of machine learning systems in healthcare relies on valid performance claims. Such  claims are typically established in a clinical validation setting designed to be as close as possible to the intended use, but inadvertent domain or population shifts remain a fundamental problem. In particular, subgroups may be differently represented in the data distribution in the validation  compared to the application setting. For example, algorithms trained on population cohort data spanning all age groups may be predominantly applied in elderly people. While these data are not “out-of distribution”, changes in the prevalence of different subgroups may have considerable impact on algorithm performance or will at least render original performance claims invalid. Both are serious problems for safely deploying machine learning systems. In this paper, we demonstrate the fundamental limitations of individual example out-of-distribution detection for such scenarios, and show that subgroup shifts can be detected on a population-level instead. We formulate population-level shift detection in the framework of statistical hypothesis testing and show that recent state-of-the-art statistical tests can be effectively applied to subgroup shift detection in a synthetic scenario as well as real histopathology images.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/koch22a.html
  PDF: https://proceedings.mlr.press/v172/koch22a/koch22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-koch22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Lisa M
    family: Koch
  - given: Christian M
    family: Schürch
  - given: Arthur
    family: Gretton
  - given: Philipp
    family: Berens
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 726-740
  id: koch22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 726
  lastpage: 740
  published: 2022-12-04 00:00:00 +0000
- title: 'Confidence Histograms for Model Reliability Analysis and Temperature Calibration'
  abstract: 'Proper estimation of uncertainty may help the adoption of deep learning-based solutions in clinical practice, when measurements can take error bounds into account and out-of-distribution situations can be reliably detected. Therefore, a variety of approaches have been proposed already, with varying requirements and computational effort. Uncertainty estimation is complicated by the fact that typical neural networks are overly confident; this effect is particularly prominent with the Dice loss, which is commonly used for image segmentation. Therefore, various methods for model calibration have been proposed to reduce the discrepancy between classifier confidence and the observed accuracy. In this work, we focus on the simple calibration method of introducing a temperature parameter for the softmax operation. This approach is not only appealing because of its mathematical simplicity, it also appears to be well-suited for countering the main distortion of the classifier output confidence levels. Finally, it comes at literally zero extra cost, because the necessary multiplications can be integrated into the previous layer’s weights after calibration, and a scalar temperature does not affect the classification at all. Our contributions are as follows: We thoroughly evaluate the confidence behavior of several models with different architectures, different numbers of output classes, different loss functions, and different segmentation tasks. In order to do so, we propose an efficient intermediate representation and some adaptations of reliability diagrams to semantic segmentation. We investigate different calibration measures and their optimal temperatures for these diverse models.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/kock22a.html
  PDF: https://proceedings.mlr.press/v172/kock22a/kock22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-kock22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Farina
    family: Kock
  - given: Felix
    family: Thielke
  - given: Grzegorz
    family: Chlebus
  - given: Hans
    family: Meine
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 741-759
  id: kock22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 741
  lastpage: 759
  published: 2022-12-04 00:00:00 +0000
- title: 'A Modular Deep Learning Pipeline for Cell Culture Analysis: Investigating the Proliferation of Cardiomyocytes'
  abstract: 'Cardiovascular disease is a leading cause of death in the Western world. The exploration of strategies to enhance the regenerative capacity of the mammalian heart is therefore of great interest. One approach is the treatment of isolated transgenic mouse cardiomyocytes (CMs) with potentially cell cycle-inducing substances and assessment if this results in atypical cell cycle activity or authentic cell division. This requires the tedious and cost intensive manual analysis of microscopy images. Recent advances have led to an increasing use of deep learning (DL) algorithms in cellular image analysis. While developments in image or single-cell classification are well advanced, multi-cell classification in crowded image scenarios remains a challenge. This is reinforced by typically smaller dataset sizes in such laboratory-specific analyses. In this paper, we propose a modular DL-based image analysis pipeline for multi-cell classification of mononuclear and binuclear CMs in confocal microscopy imaging data. We trisect the pipeline structure into preprocessing, modelling and postprocessing. We perform semantic segmentation to extract general image features, which are further analyzed in postprocessing. In total, we conduct 173 experiments. We benchmark 18 encoder-decoder model architectures, perform hyperparameter optimization across 28 runs, and conduct 127 experiments to evaluate dataset-related effects. The results show that our approach has great potential for automating specific cell culture analyses even with small datasets.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/leyendecker22a.html
  PDF: https://proceedings.mlr.press/v172/leyendecker22a/leyendecker22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-leyendecker22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Lars
    family: Leyendecker
  - given: Julius
    family: Haas
  - given: Tobias
    family: Piotrowski
  - given: Maik
    family: Frye
  - given: Cora
    family: Becker
  - given: Bernd K.
    family: Fleischmann
  - given: Michael
    family: Hesse
  - given: Robert H.
    family: Schmitt
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 760-773
  id: leyendecker22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 760
  lastpage: 773
  published: 2022-12-04 00:00:00 +0000
- title: 'Vision Transformers Enable Fast and Robust Accelerated MRI'
  abstract: 'The Vision Transformer, when trained or pre-trained on datasets consisting of millions of images, gives excellent accuracy for image classification tasks and offers computational savings relative to convolutional neural networks. Motivated by potential accuracy gains and computational savings, we study Vision Transformers for accelerated magnetic resonance image reconstruction. We show that, when trained on the fastMRI dataset, a popular dataset for accelerated MRI only consisting of thousands of images, a Vision Transformer tailored to image reconstruction yields on par reconstruction accuracy with the U-net while enjoying higher throughput and less memory consumption. Furthermore, as Transformers are known to perform best with large-scale pre-training, but MRI data is costly to obtain, we propose a simple yet effective pre-training, which solely relies on big natural image datasets, such as ImageNet. We show that pre-training the Vision Transformer drastically improves training data efficiency for accelerated MRI, and increases robustness towards anatomy shifts. In the regime where only 100 MRI training images are available, the pre-trained Vision Transformer achieves significantly better image quality than pre-trained convolutional networks and the current state-of-the-art. Our code is available at \url{https://github.com/MLI-lab/transformers_for_imaging}.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/lin22a.html
  PDF: https://proceedings.mlr.press/v172/lin22a/lin22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-lin22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Kang
    family: Lin
  - given: Reinhard
    family: Heckel
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 774-795
  id: lin22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 774
  lastpage: 795
  published: 2022-12-04 00:00:00 +0000
- title: 'Detecting Out-of-Distribution via an Unsupervised Uncertainty Estimation for Prostate Cancer Diagnosis'
  abstract: 'Artificial intelligence-based prostate cancer (PCa) detection models have been widely explored to assist clinical diagnosis. However, these trained models may generate erroneous results specifically on datasets that are not within training distribution. In this paper, we propose an approach to tackle this so-called out-of-distribution (OOD) data problem. Specifically, we devise an end-to-end unsupervised framework to estimate uncertainty values for cases analyzed by a previously trained PCa detection model. Our PCa detection model takes the inputs of bpMRI scans and through our proposed approach we identify OOD cases that are likely to generate degraded performance due to the data distribution shifts. The proposed OOD framework consists of two parts. First, an autoencoder-based reconstruction network is proposed, which learns discrete latent representations of in-distribution data. Second, the uncertainty is computed using perceptual loss that measures the distance between original and reconstructed images in the feature space of a pre-trained PCa detection network. The effectiveness of the proposed framework is evaluated on seven independent data collections with a total of 1,432 cases. The performance of pre-trained PCa detection model is significantly improved by excluding cases with high uncertainty.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/liu22a.html
  PDF: https://proceedings.mlr.press/v172/liu22a/liu22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-liu22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Jingya
    family: Liu
  - given: Bin
    family: Lou
  - given: Mamadou
    family: Diallo
  - given: Tongbai
    family: Meng
  - given: Heinrich
    prefix: von
    family: Busch
  - given: Robert
    family: Grimm
  - given: Yingli
    family: Tian
  - given: Dorin
    family: Comaniciu
  - given: Ali
    family: Kamen
  - given: ProstateAI Clinical
    family: Collaborators
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 796-807
  id: liu22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 796
  lastpage: 807
  published: 2022-12-04 00:00:00 +0000
- title: 'Hybrid Ladder Transformers with Efficient Parallel-Cross Attention for Medical Image Segmentation'
  abstract: 'Most existing transformer-based network architectures for computer vision tasks are large (in number of parameters) and require large-scale datasets for training. However, therelatively small number of data samples in medical imaging compared to the datasets for vision applications makes it difficult to effectively train transformers for medical imagingapplications. Further, transformer-based architectures encode long-range dependencies in the data and are able to learn more global representations. This could bridge the gap with convolutional neural networks (CNNs), which primarily operate on features extracted in local image neighbourhoods. In this work, we present a hybrid transformer-based approach for segmentation of medical images that works in conjunction with a CNN. We propose to use learnable global attention heads along with the traditional convolutional segmentation network architecture to encode long-range dependencies. Specifically, in our proposed architecture the local information extracted by the convolution operations and the global information learned by the self-attention mechanisms are fused using bi-directional cross attention during the encoding process, resulting in what we call a hybrid ladder transformer (HyLT). We evaluate the proposed network on two different medical image segmentation datasets. The results show that it achieves better results than the relevant CNN- and transformer-based architectures'
  volume: 172
  URL: https://proceedings.mlr.press/v172/luo22a.html
  PDF: https://proceedings.mlr.press/v172/luo22a/luo22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-luo22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Haozhe
    family: Luo
  - given: Yu
    family: Changdong
  - given: Raghavendra
    family: Selvan
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 808-819
  id: luo22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 808
  lastpage: 819
  published: 2022-12-04 00:00:00 +0000
- title: 'Semi-Supervised Medical Image Segmentation via Cross Teaching between CNN and Transformer'
  abstract: 'Recently, deep learning with Convolutional Neural Networks (CNNs) and Transformers has shown encouraging results in fully supervised medical image segmentation. However, it is still challenging for them to achieve good performance with limited annotations for training. This work presents a very simple yet efficient framework for semi-supervised medical image segmentation by introducing the cross teaching between CNN and Transformer. Specifically, we simplify the classical deep co-training from consistency regularization to cross teaching, where the prediction of a network is used as the pseudo label to supervise the other network directly end-to-end. Considering the difference in learning paradigm between CNN and Transformer, we introduce the Cross Teaching between CNN and Transformer rather than just using CNNs. Experiments on a public benchmark show that our method outperforms eight existing semi-supervised learning methods just with a more straight-forward framework. Notably, this work may be the first attempt to combine CNN and transformer for semi-supervised medical image segmentation and achieve promising results on a public benchmark. Code is available at: https://github.com/HiLab-git/SSL4MIS.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/luo22b.html
  PDF: https://proceedings.mlr.press/v172/luo22b/luo22b.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-luo22b.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Xiangde
    family: Luo
  - given: Minhao
    family: Hu
  - given: Tao
    family: Song
  - given: Guotai
    family: Wang
  - given: Shaoting
    family: Zhang
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 820-833
  id: luo22b
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 820
  lastpage: 833
  published: 2022-12-04 00:00:00 +0000
- title: 'Angular Super-Resolution in Diffusion MRI with a 3D Recurrent Convolutional Autoencoder'
  abstract: 'High resolution diffusion MRI (dMRI) data is often constrained by limited scanning time in clinical settings, thus restricting the use of downstream analysis techniques that would otherwise be available. In this work we develop a 3D recurrent convolutional neural network (RCNN) capable of super-resolving dMRI volumes in the angular (q-space) domain. Our approach formulates the task of angular super-resolution as a patch-wise regression using a 3D autoencoder conditioned on target b-vectors. Within the network we use a convolutional long short term memory (ConvLSTM) cell to model the relationship between q-space samples. We compare model performance against a baseline spherical harmonic interpolation and a 1D variant of the model architecture. We show that the 3D model has the lowest error rates across different subsampling schemes and b-values. The relative performance of the 3D RCNN is greatest in the very low angular resolution domain. Code for this project is available at github.com/m-lyon/dMRI-RCNN.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/lyon22a.html
  PDF: https://proceedings.mlr.press/v172/lyon22a/lyon22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-lyon22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Matthew
    family: Lyon
  - given: Paul
    family: Armitage
  - given: Mauricio A
    family: Álvarez
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 834-846
  id: lyon22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 834
  lastpage: 846
  published: 2022-12-04 00:00:00 +0000
- title: 'Label conditioned segmentation'
  abstract: 'Semantic segmentation is an important task in computer vision that is often tackled with convolutional neural networks (CNNs). A CNN learns to produce pixel-level predictions through training on pairs of images and their corresponding ground-truth segmentation labels. For segmentation tasks with multiple classes, the standard approach is to use a network that computes a multi-channel probabilistic segmentation map, with each channel representing one class. In applications where the image grid size (e.g., when it is a 3D volume) and/or the number of labels is relatively large, the standard (baseline) approach can become prohibitively expensive for our computational resources. In this paper, we propose a simple yet effective method to address this challenge. In our approach, the segmentation network produces a single-channel output, while being conditioned on a single class label, which determines the output class of the network. Our method, called label conditioned segmentation (LCS), can be used to segment images with a very large number of classes, which might be infeasible for the baseline approach. We also demonstrate in the experiments that label conditioning can improve the accuracy of a given backbone architecture. Finally, as we show in our results, an LCS model can produce previously unseen fine-grained labels during inference time, when only coarse labels were available during training. We provide our code here: https://github.com/tym002/Label-conditioned-segmentation'
  volume: 172
  URL: https://proceedings.mlr.press/v172/ma22a.html
  PDF: https://proceedings.mlr.press/v172/ma22a/ma22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-ma22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Tianyu
    family: Ma
  - given: Benjamin C
    family: Lee
  - given: Mert R
    family: Sabuncu
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 847-857
  id: ma22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 847
  lastpage: 857
  published: 2022-12-04 00:00:00 +0000
- title: 'MR Image Super Resolution By Combining Feature Disentanglement CNNs and Vision Transformers'
  abstract: 'State of the art magnetic resonance (MR) image super-resolution methods (ISR) using convolutional neural networks (CNNs) leverage limited contextual information due to the limited spatial coverage of CNNs. Vision transformers (ViT) learn better global context that is helpful in generating superior quality HR images. We combine local information of CNNs and global information from ViTs for image super resolution and output super resolved images that have superior quality than those produced by state of the art methods. We include  extra constraints through multiple novel loss functions that preserve structure and texture information from the low resolution to high resolution images.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/mahapatra22a.html
  PDF: https://proceedings.mlr.press/v172/mahapatra22a/mahapatra22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-mahapatra22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Dwarikanath
    family: Mahapatra
  - given: Zongyuan
    family: Ge
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 858-878
  id: mahapatra22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 858
  lastpage: 878
  published: 2022-12-04 00:00:00 +0000
- title: 'LILE: Look In-Depth before Looking Elsewhere – A Dual Attention Network using Transformers for Cross-Modal Information Retrieval in Histopathology Archives'
  abstract: 'The volume of available data has grown dramatically in recent years in many applications. Furthermore, the age of networks that used multiple modalities separately has practically ended. Therefore, enabling bidirectional cross-modality data retrieval capable of processing has become a requirement for many domains and disciplines of research. This is especially true in the medical field, as data comes in a multitude of types, including various types of images and reports as well as molecular data. Most contemporary works apply cross attention to highlight the essential elements of an image or text in relation to the other modalities and try to match them together. However, regardless of their importance in their own modality, these approaches usually consider features of each modality equally. In this study, self-attention as an additional loss term will be proposed to enrich the internal representation provided into the cross attention module. This work suggests a novel architecture with a new loss term to help represent images and texts in the joint latent space. Experiment results on two benchmark datasets, i.e. MS-COCO and ARCH, show the effectiveness of the proposed method.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/maleki22a.html
  PDF: https://proceedings.mlr.press/v172/maleki22a/maleki22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-maleki22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Danial
    family: Maleki
  - given: H.R
    family: Tizhoosh
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 879-894
  id: maleki22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 879
  lastpage: 894
  published: 2022-12-04 00:00:00 +0000
- title: 'Self-Supervised Transformers for fMRI representation'
  abstract: 'We present TFF, which is a Transformer framework for the analysis of functional Magnetic Resonance Imaging (fMRI) data. TFF employs a two-phase training approach. First, self-supervised training is applied to a collection of fMRI scans, where the model is trained to reconstruct 3D volume data. Second, the pre-trained model is fine-tuned on specific tasks, utilizing ground truth labels. Our results show state-of-the-art performance on a variety of fMRI tasks, including age and gender prediction, as well as schizophrenia recognition. Our code for the training, network architecture, and results is attached as supplementary material.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/malkiel22a.html
  PDF: https://proceedings.mlr.press/v172/malkiel22a/malkiel22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-malkiel22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Itzik
    family: Malkiel
  - given: Gony
    family: Rosenman
  - given: Lior
    family: Wolf
  - given: Talma
    family: Hendler
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 895-913
  id: malkiel22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 895
  lastpage: 913
  published: 2022-12-04 00:00:00 +0000
- title: 'On the Pitfalls of Using the Residual Error as Anomaly Score'
  abstract: 'Many current state-of-the-art methods for anomaly localization in medical images rely on calculating a residual image between a potentially anomalous input image and its ("healthy") reconstruction. As the reconstruction of the unseen anomalous region should be erroneous, this yields large residuals as a score to detect anomalies in medical images. However, this assumption does not take into account residuals resulting from imperfect reconstructions of the machine learning models used. Such errors can easily overshadow residuals of interest and therefore strongly question the use of residual images as scoring function. Our work explores this fundamental problem of residual images in detail. We theoretically define the problem and thoroughly evaluate the influence of intensity and texture of anomalies against the effect of imperfect reconstructions in a series of experiments.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/meissen22a.html
  PDF: https://proceedings.mlr.press/v172/meissen22a/meissen22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-meissen22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Felix
    family: Meissen
  - given: Benedikt
    family: Wiestler
  - given: Georgios
    family: Kaissis
  - given: Daniel
    family: Rueckert
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 914-928
  id: meissen22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 914
  lastpage: 928
  published: 2022-12-04 00:00:00 +0000
- title: 'Robust Multi-Organ Nucleus Segmentation Using a Locally Rotation Invariant Bispectral U-Net'
  abstract: 'Locally Rotation Invariant (LRI) operators have shown great potential to robustly identify biomedical textures where discriminative patterns appear at random positions and orientations. We build LRI operators through the local projection of the image on circular harmonics followed by the computation of the bispectrum, which is LRI by design. This formulation allows to avoid the discretization of the orientations and does not require any criterion to locally align the descriptors. This operator is used in a convolutional layer resulting in LRI Convolutional Neural Networks (LRI CNN). To evaluate the relevance of this approach, we use it to segment cellular nuclei in histopathological images. We compare the proposed bispectral LRI layer against a standard convolutional layer in a U-Net architecture. While they perform equally in terms of F-score, the LRI CNN provides more robust segmentation with respect to orientation, even when rotational data augmentation is used. This robustness is essential when the relevant pattern may vary in orientation, which is often the case in medical images.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/oreiller22a.html
  PDF: https://proceedings.mlr.press/v172/oreiller22a/oreiller22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-oreiller22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Valentin
    family: Oreiller
  - given: Julien
    family: Fageot
  - given: Vincent
    family: Andrearczyk
  - given: John O.
    family: Prior
  - given: Adrien
    family: Depeursinge
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 929-943
  id: oreiller22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 929
  lastpage: 943
  published: 2022-12-04 00:00:00 +0000
- title: 'Structural Networks for Brain Age Prediction'
  abstract: 'Biological networks have gained considerable attention within the Deep Learning community because of the promising framework of Graph Neural Networks (GNN), neural models that operate in complex networks. In the context of neuroimaging, GNNs have successfully been employed for functional MRI processing but their application to ROI-level structural MRI (sMRI) remains mostly unexplored. In this work we analyze the implementation of these geometric models with sMRI by building graphs of ROIs (ROI graphs) using tools from Graph Signal Processing literature and evaluate their performance in a downstream supervised task, age prediction. We first make a qualitative and quantitative comparison of the resulting networks obtained with common graph topology learning strategies. In a second stage, we train GNN-based models for brain age prediction. Since the order of every ROI graph is exactly the same and each vertex is an entity by itself (a ROI), we evaluate whether including ROI information during message-passing or global pooling operations is beneficial and compare the performance of GNNs against a Fully-Connected Neural Network baseline. The results show that ROI-level information is needed during the global pooling operation in order to achieve competitive results. However, no relevant improvement has been detected when it is incorporated during the message passing. These models achieve a MAE of 4.27 in hold-out test data, which is a performance very similar to the baseline, suggesting that the inductive bias included with the obtained graph connectivity is relevant and useful to reduce the dimensionality of the problem.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/pina22a.html
  PDF: https://proceedings.mlr.press/v172/pina22a/pina22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-pina22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Oscar
    family: Pina
  - given: Irene
    family: Cumplido-Mayoral
  - given: Raffaele
    family: Cacciaglia
  - given: José María
    family: González-de-Echávarri
  - given: Juan Domingo
    family: Gispert
  - given: Verónica
    family: Vilaplana
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 944-960
  id: pina22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 944
  lastpage: 960
  published: 2022-12-04 00:00:00 +0000
- title: 'Video-based Computer-aided Laparoscopic Bleeding Management: a Space-time Memory Neural Network with Positional Encoding and Adversarial Domain Adaptation'
  abstract: 'One of the main challenges in laparoscopic procedures is handling intraoperative bleeding. We propose video-based Computer-aided Laparoscopic Bleeding Management (CALBM) for early detection and management of intraoperative bleeding. Our system performs the online video-based segmentation of bleeding sources and displays them to the surgeon. It hinges on an improved space-time memory network, which we train from real and semi-synthetic data, using adversarial domain adaptation. Our system improves the IoU and F-Score from 69.97% to 73.40% and 50.23% to 58.09% in comparison to the baseline space-time memory network. It is far better than the prior CALBM systems based on still images, which we reimplemented with DeepLabV3+, reaching an  IoU and F-Score of 65.86% and 43.19%. The improvement is also supported by user evaluation.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/rabbani22a.html
  PDF: https://proceedings.mlr.press/v172/rabbani22a/rabbani22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-rabbani22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Navid
    family: Rabbani
  - given: Callyane
    family: Seve
  - given: Nicolas
    family: Bourdel
  - given: Adrien
    family: Bartoli
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 961-974
  id: rabbani22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 961
  lastpage: 974
  published: 2022-12-04 00:00:00 +0000
- title: 'Attention-Guided Prostate Lesion Localization and Grade Group Classification with Multiple Instance Learning'
  abstract: 'Lesion localization is a component of prostate magnetic resonance imaging (MRI) evaluation and is essential for targeted biopsy by enabling registration with real-time ultrasound. Most previous work on prostate cancer localization has focused on classification or segmentation assuming the availability of radiology annotations.  In this work, we propose to use an unsupervised attention-based multiple instance learning (MIL) method in an application for the classification and localization of clinically significant prostate cancer. We train our model end-to-end with only image-level labels instead of relying on voxel-level annotations. We extend MIL method by operating both on patches and the whole size images to learn local and global features, which improves classification and localization performance. To better leverage the relationships between multi-modal data, we use an architecture with multiple encoding paths, where each path processes one image modality. The model was developed on a dataset containing 986 multiparametric prostate MRIs and achieved $0.75 \pm  0.03$ AUROC using 3-fold cross-validation in prostate cancer Grade Group classification. Lesion localization analysis showed 70-80% sensitivity for GG $\ge$  3 at less than one false positive (FP) per patient and 65% of GG2 at one FP per patient.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/redekop22a.html
  PDF: https://proceedings.mlr.press/v172/redekop22a/redekop22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-redekop22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Ekaterina
    family: Redekop
  - given: Karthik V.
    family: Sarma
  - given: Adam
    family: Kinnaird
  - given: Anthony
    family: Sisk
  - given: Steven S.
    family: Raman
  - given: Leonard S.
    family: Marks
  - given: William
    family: Speier
  - given: Corey W.
    family: Arnold
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 975-987
  id: redekop22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 975
  lastpage: 987
  published: 2022-12-04 00:00:00 +0000
- title: 'Are 2.5D approaches superior to 3D deep networks in whole brain segmentation?'
  abstract: 'Segmentation of 3D volumes with a large number of labels, small convoluted structures, and lack of contrast between various structural boundaries is a difficult task. While recent methodological advances across many segmentation tasks are dominated by 3D architectures, currently the strongest performing method for whole brain segmentation is FastSurferCNN, a 2.5D approach. To shed light on the nuanced differences between 2.5D and various 3D approaches, we perform a thorough and fair comparison and suggest a spatially-ensembled 3D architecture. Interestingly, we observe training memory intensive 3D segmentation on full-view images does not outperform the 2.5D approach. A shift to training on patches even while evaluating on full-view solves these limitations of both memory and performance limitations at the same time. We demonstrate significant performance improvements over state-of-the-art 3D methods on both Dice Similarity Coefficient and especially average Hausdorff Distance measures across five datasets. Finally, our validation across variations of neurodegenerative disease states and scanner manufacturers, shows we outperform the previously leading 2.5D approach FastSurferCNN demonstrating robust segmentation performance in realistic settings. Our code is available online at github.com/Deep-MI/3d-neuro-seg.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/roy22a.html
  PDF: https://proceedings.mlr.press/v172/roy22a/roy22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-roy22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Saikat
    family: Roy
  - given: David
    family: Kügler
  - given: Martin
    family: Reuter
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 988-1004
  id: roy22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 988
  lastpage: 1004
  published: 2022-12-04 00:00:00 +0000
- title: 'Is it Possible to Predict MGMT Promoter Methylation from Brain Tumor MRI Scans using Deep Learning Models?'
  abstract: 'Glioblastoma is a common brain malignancy that tends to occur in older adults and is almost always lethal. The effectiveness of chemotherapy, being the standard treatment for most cancer types, can be improved if a particular genetic sequence in the tumor known as MGMT promoter is methylated. However, to identify the state of the MGMT promoter, the conventional approach is to perform a biopsy for genetic analysis, which is time and effort consuming. A couple of recent publications proposed a connection between the MGMT promoter state and the MRI scans of the tumor and hence suggested the use of deep learning models for this purpose. Therefore, in this work, we use one of the most extensive datasets, BraTS 2021, to study the potency of employing deep learning solutions, including 2D and 3D CNN models and vision transformers. After conducting a thorough analysis of the models’ performance, we concluded that there seems to be no connection between the MRI scans and the state of the MGMT promoter.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/saeed22a.html
  PDF: https://proceedings.mlr.press/v172/saeed22a/saeed22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-saeed22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Numan
    family: Saeed
  - given: Shahad
    family: Hardan
  - given: Kudaibergen
    family: Abutalip
  - given: Mohammad
    family: Yaqub
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1005-1018
  id: saeed22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1005
  lastpage: 1018
  published: 2022-12-04 00:00:00 +0000
- title: 'YAMU: Yet Another Modified U-Net Architecture for Semantic Segmentation'
  abstract: 'Digital histopathology images must be examined accurately and quickly as part of a pathologist’s clinical procedure. For histopathology image segmentation, different variants of U-Net and fully convolutional networks (FCN) are state-of-the-art. HistNet or histopathology network for semantic labelling in histopathology images, for example, is one of them. We improve our previously proposed model HistNet in this paper by introducing new skip pathways to the decoder stage to aggregate multiscale features and incorporate a feature pyramid to keep the contextual information. In addition, to boost performance, we employ a deep supervision training technique. We show that not only does the proposed design outperform the baseline, but it also outperforms state-of-the-art segmentation architectures with much fewer parameters.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/samanta22a.html
  PDF: https://proceedings.mlr.press/v172/samanta22a/samanta22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-samanta22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Pranab
    family: Samanta
  - given: Nitin
    family: Singhal
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1019-1033
  id: samanta22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1019
  lastpage: 1033
  published: 2022-12-04 00:00:00 +0000
- title: 'Segmentation-Consistent Probabilistic Lesion Counting'
  abstract: 'Lesion counts are important indicators of disease severity, patient prognosis, and treatment efficacy, yet counting as a task in medical imaging is often overlooked in favor of segmentation. This work introduces a novel continuously differentiable function that maps lesion segmentation predictions to lesion count probability distributions in a consistent manner. The proposed end-to-end approach—which consists of voxel clustering, lesion-level voxel probability aggregation, and Poisson-binomial counting—is non-parametric and thus offers a robust and consistent way to augment lesion segmentation models with post hoc counting capabilities. Experiments on Gadolinium-enhancing lesion counting demonstrate that our method outputs accurate and well-calibrated count distributions that capture meaningful uncertainty information. They also reveal that our model is suitable for multi-task learning of lesion segmentation, is efficient in low data regimes, and is robust to adversarial attacks.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/schroeter22a.html
  PDF: https://proceedings.mlr.press/v172/schroeter22a/schroeter22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-schroeter22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Julien
    family: Schroeter
  - given: Chelsea
    family: Myers-Colet
  - given: Douglas L
    family: Arnold
  - given: Tal
    family: Arbel
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1034-1056
  id: schroeter22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1034
  lastpage: 1056
  published: 2022-12-04 00:00:00 +0000
- title: 'Survival Analysis for Idiopathic Pulmonary Fibrosis using CT Images and Incomplete Clinical Data'
  abstract: 'Idiopathic Pulmonary Fibrosis (IPF) is an inexorably progressive fibrotic lung disease with a variable and unpredictable rate of progression. CT scans of the lungs inform clinical assessment of IPF patients and contain pertinent information related to disease progression. In this work, we propose a multi-modal method that uses neural networks and memory banks to predict the survival of IPF patients using clinical and imaging data. The majority of clinical IPF patient records have missing data (e.g. missing lung function tests). To this end, we propose a probabilistic model that captures the dependencies between the observed clinical variables and imputes missing ones. This principled approach to missing data imputation can be naturally combined with a deep survival analysis model. We show that the proposed framework yields significantly better survival analysis results than baselines in terms of concordance index and integrated Brier score. Our work also provides insights into novel image-based biomarkers that are linked to mortality.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/shahin22a.html
  PDF: https://proceedings.mlr.press/v172/shahin22a/shahin22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-shahin22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Ahmed
    family: Shahin
  - given: Joseph
    family: Jacob
  - given: Daniel
    family: Alexander
  - given: David
    family: Barber
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1057-1074
  id: shahin22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1057
  lastpage: 1074
  published: 2022-12-04 00:00:00 +0000
- title: 'Learning Strategies for Contrast-agnostic Segmentation via SynthSeg for Infant MRI data'
  abstract: 'Longitudinal studies of infants’ brains are essential for research and clinical detection of neurodevelopmental disorders. However, for infant brain MRI scans, effective deep learning-based  segmentation frameworks exist only within small age intervals due to the large image intensity and contrast changes that take place in the early postnatal stages of development. However, using different segmentation frameworks or models at different age intervals within the same longitudinal data set would cause segmentation inconsistencies and age-specific biases. Thus, an age-agnostic segmentation model for infants’ brains is needed. In this paper, we present “Infant-SynthSeg“, an extension of the contrast-agnostic SynthSeg segmentation framework applicable to MRI data of infants at ages within the first year of life. Our work mainly focuses on extending learning strategies related to synthetic data generation and augmentation, with the aim of creating a method that employs training data capturing features unique to infants’ brains during this early-stage development. Comparison across different learning strategy settings, as well as a more-traditional contrast-aware deep learning model (nnU-net) are presented. Our experiments show that our trained Infant-SynthSeg models show consistently high segmentation performance on MRI scans of infant brains throughout the first year of life. Furthermore, as the model is trained on ground truth labels at different ages, even labels that are not present at certain ages (such as cerebellar white matter at 1 month) can be appropriately segmented via Infant-SynthSeg across the whole age range. Finally, while Infant-SynthSeg shows consistent segmentation performance across the first year of life, it is outperformed by age-specific deep learning models trained for a specific narrow age range.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/shang22a.html
  PDF: https://proceedings.mlr.press/v172/shang22a/shang22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-shang22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Ziyao
    family: Shang
  - given: Md Asadullah
    family: Turja
  - given: Eric
    family: Feczko
  - given: Audrey
    family: Houghton
  - given: Amanda
    family: Rueter
  - given: Lucille
    family: A Moore
  - given: Kathy
    family: Snider
  - given: Timothy
    family: Hendrickson
  - given: Paul
    family: Reiners
  - given: Sally
    family: Stoyell
  - given: Omid
    family: Kardan
  - given: Monica
    family: Rosenberg
  - given: Jed T
    family: Elison
  - given: Damien A
    family: Fair
  - given: Martin A
    family: Styner
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1075-1084
  id: shang22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1075
  lastpage: 1084
  published: 2022-12-04 00:00:00 +0000
- title: 'Attention Guided Deep Supervision Model for Prostate Segmentation in Multisite Heterogeneous MRI Data'
  abstract: 'Prostate cancer and benign prostatic hyperplasia are common diseases in men and require early and accurate diagnosis for optimal treatment. Standard diagnostic tests such as the prostate-specific antigen test and digital rectal examination are inconvenient. Thus, non-invasive methods such as magnetic resonance imaging (MRI) and automated image analysis are increasingly utilised to facilitate and improve prostate diagnostics. Segmentation is a vital part of the prostate image analysis pipeline, and deep neural networks are now the tool of choice to automate this task. In this work, we benchmark various deep neural networks for 3D prostate segmentation using four different publicly available datasets and one private dataset. We show that popular networks such as U-Net trained on one dataset typically generalise poorly when tested on others due to data heterogeneity. Aiming to address this issue, we propose a novel deep-learning architecture for prostate whole-gland segmentation in T2-weighted MRI images that exploits various techniques such as pyramid pooling, concurrent spatial and channel squeeze and excitation, and deep supervision. Our extensive experiments demonstrate that it performs superiorly without requiring special adaptation to any specific dataset.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/shanmugalingam22a.html
  PDF: https://proceedings.mlr.press/v172/shanmugalingam22a/shanmugalingam22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-shanmugalingam22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Kuruparan
    family: Shanmugalingam
  - given: Arcot
    family: Sowmya
  - given: Daniel
    family: Moses
  - given: Erik
    family: Meijering
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1085-1095
  id: shanmugalingam22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1085
  lastpage: 1095
  published: 2022-12-04 00:00:00 +0000
- title: 'Unsupervised Domain Adaptation for Medical Image Segmentation via Self-Training of Early Features'
  abstract: 'U-Net models provide a state-of-the-art approach for medical image segmentation, but their accuracy is often reduced when training and test images come from different domains, such as different scanners. Recent work suggests that, when limited supervision is available for domain adaptation, early U-Net layers benefit the most from a refinement. This motivates our proposed approach for self-supervised refinement, which does not require any manual annotations, but instead refines early layers based on the richer, higher-level information that is derived in later layers of the U-Net. This is achieved by adding a segmentation head for early features, and using the final predictions of the network as pseudo-labels for refinement. This strategy reduces detrimental effects of imperfection in the pseudo-labels, which are unavoidable given the domain shift, by retaining their probabilistic nature and restricting the refinement to early layers. Experiments on two medical image segmentation tasks confirm the effectiveness of this approach, even in a one-shot setting, and compare favorably to a baseline method for unsupervised domain adaptation.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/sheikh22a.html
  PDF: https://proceedings.mlr.press/v172/sheikh22a/sheikh22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-sheikh22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Rasha
    family: Sheikh
  - given: Thomas
    family: Schultz
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1096-1107
  id: sheikh22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1096
  lastpage: 1107
  published: 2022-12-04 00:00:00 +0000
- title: 'Self-Supervised Representation Learning for High-Content Screening'
  abstract: 'Biopharma drug discovery requires a set of approaches to find, produce, and test the safety of drugs for clinical application. A crucial part involves image-based screening of cell culture models where single cells are stained with appropriate markers to visually distinguish between disease and healthy states. In practice, such image-based screening experiments are frequently performed using highly scalable and automated multichannel microscopy instruments. This automation enables parallel screening against large panels of marketed drugs with known function. However, the large data volume produced by such instruments hinders a systematic inspection by human experts, which consequently leads to an extensive and biased data curation process for supervised phenotypic endpoint classification. To overcome this limitation, we propose a novel approach for learning an embedding of phenotypic endpoints, without any supervision. We employ the concept of archetypal analysis, in which pseudo-labels are extracted based on biologically reasonable endpoints. Subsequently, we use a self-supervised triplet network to learn a phenotypic embedding which is used for visual inspection and top-down assay quality control. Extensive experiments on two industry-relevant assays demonstrate that our method outperforms state-of-the-art unsupervised and supervised approaches.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/siegismund22a.html
  PDF: https://proceedings.mlr.press/v172/siegismund22a/siegismund22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-siegismund22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Daniel
    family: Siegismund
  - given: Mario
    family: Wieser
  - given: Stephan
    family: Heyse
  - given: Stephan
    family: Steigele
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1108-1124
  id: siegismund22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1108
  lastpage: 1124
  published: 2022-12-04 00:00:00 +0000
- title: 'MRI bias field correction with an implicitly trained CNN'
  abstract: 'In magnetic resonance imaging (MRI), bias fields are difficult to correct since they are inherently unknown. They cause intra-volume intensity inhomogeneities which limit the performance of subsequent automatic medical imaging tasks, \eg, tissue-based segmentation. Since the ground truth is unavailable, training a supervised machine learning solution requires approximating the bias fields, which limits the resulting method. We introduce implicit training which sidesteps the inherent lack of data and allows the training of machine learning solutions without ground truth. We describe how training a model implicitly for bias field correction allows using non-medical data for training, achieving a highly generalized model. The implicit approach was compared to a more traditional training based on medical data. Both models were compared to an optimized N4ITK method, with evaluations on six datasets. The implicitly trained model improved the homogeneity of all encountered medical data, and it generalized better for a range of anatomies, than the model trained traditionally. The model achieves a significant speed-up over an optimized N4ITK method—by a factor of $100$, and after training, it also requires no parameters to tune. For tasks such as bias field correction—where ground truth is generally not available, but the characteristics of the corruption are known—implicit training promises to be a fruitful alternative for highly generalized solutions.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/simko22a.html
  PDF: https://proceedings.mlr.press/v172/simko22a/simko22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-simko22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Attila
    family: Simkó
  - given: Tommy
    family: Löfstedt
  - given: Anders
    family: Garpebring
  - given: Tufve
    family: Nyholm
  - given: Joakim
    family: Jonsson
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1125-1138
  id: simko22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1125
  lastpage: 1138
  published: 2022-12-04 00:00:00 +0000
- title: 'Speckle and Shadows: Ultrasound-specific Physics-based Data Augmentation for Kidney Segmentation'
  abstract: 'Techniques for data augmentation are widely employed to avoid overfitting, improve generalizability and overcome data scarcity. This data-oriented approach frequently uses domain-agnostic approaches such as geometric transformations, colour space transformations, and generative adversarial networks. However, utilsing domain-specific characteristics in augmentations may result in additional invariances or improved robustness. We present several augmentation techniques for ultrasound: zoom, time-gain compensation, artificial shadowing, and speckle parameter maps. Zoom and time-gain compensation mimic traditional image quality parameters. For shadowing, we characterize acoustic shadows within abdominal ultrasound images and provide a method for incorporating artificial shadows into existing images. Finally, we transform B-mode ultrasound images into Nakagami-based speckle parameter maps to describe spatial structures that are not visible in conventional B-mode. The augmentations are evaluated by training a fully supervised network and a contrastive learning network for multi-class intra-organ semantic segmentation. Our preliminary results reflect the difficulties of creating augmentations as well as the limitations posed by acoustic shadowing.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/singla22a.html
  PDF: https://proceedings.mlr.press/v172/singla22a/singla22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-singla22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Rohit
    family: Singla
  - given: Cailin
    family: Ringstrom
  - given: Ricky
    family: Hu
  - given: Victoria
    family: Lessoway
  - given: Janice
    family: Reid
  - given: Robert
    family: Rohling
  - given: Christophe
    family: Nguan
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1139-1148
  id: singla22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1139
  lastpage: 1148
  published: 2022-12-04 00:00:00 +0000
- title: 'Automatic Segmentation of Head and Neck Tumor: How Powerful Transformers Are?'
  abstract: 'Cancer is one of the leading causes of death worldwide, and head and neck (H&N) cancer is amongst the most prevalent types. Positron emission tomography and computed tomography are used to detect, segment and quantify the tumor region. Clinically, tumor segmentation is extensively time-consuming and prone to error. Machine learning, and deep learning in particular, can assist to automate this process, yielding results as accurate as the results of a clinician. In this paper, we investigate a vision transformer-based method to automatically delineate H&N tumor, and compare its results to leading convolutional neural network (CNN)-based models. We use multi-modal data from CT and PET scans to perform the segmentation task. We show that a solution with a transformer-based model has the potential to achieve comparable results to CNN-based ones. With cross validation, the model achieves a mean dice similarity coefficient (DSC) of 0.736, mean precision of 0.766 and mean recall of 0.766. This is only 0.021 less than the 2020 competition winning model (cross validated in-house) in terms of the DSC score. On the testing set, the model performs similarly, with DSC of 0.736, precision of 0.773, and recall of 0.760, which is only 0.023 lower in DSC than the 2020 competition winning model. This work shows that cancer segmentation via transformer-based models is a promising research area to further explore.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/sobirov22a.html
  PDF: https://proceedings.mlr.press/v172/sobirov22a/sobirov22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-sobirov22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Ikboljon
    family: Sobirov
  - given: Otabek
    family: Nazarov
  - given: Hussain
    family: Alasmawi
  - given: Mohammad
    family: Yaqub
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1149-1161
  id: sobirov22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1149
  lastpage: 1161
  published: 2022-12-04 00:00:00 +0000
- title: 'MAF-Net: Multi-branch Anchor-Free Detector for Polyp Localization and Classification in Colonoscopy'
  abstract: 'Colorectal polyps are abnormal tissues growing on the intima of the colon or rectum with a high risk of developing into colorectal cancer, the third leading cause of cancer death worldwide. The most common types of colorectal polyps include inflammatory, hyperplastic, and adenomatous polyps. Adenomatous polyps are the most dangerous type of polyp with the potential to become cancerous. Therefore, the prevention of colorectal cancer heavily depends on the identification and removal of adenomatous polyps. In this paper, we propose a novel framework to assist physicians to localize, identify, and remove adenomatous polyps in colonoscopy. The framework consists of an anchor-free polyp detection branch for detecting and localizing polyps and a classification branch for global feature extraction and pathology prediction. Furthermore, we propose a foreground attention module to generate local features from the foreground subnet in the detection branch, which are combined with the global feature in the classification branch to enhance the pathology prediction performance. We collect a dataset that contains 6,059 images with 6,827 object-level annotations. This dataset is the first large-scale polyp pathology dataset with both object segmentation annotations and pathology labels. Experiment results show that our proposed framework outperforms traditional CNN-based classifiers on polyp pathology classification and anchor-based detectors on polyp detection and localization.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/sun22a.html
  PDF: https://proceedings.mlr.press/v172/sun22a/sun22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-sun22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Xinzi
    family: Sun
  - given: Dechun
    family: Wang
  - given: Qilei
    family: Chen
  - given: Jing
    family: Ni
  - given: Shuijiao
    family: Chen
  - given: Xiaowei
    family: Liu
  - given: Yu
    family: Cao
  - given: Benyuan
    family: Liu
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1162-1172
  id: sun22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1162
  lastpage: 1172
  published: 2022-12-04 00:00:00 +0000
- title: 'Signal Domain Learning Approach for Optoacoustic Image Reconstruction from Limited View Data'
  abstract: 'Multi-spectral optoacoustic tomography (MSOT) relies on optical excitation of tissues with subsequent detection of the generated ultrasound waves.Optimal image quality in MSOT is achieved by detection of signals from a broad tomographic view.However, due to physical constraints and other cost-related considerations, most imaging systems are implemented with probes having limited tomographic coverage around the imaged object, such as linear array transducers often employed for clinical ultrasound (US) imaging.MSOT image reconstruction from limited-view data results in arc-shaped image artifacts and disrupted shape of the vascular structures. Deep learning methods have previously been used to recover MSOT images from incomplete tomographic data, albeit poor performance was attained when training with data from simulations or other imaging modalities.We propose a two-step method consisting of i) style transfer for domain adaptation between simulated and experimental MSOT signals, and ii) supervised training on simulated data to recover missing tomographic signals in realistic clinical data. The method is shown capable of correcting images reconstructed from sub-optimal probe geometries using only signal domain data without the need for training with ground truth (GT) full-view images.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/susmelj22a.html
  PDF: https://proceedings.mlr.press/v172/susmelj22a/susmelj22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-susmelj22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Anna Klimovskaia
    family: Susmelj
  - given: Berkan
    family: Lafci
  - given: Firat
    family: Ozdemir
  - given: Neda
    family: Davoudi
  - given: Xose Luis
    family: Dean-Ben
  - given: Fernando
    family: Perez-Cruz
  - given: Daniel
    family: Razansky
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1173-1191
  id: susmelj22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1173
  lastpage: 1191
  published: 2022-12-04 00:00:00 +0000
- title: 'OptTTA: Learnable Test-Time Augmentation for Source-Free Medical Image Segmentation Under Domain Shift'
  abstract: 'As distribution shifts are inescapable in realistic clinical scenarios due to inconsistencies in imaging protocols, scanner vendors, and across different centers, well-trained deep models incur a domain generalization problem in unseen environments. Despite a myriad of model generalization techniques to circumvent this issue, their broad applicability is impeded as (i) source training data may not be accessible after deployment due to privacy regulations, (ii) the availability of adequate test domain samples is often impractical, and (iii) such model generalization methods are not well-calibrated, often making unreliable overconfident predictions. This paper proposes a novel learnable test-time augmentation, namely OptTTA, tailored specifically to alleviate large domain shifts for the source-free medical image segmentation task. OptTTA enables efficiently generating augmented views of test input, resembling the style of private source images and bridging a domain gap between training and test data. Our proposed method explores optimal learnable test-time augmentation sub-policies that provide lower predictive entropy and match the feature statistics stored in the BatchNorm layers of the pretrained source model without requiring access to training source samples. Thorough evaluation and ablation studies on challenging multi-center and multi-vendor MRI datasets of three anatomies have demonstrated the performance superiority of OptTTA over prior-arts test-time augmentation and model adaptation methods. Additionally, the generalization capabilities and effectiveness of OptTTA are evaluated in terms of aleatoric uncertainty and model calibration analyses. Our PyTorch code implementation is publicly available at https://github.com/devavratTomar/OptTTA.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/tomar22a.html
  PDF: https://proceedings.mlr.press/v172/tomar22a/tomar22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-tomar22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Devavrat
    family: Tomar
  - given: Guillaume
    family: Vray
  - given: Jean-Philippe
    family: Thiran
  - given: Behzad
    family: Bozorgtabar
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1192-1217
  id: tomar22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1192
  lastpage: 1217
  published: 2022-12-04 00:00:00 +0000
- title: 'Efficient tool segmentation for endoscopic videos in the wild'
  abstract: 'In recent years, deep learning methods have become the most effective approach for tool segmentation in endoscopic images, achieving the state of the art on the available public benchmarks. However, these methods present some challenges that hinder their direct deployment in real world scenarios. This work explores how to solve two of the most common challenges: real-time and memory restrictions and false positives in frames with no tools. To cope with the first case, we show how to adapt an efficient general purpose semantic segmentation model. Then, we study how to cope with the common issue of only training on images with at least one tool. Then, when images of endoscopic procedures without tools are processed, there are a lot of false positives. To solve this, we propose to add an extra classification head that performs binary frame classification, to identify frames with no tools present. Finally, we present a thorough comparison of this approach with current state of the art on different benchmarks, including real medical practice recordings, demonstrating similar accuracy with much lower computational requirements.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/tomasini22a.html
  PDF: https://proceedings.mlr.press/v172/tomasini22a/tomasini22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-tomasini22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Clara
    family: Tomasini
  - given: Iñigo
    family: Alonso
  - given: Luis
    family: Riazuelo
  - given: Ana C
    family: Murillo
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1218-1234
  id: tomasini22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1218
  lastpage: 1234
  published: 2022-12-04 00:00:00 +0000
- title: 'Inference of captions from histopathological patches'
  abstract: 'Computational histopathology has made significant strides in the past few years, slowly getting closer to clinical adoption. One area of benefit would be the automatic generation of diagnostic reports from H&E-stained whole slide images which would further increase the efficiency of the pathologists’ routine diagnostic workflows. In this study, we compiled a dataset (PatchGastricADC22) of histopathological captions of stomach adenocarcinoma endoscopic biopsy specimens, which we extracted from diagnostic reports and paired with patches extracted from the associated whole slide images. The dataset contains a variety of gastric adenocarcinoma subtypes. We trained a baseline attention-based model to predict the captions from features extracted from the patches and obtained promising results. We make the captioned dataset of 262K patches publicly available.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/tsuneki22a.html
  PDF: https://proceedings.mlr.press/v172/tsuneki22a/tsuneki22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-tsuneki22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Masayuki
    family: Tsuneki
  - given: Fahdi
    family: Kanavati
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1235-1250
  id: tsuneki22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1235
  lastpage: 1250
  published: 2022-12-04 00:00:00 +0000
- title: 'An Analysis of the Impact of Annotation Errors on the Accuracy of Deep Learning for Cell Segmentation'
  abstract: 'Recent studies have shown that there can be high inter- and intra-observer variability when creating annotations for biomedical image segmentation. To mitigate the effects of manual annotation variability when training machine learning algorithms, various methods have been developed. However, little work has been done on actually assessing the impact of annotation errors on machine learning-based segmentation. For the task of cell segmentation, our work aims to bridge this gap by providing a thorough analysis of three types of potential annotation errors. We tackle the limitation of previous studies that lack a golden standard ground truth by performing our analysis on two synthetically-generated data sets with perfect labels, while also validating our observations on manually-labeled data. Moreover, we discuss the influence of the annotation errors on the results of three different network architectures: UNet, SegNet, and MSD. We find that UNet shows the overall best robustness for all data sets on two categories of errors, especially when the severity of the error is low, while MSD generalizes well even when a large proportion of the cell labels is missing during training. Moreover, we observe that special care should be taken to avoid wrongly labeling large objects when the target cells have small footprints.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/vadineanu22a.html
  PDF: https://proceedings.mlr.press/v172/vadineanu22a/vadineanu22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-vadineanu22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Şerban
    family: Vădineanu
  - given: Daniël Maria
    family: Pelt
  - given: Oleh
    family: Dzyubachyk
  - given: Kees Joost
    family: Batenburg
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1251-1267
  id: vadineanu22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1251
  lastpage: 1267
  published: 2022-12-04 00:00:00 +0000
- title: 'SynthMap: a generative model for synthesis of 3D datasets for quantitative MRI parameter mapping of myelin water fraction'
  abstract: 'We present a generative model for synthesis of large scale 3D datasets for quantitative MRI parameter mapping of myelin water fraction (MWF). Training robust neural networks for estimation of quantitative MRI parameters requires large amounts of data. Conventional approaches to tackling data scarcity use spatial augmentations, which may not capture a broad range of possible variations when only a very small initial dataset is available. Furthermore, conventional non linear least squares (NNLS) based methods for MWF estimation are highly sensitive to noise, which means that high quality ground truth MWF parameters are not available for supervised training. Instead of using the noisy NNLS based estimates of MWF parameters from limited real data, we propose to leverage the biophysical model that describes how the MRI signals arise from the underlying tissue parameters to synthetically generate a wide variety of high quality data of the corresponding signals and corresponding parameters for training any CNN based architecture. Our model samples parameter values from a range of naturally occurring prior values for each tissue type. To capture spatial variation, the generative signal decay model is combined with a generative spatial model conditioned on generic tissue segmentations. We demonstrate that our synthetically trained neural network provides superior accuracy over conventional NNLS based methods under the constraints of naturally occuring noise as well as on synthetic low SNR images. Our source code is available at: https://github.com/sergeicu/synthmap.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/vasylechko-didenko22a.html
  PDF: https://proceedings.mlr.press/v172/vasylechko-didenko22a/vasylechko-didenko22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-vasylechko-didenko22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Serge
    family: Vasylechko Didenko
  - given: Simon
    family: Warfield
  - given: Sila
    family: Kurugol
  - given: Onur
    family: Afacan
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1268-1284
  id: vasylechko-didenko22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1268
  lastpage: 1284
  published: 2022-12-04 00:00:00 +0000
- title: 'Cell Anomaly Localisation using Structured Uncertainty Prediction Networks'
  abstract: 'This paper proposes an unsupervised approach to anomaly detection in bright-field or fluorescence cell microscopy, where our goal is to localise malaria parasites. This is achieved by building a generative model (a variational autoencoder) that describes healthy cell images, where we additionally model the structure of the predicted image uncertainty, rather than assuming pixelwise independence in the likelihood function. This provides a whitened residual representation, where the anticipated structured mistakes by the generative model are reduced, but distinctive structures that did not occur in the training distribution, e.g. parasites are highlighted. We employ the recently published Structured Uncertainty Prediction Networks approach to enable tractable learning of the uncertainty structure. Here, the residual covariance matrix is efficiently approximated using a sparse Cholesky parameterisation. We demonstrate that our proposed approach is more effective for detecting real and synthetic structured image perturbations compared to diagonal Gaussian likelihoods.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/vodenicharski22a.html
  PDF: https://proceedings.mlr.press/v172/vodenicharski22a/vodenicharski22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-vodenicharski22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Boyko
    family: Vodenicharski
  - given: Samuel
    family: McDermott
  - given: Katherine M.
    family: Webber
  - given: Viola
    family: Introini
  - given: Pietro
    family: Cicuta
  - given: Richard
    family: Bowman
  - given: Ivor J. A.
    family: Simpson
  - given: Neill D. F.
    family: Campbell
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1285-1300
  id: vodenicharski22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1285
  lastpage: 1300
  published: 2022-12-04 00:00:00 +0000
- title: 'MedSelect: Selective Labeling for Medical Image Classification Using Meta-Learning'
  abstract: 'We propose a selective labeling method using meta-learning for medical image interpretation in the setting of limited labeling resources. Our method, MedSelect, consists of a trainable deep learning model that uses image embeddings  to select   images to label, and a non-parametric classifier that uses cosine similarity to classify unseen images. We demonstrate that MedSelect learns an effective selection strategy outperforming baseline selection strategies across seen and unseen medical conditions for chest X-ray interpretation. We also perform an analysis of the selections performed by MedSelect comparing the distribution of latent embeddings and clinical features, and find significant differences compared to the strongest performing baseline. Our method is broadly applicable across medical imaging tasks where labels are expensive to acquire.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/vrabac22a.html
  PDF: https://proceedings.mlr.press/v172/vrabac22a/vrabac22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-vrabac22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Damir
    family: Vrabac
  - given: Akshay
    family: Smit
  - given: Yujie
    family: He
  - given: Andrew Y.
    family: Ng
  - given: Andrew L.
    family: Beam
  - given: Pranav
    family: Rajpurkar
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1301-1310
  id: vrabac22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1301
  lastpage: 1310
  published: 2022-12-04 00:00:00 +0000
- title: 'EfficientCellSeg: Efficient Volumetric Cell Segmentation Using Context Aware Pseudocoloring'
  abstract: 'Volumetric cell segmentation in fluorescence microscopy images is important to study a wide variety of cellular processes. Applications range from the analysis of cancer cells to behavioral studies of cells in the embryonic stage. Like in other computer vision fields, most recent methods use either large convolutional neural networks (CNNs) or vision transformer models (ViTs). Since the number of available 3D microscopy images is typically limited in applications, we take a different approach and introduce a small CNN for volumetric cell segmentation. Compared to previous CNN models for cell segmentation, our model is efficient and has an asymmetric encoder-decoder structure with very few parameters in the decoder. Training efficiency is further improved via transfer learning. In addition, we introduce Context Aware Pseudocoloring to exploit spatial context in z-direction of 3D images while performing volumetric cell segmentation slice-wise. We evaluated our method using different 3D datasets from the Cell Segmentation Benchmark of the Cell Tracking Challenge. Our segmentation method achieves top-ranking results, while our CNN model has an up to 25x lower number of parameters than other top-ranking methods. Code and pretrained models are available at: https://github.com/roydenwa/efficient-cell-seg.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/wagner22a.html
  PDF: https://proceedings.mlr.press/v172/wagner22a/wagner22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-wagner22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Royden
    family: Wagner
  - given: Karl
    family: Rohr
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1311-1321
  id: wagner22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1311
  lastpage: 1321
  published: 2022-12-04 00:00:00 +0000
- title: 'Memory-efficient Segmentation of High-resolution Volumetric MicroCT Images'
  abstract: 'In recent years, 3D convolutional neural networks have become the dominant approach for volumetric medical image segmentation. However, compared to their 2D counterparts, 3D networks introduce substantially more training parameters and higher requirement for the GPU memory. This has become a major limiting factor for designing and training 3D networks for high-resolution volumetric images. In this work, we propose a novel memory-efficient network architecture for 3D high-resolution image segmentation. The network incorporates both global and local features via a two-stage U-net-based cascaded framework and at the first stage, a memory-efficient U-net (meU-net) is developed. The features learnt at the two stages are connected via post-concatenation, which further improves the information flow. The proposed segmentation method is evaluated on an ultra high-resolution microCT dataset with typically 250 million voxels per volume. Experiments show that it outperforms state-of-the-art 3D segmentation methods in terms of both segmentation accuracy and memory efficiency.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/wang22a.html
  PDF: https://proceedings.mlr.press/v172/wang22a/wang22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-wang22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Yuan
    family: Wang
  - given: Laura
    family: Blackie
  - given: Irene
    family: Miguel-Aliaga
  - given: Wenjia
    family: Bai
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1322-1335
  id: wang22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1322
  lastpage: 1335
  published: 2022-12-04 00:00:00 +0000
- title: 'Diffusion Models for Implicit Image Segmentation Ensembles'
  abstract: 'Diffusion models have shown impressive performance for generative modelling of images. In this paper, we present a novel semantic segmentation method based on diffusion models. By modifying the training and sampling scheme, we show that diffusion models can perform lesion segmentation of medical images. To generate an image-specific segmentation, we train the model on the ground truth segmentation, and use the image as a prior during training and in every step during the sampling process. With the given stochastic sampling process, we can generate a distribution of segmentation masks. This property allows us to compute pixel-wise uncertainty maps of the segmentation, and allows an implicit ensemble of segmentations that increases the segmentation performance. We evaluate our method on the BRATS2020 dataset for brain tumor segmentation. Compared to state-of-the-art segmentation models, our approach yields good segmentation results and, additionally, detailed uncertainty maps.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/wolleb22a.html
  PDF: https://proceedings.mlr.press/v172/wolleb22a/wolleb22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-wolleb22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Julia
    family: Wolleb
  - given: Robin
    family: Sandkühler
  - given: Florentin
    family: Bieder
  - given: Philippe
    family: Valmaggia
  - given: Philippe C.
    family: Cattin
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1336-1348
  id: wolleb22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1336
  lastpage: 1348
  published: 2022-12-04 00:00:00 +0000
- title: 'Implicit Neural Representations for Deformable Image Registration'
  abstract: 'Deformable medical image registration has in past years been revolutionized by the use of convolutional neural networks. These methods surpass conventional image registration techniques in speed but not in accuracy. Here, we present an alternative approach to leveraging neural networks for image registration. Instead of using a convolutional neural network to predict the transformation between images, we optimize a multi-layer perceptron to represent this transformation function. Using recent insights from differentiable rendering, we show how such an implicit deformable image registration (IDIR) model can be naturally combined with regularization terms based on standard automatic differentiation techniques. We demonstrate the effectiveness of this model on 4D chest CT registration in the DIR-LAB data set and find that a three-layer multi-layer perceptron with periodic activation functions outperforms all published deep learning-based results on this problem, without any folding and without the need for training data. The model is implemented using standard deep learning libraries and flexible enough to be extended to include different losses, regularizers, and optimization schemes.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/wolterink22a.html
  PDF: https://proceedings.mlr.press/v172/wolterink22a/wolterink22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-wolterink22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Jelmer M
    family: Wolterink
  - given: Jesse C
    family: Zwienenberg
  - given: Christoph
    family: Brune
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1349-1359
  id: wolterink22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1349
  lastpage: 1359
  published: 2022-12-04 00:00:00 +0000
- title: 'Anomaly-Aware 3D Segmentation of Knee Magnetic Resonance Images'
  abstract: 'In medical imaging, anatomical structures under examination often contain anomalies or pathologies making automated segmentation challenging in these situations. Hence, the robust segmentation of anatomical structures in the presence of anomalies represents an important step within the medical image analysis field. In this work, we show how popular U-Net-based neural networks can be used for detecting anomalies in the knee from 3D magnetic resonance (MR) images in patients with varying grades of osteoarthritis (OA). We also show that the extracted information can be utilized for downstream tasks such as parallel segmentation of anatomical structures along with associated anomalies such as bone marrow lesions (BMLs). For anomaly detection, a U-Net-based model was adopted to inpaint the region of interest in images so that the anomalous regions can be replaced with close to normal appearances. The difference between the original image and the inpainted image was then used to highlight the anomalies. The extracted information was then used to improve the segmentation of bones and cartilages; in particular, the anomaly-aware segmentation mechanism provided a significant reduction in surface distance error in the segmentation of knee MR images containing severe anomalies within the distal femur.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/woo22a.html
  PDF: https://proceedings.mlr.press/v172/woo22a/woo22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-woo22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Boyeong
    family: Woo
  - given: Craig
    family: Engstrom
  - given: Jurgen
    family: Fripp
  - given: Stuart
    family: Crozier
  - given: Shekhar S.
    family: Chandra
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1360-1374
  id: woo22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1360
  lastpage: 1374
  published: 2022-12-04 00:00:00 +0000
- title: 'Towards IID representation learning and its application on biomedical data'
  abstract: 'Due to the heterogeneity of real-world data, the widely accepted independent and identically distributed (IID) assumption has been criticized in recent studies on causality. In this paper, we argue that instead of being a questionable assumption, IID is a fundamental task-relevant property that needs to be learned. Consider $k$ independent random vectors $\mathsf{X}^{i = 1, \ldots, k}$, we elaborate on how a variety of different causal questions can be reformulated to learning a task-relevant function $\phi$ that induces IID among $\mathsf{Z}^i :=  \phi \circ \mathsf{X}^i$, which we term IID representation learning. For proof of concept, we examine the IID representation learning on Out-of-Distribution (OOD) generalization tasks. Concretely, by utilizing the representation obtained via the learned function that induces IID, we conduct prediction of molecular characteristics (molecular prediction) on two biomedical datasets with real-world distribution shifts introduced by a) preanalytical variation and b) sampling protocol.  To enable reproducibility and for comparison to the state-of-the-art (SOTA) methods, this is done by following the OOD benchmarking guidelines recommended from WILDS. Compared to the SOTA baselines supported in WILDS, the results confirm the superior performance of IID representation learning on OOD tasks. The code is publicly accessible via https://github.com/CTPLab/IID_representation_learning.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/wu22a.html
  PDF: https://proceedings.mlr.press/v172/wu22a/wu22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-wu22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Jiqing
    family: Wu
  - given: Inti
    family: Zlobec
  - given: Maxime
    family: Lafarge
  - given: Yukun
    family: He
  - given: Viktor
    family: Koelzer
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1375-1402
  id: wu22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1375
  lastpage: 1402
  published: 2022-12-04 00:00:00 +0000
- title: 'Learned Half-Quadratic Splitting Network for MR Image Reconstruction'
  abstract: 'Magnetic Resonance (MR) image reconstruction from highly undersampled $k$-space data is critical in accelerated MR imaging (MRI) techniques. In recent years, deep learning-based methods have shown great potential in this task. This paper proposes a learned half-quadratic splitting algorithm for MR image reconstruction and implements the algorithm in an unrolled deep learning network architecture. We compare the performance of our proposed method on a public cardiac MR dataset against  DC-CNN, ISTANet$^+$ and LPDNet, and our method outperforms other methods in both quantitative results and qualitative results. Finally, we enlarge our model to achieve superior reconstruction quality, and the improvement is $1.00$ dB and $1.76$ dB over LPDNet in peak signal-to-noise ratio on $5\times$ and $10\times$ acceleration, respectively. Code for our method is publicly available at \url{https://github.com/hellopipu/HQS-Net.}'
  volume: 172
  URL: https://proceedings.mlr.press/v172/xin22a.html
  PDF: https://proceedings.mlr.press/v172/xin22a/xin22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-xin22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Bingyu
    family: Xin
  - given: Timothy
    family: Phan
  - given: Leon
    family: Axel
  - given: Dimitris
    family: Metaxas
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1403-1412
  id: xin22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1403
  lastpage: 1412
  published: 2022-12-04 00:00:00 +0000
- title: 'Learning Morphological Feature Perturbations for Calibrated Semi-Supervised Segmentation'
  abstract: 'We propose MisMatch, a novel consistency-driven semi-supervised segmentation framework which produces predictions that are invariant to learnt feature perturbations. MisMatch consists of an encoder and a two-head decoders. One decoder learns positive attention to the foreground regions of interest (RoI) on unlabelled images thereby generating dilated features. The other decoder learns negative attention to the foreground on the same unlabelled images thereby generating eroded features. We then apply a consistency regularisation on the paired predictions. MisMatch outperforms state-of-the-art semi-supervised methods on a CT-based pulmonary vessel segmentation task and a MRI-based brain tumour segmentation task. In addition, we show that the effectiveness of MisMatch comes from better model calibration than its supervised learning counterpart.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/xu22a.html
  PDF: https://proceedings.mlr.press/v172/xu22a/xu22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-xu22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Mou-Cheng
    family: Xu
  - given: Yu-Kun
    family: Zhou
  - given: Chen
    family: Jin
  - given: Stefano B.
    family: Blumberg
  - given: Frederick J.
    family: Wilson
  - given: Marius
    family: deGroot
  - given: Daniel C.
    family: Alexander
  - given: Neil P.
    family: Oxtoby
  - given: Joseph
    family: Jacob
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1413-1429
  id: xu22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1413
  lastpage: 1429
  published: 2022-12-04 00:00:00 +0000
- title: 'Regularizing Brain Age Prediction via Gated Knowledge Distillation'
  abstract: 'The brain age has been proven a phenotype with relevance to cognitive performance and brain disease. With the development of deep learning, brain age estimation accuracy has been greatly improved. However, such methods may incur over-fitting and suffer from poor generalizations, especially for insufficient brain imaging data. This paper presents a novel regularization method that penalizes the predictive distribution using knowledge distillation and introduces additional knowledge to reinforce the learning process. During knowledge distillation, we propose a gated distillation mechanism to enable the student model to attentively learn key knowledge from the teacher model, given the assumption that the teacher may not always be correct. Moreover, to enhance the capability of knowledge transfer, the hint representation similarity is also adopted to regularize the model training. We evaluate the model by a cohort of 3655 subjects from 4 public datasets, demonstrating that the proposed method improves the prediction performance over several well-established models, where the mean absolute error of the estimated ages is 2.129 years.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/yang22a.html
  PDF: https://proceedings.mlr.press/v172/yang22a/yang22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-yang22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Yanwu
    family: Yang
  - given: Guo
    family: Xutao
  - given: Chenfei
    family: Ye
  - given: Yang
    family: Xiang
  - given: Ting
    family: Ma
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1430-1443
  id: yang22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1430
  lastpage: 1443
  published: 2022-12-04 00:00:00 +0000
- title: 'Unsupervised Domain Adaptation through Shape Modeling for Medical Image Segmentation'
  abstract: 'Shape information is a strong and valuable prior in segmenting organs in medical images. However, most current deep learning based segmentation algorithms have not taken shape information into consideration, which can lead to bias towards texture. We aim at modeling shape explicitly and using it to help medical image segmentation. Previous methods proposed Variational Autoencoder (VAE) based models to learn the distribution of shape for a particular organ and used it to automatically evaluate the quality of a segmentation prediction by fitting it into the learned shape distribution. Based on which we aim at incorporating VAE into current segmentation pipelines. Specifically, we propose a new unsupervised domain adaptation pipeline based on a pseudo loss and a VAE reconstruction loss under a teacher-student learning paradigm. Both losses are optimized simultaneously and, in return, boost the segmentation task performance. Extensive experiments on three public Pancreas segmentation datasets as well as two in-house Pancreas segmentation datasets show consistent improvements with at least 2.8 points gain in the Dice score, demonstrating the effectiveness of our method in challenging unsupervised domain adaptation scenarios for medical image segmentation. We hope this work will advance shape analysis and geometric learning in medical imaging.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/yao22a.html
  PDF: https://proceedings.mlr.press/v172/yao22a/yao22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-yao22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Yuan
    family: Yao
  - given: Fengze
    family: Liu
  - given: Zongwei
    family: Zhou
  - given: Yan
    family: Wang
  - given: Wei
    family: Shen
  - given: Alan
    family: Yuille
  - given: Yongyi
    family: Lu
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1444-1458
  id: yao22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1444
  lastpage: 1458
  published: 2022-12-04 00:00:00 +0000
- title: 'Hierarchical Optimal Transport for Comparing Histopathology Datasets'
  abstract: 'Scarcity of labeled histopathology data limits the applicability of deep learning methods to under-profiled cancer types and labels. Transfer learning allows researchers to overcome the limitations of small datasets by pre-training machine learning models on larger datasets \emph{similar} to the small target dataset. However, similarity between datasets is often determined heuristically. In this paper, we propose a principled notion of distance between histopathology datasets based on a hierarchical generalization of optimal transport distances. Our method does not require any training, is agnostic to model type, and preserves much of the hierarchical structure in histopathology datasets imposed by tiling. We apply our method to H&E stained slides from The Cancer Genome Atlas from six different cancer types. We show that our method outperforms a baseline distance in a cancer-type prediction task. Our results also show that our optimal transport distance predicts difficulty of transferability in a tumor vs. normal prediction setting.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/yeaton22a.html
  PDF: https://proceedings.mlr.press/v172/yeaton22a/yeaton22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-yeaton22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Anna
    family: Yeaton
  - given: Rahul G.
    family: Krishnan
  - given: Rebecca
    family: Mieloszyk
  - given: David
    family: Alvarez-Melis
  - given: Grace
    family: Huynh
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1459-1469
  id: yeaton22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1459
  lastpage: 1469
  published: 2022-12-04 00:00:00 +0000
- title: 'Left Ventricle Contouring in Cardiac Images Based on Deep Reinforcement Learning'
  abstract: 'Assessment of the left ventricle segmentation in cardiac magnetic resonance imaging (MRI) is of crucial importance for cardiac disease diagnosis. However, conventional manual segmentation is a tedious task that requires excessive human effort, which makes automated segmentation highly desirable in practice to facilitate the process of clinical diagnosis. In this paper, we propose a novel reinforcement-learning-based framework for left ventricle contouring, which mimics how a cardiologist outlines the left ventricle along a specific trajectory in a cardiac image. Following the algorithm of proximal policy optimization (PPO), we train a policy network, which makes a stochastic decision on the agent’s movement according to its local observation such that the generated trajectory matches the true contour of the left ventricle as much as possible. Moreover, we design a deep learning model with a customized loss function to generate the agent’s landing spot (or coordinate of its initial position on a cardiac image). The experiment results show that the coordinate of the generated landing spot is sufficiently close to the true contour and the proposed reinforcement-learning-based approach outperforms the existing U-net model and its improved version, even with limited training set.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/yin22a.html
  PDF: https://proceedings.mlr.press/v172/yin22a/yin22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-yin22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Sixing
    family: Yin
  - given: Yameng
    family: Han
  - given: Judong
    family: Pan
  - given: Yining
    family: Wang
  - given: Shufang
    family: Li
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1470-1481
  id: yin22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1470
  lastpage: 1481
  published: 2022-12-04 00:00:00 +0000
- title: 'KeyMorph: Robust Multi-modal Affine Registration via Unsupervised Keypoint Detection'
  abstract: 'Registration is a fundamental task in medical imaging, and recent machine learning methods have become the state-of-the-art. However, these approaches are often not interpretable, lack robustness to large misalignments, and do not incorporate symmetries of the problem. In this work, we propose KeyMorph, an unsupervised end-to-end learning-based image registration framework that relies on automatically detecting corresponding keypoints. Our core insight is straightforward: matching keypoints between images can be used to obtain the optimal transformation via a differentiable closed-form expression. We use this observation to drive the unsupervised learning of anatomically-consistent keypoints from images. This not only leads to substantially more robust registration but also yields better interpretability, since the keypoints reveal which parts of the image are driving the final alignment. Moreover, KeyMorph can be designed to be equivariant under image translations and symmetric with respect to the input image ordering. We demonstrate the proposed framework in solving 3D affine registration of multi-modal brain MRI scans. Remarkably, we show that this strategy leads to consistent keypoints, even across modalities. We demonstrate registration accuracy that surpasses current state-of-the-art methods, especially in the context of large displacements.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/yu22a.html
  PDF: https://proceedings.mlr.press/v172/yu22a/yu22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-yu22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Evan M
    family: Yu
  - given: Alan Q
    family: Wang
  - given: Adrian V
    family: Dalca
  - given: Mert R
    family: Sabuncu
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1482-1503
  id: yu22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1482
  lastpage: 1503
  published: 2022-12-04 00:00:00 +0000
- title: 'Interpretable Prediction of Lung Squamous Cell Carcinoma Recurrence With Self-supervised Learning'
  abstract: 'Lung squamous cell carcinoma (LSCC) has a high recurrence and metastasis rate. Factors influencing recurrence and metastasis are currently unknown and there are no distinct histopathological or morphological features indicating the risks of recurrence and metastasis in LSCC. Our study focuses on the recurrence prediction of LSCC based on H&E-stained histopathological whole-slide images (WSI). Due to the small size of LSCC cohorts in terms of patients with available recurrence information, standard end-to-end learning with various convolutional neural networks for this task tends to overfit. Also, the predictions made by these models are hard to interpret. Histopathology WSIs are typically very large and are therefore processed as a set of smaller tiles. In this work, we propose a novel conditional self-supervised learning (SSL) method to learn representations of WSI at the tile level first, and leverage clustering algorithms to identify the tiles with similar histopathological representations. The resulting representations and clusters from self-supervision are used as features of a survival model for recurrence prediction at the patient level. Using two publicly available datasets from TCGA and CPTAC, we show that our LSCC recurrence prediction survival model outperforms both LSCC pathological stage-based approach and machine learning baselines such as multiple instance learning. The proposed method also enables us to explain the recurrence histopathological risk factors via the derived clusters. This can help pathologists derive new hypotheses regarding morphological features associated with LSCC recurrence.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/zhu22a.html
  PDF: https://proceedings.mlr.press/v172/zhu22a/zhu22a.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-zhu22a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Weicheng
    family: Zhu
  - given: Carlos
    family: Fernandez-Granda
  - given: Narges
    family: Razavian
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1504-1522
  id: zhu22a
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1504
  lastpage: 1522
  published: 2022-12-04 00:00:00 +0000
- title: 'Region Aware Transformer for Automatic Breast Ultrasound Tumor Segmentation'
  abstract: 'Although Automatic Breast Ultrasound (ABUS) has become an important tool to detect breast cancer, computer-aided diagnosis requires accurate segmentation of tumors on ABUS. In this paper, we propose the Region Aware Transformer Network (RAT-Net) for tumor segmentation on ABUS images. RAT-Net incorporates region prior information of tumors into network design. The specially designed Region Aware Self-Attention Block (RASAB) and Region Aware Transformer Block (RATB) fuse the tumor region information into multi-scale features to obtain accurate segmentation. To the best of our knowledge, it is the first time that tumor region distributions are incorporated into network architectures for ABUS image segmentation. Experimental results on a dataset of 256 subjects (330 ABUS images each) show that RAT-Net outperforms other state-of-the-art methods.'
  volume: 172
  URL: https://proceedings.mlr.press/v172/zhu22b.html
  PDF: https://proceedings.mlr.press/v172/zhu22b/zhu22b.pdf
  edit: https://github.com/mlresearch//v172/edit/gh-pages/_posts/2022-12-04-zhu22b.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 5th International Conference on Medical Imaging with Deep Learning'
  publisher: 'PMLR'
  author: 
  - given: Xiner
    family: Zhu
  - given: Haoji
    family: Hu
  - given: Hualiang
    family: Wang
  - given: Jincao
    family: Yao
  - given: Wei
    family: Li
  - given: Di
    family: Ou
  - given: Dong
    family: Xu
  editor: 
  - given: Ender
    family: Konukoglu
  - given: Bjoern
    family: Menze
  - given: Archana
    family: Venkataraman
  - given: Christian
    family: Baumgartner
  - given: Qi
    family: Dou
  - given: Shadi
    family: Albarqouni
  page: 1523-1537
  id: zhu22b
  issued:
    date-parts: 
      - 2022
      - 12
      - 4
  firstpage: 1523
  lastpage: 1537
  published: 2022-12-04 00:00:00 +0000
