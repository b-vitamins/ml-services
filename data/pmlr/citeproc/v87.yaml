
- title: 'Driving Policy Transfer via Modularity and Abstraction'
  abstract: 'End-to-end approaches to autonomous driving have high sample complexity and are difficult to scale to realistic urban driving. Simulation can help end-to-end driving systems by providing a cheap, safe, and diverse training environment. Yet training driving policies in simulation brings up the problem of transferring such policies to the real world. We present an approach to transferring driving policies from simulation to reality via modularity and abstraction. Our approach is inspired by classic driving systems and aims to combine the benefits of modular architectures and end-to-end deep learning approaches. The key idea is to encapsulate the driving policy such that it is not directly exposed to raw perceptual input or low-level vehicle dynamics. We evaluate the presented approach in simulated urban environments and in the real world. In particular, we transfer a driving policy trained in simulation to a 1/5-scale robotic truck that is deployed in a variety of conditions, with no finetuning, on two continents.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/mueller18a.html
  PDF: http://proceedings.mlr.press/v87/mueller18a/mueller18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-mueller18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Matthias
    family: Mueller
  - given: Alexey
    family: Dosovitskiy
  - given: Bernard
    family: Ghanem
  - given: Vladlen
    family: Koltun
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 1-15
  id: mueller18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 1
  lastpage: 15
  published: 2018-10-23 00:00:00 +0000
- title: 'Personalized Dynamics Models for Adaptive Assistive Navigation Systems'
  abstract: 'Consider an assistive system that guides visually impaired users through speech and haptic feedback to their destination. Existing robotic and ubiquitous navigation technologies (e.g., portable, ground, or wearable systems) often operate in a generic, user-agnostic manner. However, to minimize confusion and navigation errors, our real-world analysis reveals a crucial need to adapt theinstructional guidance across different end-users with diverse mobility skills. To address this practical issue in scalable system design, we propose a novel model based reinforcement learning framework for personalizing the system-user interaction experience. When incrementally adapting the system to new users, we propose to use a weighted experts model for addressing data-efficiency limitations in transfer learning with deep models. A real-world dataset of navigation by blind users is used to show that the proposed approach allows for (1) more accurate long-term human behavior prediction (up to 20 seconds into the future) through improved reasoning over personal mobility characteristics, interaction with surrounding obstacles, and the current navigation goal, and (2) quick adaptation at the onset of learning, when data is limited.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/ohnbar18a.html
  PDF: http://proceedings.mlr.press/v87/ohnbar18a/ohnbar18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-ohnbar18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Eshed
    family: OhnBar
  - given: Kris
    family: Kitani
  - given: Chieko
    family: Asakawa
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 16-39
  id: ohnbar18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 16
  lastpage: 39
  published: 2018-10-23 00:00:00 +0000
- title: 'Few-Shot Goal Inference for Visuomotor Learning and Planning'
  abstract: 'Reinforcement learning and planning methods require an objective or reward function that encodes the desired behavior. Yet, in practice, there is a wide range of scenarios where an objective is difficult to provide programmatically, such as tasks with visual observations involving unknown object positions or deformable objects. In these cases, prior methods use engineered problem-specific solutions, e.g., by instrumenting the environment with additional sensors to measure a proxy for the objective. Such solutions require a significant engineering effort on a per-task basis, and make it impractical for robots to continuously learn complex skills outside of laboratory settings. We aim to find a more general and scalable solution for specifying goals for robot learning in unconstrained environments. To that end, we formulate the few-shot objective learning problem, where the goal is to learn a task objective from only a few example images of successful end states for that task. We propose a simple solution to this problem: meta-learn a classifier that can recognize new goals from a few examples. We show how this approach can be used with both model-free reinforcement learning and visual model-based planning and show results in three domains: rope manipulation from images in simulation, visual navigation in a simulated 3D environment, and object arrangement into user-specified configurations on a real robot.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/xie18a.html
  PDF: http://proceedings.mlr.press/v87/xie18a/xie18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-xie18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Annie
    family: Xie
  - given: Avi
    family: Singh
  - given: Sergey
    family: Levine
  - given: Chelsea
    family: Finn
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 40-52
  id: xie18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 40
  lastpage: 52
  published: 2018-10-23 00:00:00 +0000
- title: 'Neural Modular Control for Embodied Question Answering'
  abstract: 'We present a modular approach for learning policies for navigation over long planning horizons from language input. Our hierarchical policy operates at multiple timescales, where the higher-level master policy proposes subgoals to be executed by specialized sub-policies. Our choice of subgoals is compositional and semantic, i.e. they can be sequentially combined in arbitrary orderings, and assume human-interpretable descriptions (e.g. ‘exit room’, ‘find kitchen’, ‘find refrigerator’, etc.). We use imitation learning to warm-start policies at each level of the hierarchy, dramatically increasing sample efficiency, followed by reinforcement learning. Independent reinforcement learning at each level of hierarchy enables sub-policies to adapt to consequences of their actions and recover from errors. Subsequent joint hierarchical training enables the master policy to adapt to the sub-policies. On the challenging EQA [1] benchmark in House3D [2], requiring navigating diverse realistic indoor environments, our approach outperforms prior work by a significant margin, both in terms of navigation and question answering.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/das18a.html
  PDF: http://proceedings.mlr.press/v87/das18a/das18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-das18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Abhishek
    family: Das
  - given: Georgia
    family: Gkioxari
  - given: Stefan
    family: Lee
  - given: Devi
    family: Parikh
  - given: Dhruv
    family: Batra
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 53-62
  id: das18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 53
  lastpage: 62
  published: 2018-10-23 00:00:00 +0000
- title: 'Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition'
  abstract: 'In an open-world setting, it is inevitable that an intelligent agent (e.g., a robot) will encounter visual objects, attributes or relationships it does not recognize. In this work, we develop an agent empowered with visual curiosity, i.e. the ability to ask questions to an Oracle (e.g., human) about the contents in images (e.g., ‘What is the object on the left side of the red cube?’) and build visual recognition model based on the answers received (e.g., ‘Cylinder’). In order to do this, the agent must (1) understand what it recognizes and what it does not, (2) formulate a valid, unambiguous and informative ‘language’ query (a question) to ask the Oracle, (3) derive the parameters of visual classifiers from the Oracle response and (4) leverage the updated visual classifiers to ask more clarified questions. Specifically, we propose a novel framework and formulate the learning of visual curiosity as a reinforcement learning problem. In this framework, all components of our agent – visual recognition module (to see), question generation policy (to ask), answer digestion module (to understand) and graph memory module (to memorize) – are learned entirely end-to-end to maximize the reward derived from the scene graph obtained by the agent as a consequence of the dialog with the Oracle. Importantly, the question generation policy is disentangled from the visual recognition system and specifics of the ‘environment’ (scenes). Consequently, we demonstrate a sort of ‘double’ generalization – our question generation policy generalizes to new environments and a new pair of eyes, i.e., new visual system. Specifically, an agent trained on one set of environments (scenes) and with one particular visual recognition system is able to ask intelligent questions about new scenes when paired with a new visual recognition system. Trained on a synthetic dataset, our results show that our agent learns new visual concepts significantly faster than several heuristic baselines – even when tested on synthetic environments with novel objects, as well as in a realistic environment.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/yang18a.html
  PDF: http://proceedings.mlr.press/v87/yang18a/yang18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-yang18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Jianwei
    family: Yang
  - given: Jiasen
    family: Lu
  - given: Stefan
    family: Lee
  - given: Dhruv
    family: Batra
  - given: Devi
    family: Parikh
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 63-80
  id: yang18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 63
  lastpage: 80
  published: 2018-10-23 00:00:00 +0000
- title: 'Guided Feature Transformation (GFT): A Neural Language Grounding Module for Embodied Agents'
  abstract: 'Recently there has been a rising interest in training agents, embodied in virtual environments, to perform language-directed tasks by deep reinforcement learning. In this paper, we propose a simple but effective neural language grounding module for embodied agents that can be trained end to end from scratch taking raw pixels, unstructured linguistic commands, and sparse rewards as the inputs. We model the language grounding process as a language-guided transformation of visual features, where latent sentence embeddings are used as the transformation matrices. In several language-directed navigation tasks that feature challenging partial observability and require simple reasoning, our module significantly outperforms the state of the art. We also release XWORLD3D, an easy-to-customize 3D environment that can be modified to evaluate a variety of embodied agents.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/yu18a.html
  PDF: http://proceedings.mlr.press/v87/yu18a/yu18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-yu18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Haonan
    family: Yu
  - given: Xiaochen
    family: Lian
  - given: Haichao
    family: Zhang
  - given: Wei
    family: Xu
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 81-98
  id: yu18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 81
  lastpage: 98
  published: 2018-10-23 00:00:00 +0000
- title: 'Grasp2Vec: Learning Object Representations from Self-Supervised Grasping'
  abstract: 'Well structured visual representations can make robot learning faster and can improve generalization. In this paper, we study how we can acquire effective object-centric representations for robotic manipulation tasks without human labeling by using autonomous robot interaction with the environment. Such representation learning methods can benefit from continuous refinement of the representation as the robot collects more experience, allowing them to scale effectively without human intervention. Our representation learning approach is based on object persistence: when a robot removes an object from a scene, the representation of that scene should change according to the features of the object that was removed. We formulate an arithmetic relationship between feature vectors from this observation, and use it to learn a representation of scenes and objects that can then be used to identify object instances, localize them in the scene, and perform goal-directed grasping tasks where the robot must retrieve commanded objects from a bin. The same grasping procedure can also be used to automatically collect training data for our method, by recording images of scenes, grasping and removing an object, and recording the outcome. Our experiments demonstrate that this self-supervised approach for tasked grasping substantially outperforms direct reinforcement learning from images and prior representation learning methods. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/jang18a.html
  PDF: http://proceedings.mlr.press/v87/jang18a/jang18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-jang18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Eric
    family: Jang
  - given: Coline
    family: Devin
  - given: Vincent
    family: Vanhoucke
  - given: Sergey
    family: Levine
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 99-112
  id: jang18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 99
  lastpage: 112
  published: 2018-10-23 00:00:00 +0000
- title: 'Energy-Based Hindsight Experience Prioritization'
  abstract: 'In Hindsight Experience Replay (HER), a reinforcement learning agent is trained by treating whatever it has achieved as virtual goals. However, in pre- vious work, the experience was replayed at random, without considering which episode might be the most valuable for learning. In this paper, we develop an energy-based framework for prioritizing hindsight experience in robotic manipulation tasks. Our approach is inspired by the work-energy principle in physics. We define a trajectory energy function as the sum of the transition energy of the target object over the trajectory. We hypothesize that replaying episodes that have high trajectory energy is more effective for reinforcement learning in robotics. To verify our hypothesis, we designed a framework for hindsight experience prioritization based on the trajectory energy of goal states. The trajectory energy function takes the potential, kinetic, and rotational energy into consideration. We evaluate our Energy-Based Prioritization (EBP) approach on four challenging robotic manipulation tasks in simulation. Our empirical results show that our proposed method surpasses state-of-the-art approaches in terms of both performance and sample-efficiency on all four tasks, without increas- ing computational time. A video showing experimental results is available at https://youtu.be/jtsF2tTeUGQ. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/zhao18a.html
  PDF: http://proceedings.mlr.press/v87/zhao18a/zhao18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-zhao18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Rui
    family: Zhao
  - given: Volker
    family: Tresp
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 113-122
  id: zhao18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 113
  lastpage: 122
  published: 2018-10-23 00:00:00 +0000
- title: 'Including Uncertainty when Learning from Human Corrections'
  abstract: 'It is difficult for humans to efficiently teach robots how to correctly perform a task. One intuitive solution is for the robot to iteratively learn the human’s preferences from corrections, where the human improves the robot’s current behavior at each iteration. When learning from corrections, we argue that while the robot should estimate the most likely human preferences, it should also know what it does not know, and integrate this uncertainty as it makes decisions. We advance the state-of-the-art by introducing a Kalman filter for learning from corrections: this approach obtains the uncertainty of the estimated human preferences. Next, we demonstrate how the estimate uncertainty can be leveraged for active learning and risk-sensitive deployment. Our results indicate that obtaining and leveraging uncertainty leads to faster learning from human corrections. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/losey18a.html
  PDF: http://proceedings.mlr.press/v87/losey18a/losey18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-losey18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Dylan P.
    family: Losey
  - given: Marcia K.
    family: O’Malley
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 123-132
  id: losey18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 123
  lastpage: 132
  published: 2018-10-23 00:00:00 +0000
- title: 'Deep Drone Racing: Learning Agile Flight in Dynamic Environments'
  abstract: 'Autonomous agile flight brings up fundamental challenges in robotics, such as coping with unreliable state estimation, reacting optimally to dynamically changing environments, and coupling perception and action in real time under severe resource constraints. In this paper, we consider these challenges in the context of autonomous, vision-based drone racing in dynamic environments. Our approach combines a convolutional neural network (CNN) with a state-of-the-art path-planning and control system. The CNN directly maps raw images into a robust representation in the form of a waypoint and desired speed. This information is then used by the planner to generate a short, minimum-jerk trajectory segment and corresponding motor commands to reach the desired goal. We demonstrate our method in autonomous agile flight scenarios, in which a vision-based quadrotor traverses drone-racing tracks with possibly moving gates. Our method does not require any explicit map of the environment and runs fully onboard. We extensively test the precision and robustness of the approach in simulation and in the physical world. We also evaluate our method against state-of-the-art navigation approaches and professional human drone pilots. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/kaufmann18a.html
  PDF: http://proceedings.mlr.press/v87/kaufmann18a/kaufmann18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-kaufmann18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Elia
    family: Kaufmann
  - given: Antonio
    family: Loquercio
  - given: Rene
    family: Ranftl
  - given: Alexey
    family: Dosovitskiy
  - given: Vladlen
    family: Koltun
  - given: Davide
    family: Scaramuzza
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 133-145
  id: kaufmann18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 133
  lastpage: 145
  published: 2018-10-23 00:00:00 +0000
- title: 'HDNET: Exploiting HD Maps for 3D Object Detection'
  abstract: 'In this paper we show that High-Definition (HD) maps provide strong priors that can boost the performance and robustness of modern 3D object detectors. Towards this goal, we design a single stage detector that extracts geometric and semantic features from the HD maps. As maps might not be available everywhere, we also propose a map prediction module that estimates the map on the fly from raw LiDAR data. We conduct extensive experiments on KITTI [1] as well as a large-scale 3D detection benchmark containing 1 million frames, and show that the proposed map-aware detector consistently outperforms the state-of-the-art in both mapped and un-mapped scenarios. Importantly the whole framework runs at 20 frames per second. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/yang18b.html
  PDF: http://proceedings.mlr.press/v87/yang18b/yang18b.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-yang18b.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Bin
    family: Yang
  - given: Ming
    family: Liang
  - given: Raquel
    family: Urtasun
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 146-155
  id: yang18b
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 146
  lastpage: 155
  published: 2018-10-23 00:00:00 +0000
- title: 'Motion Perception in Reinforcement Learning with Dynamic Objects'
  abstract: 'In dynamic environments, learned controllers are supposed to take motion into account when selecting the action to be taken. However, in existing reinforcement learning works motion is rarely treated explicitly; it is rather assumed that the controller learns the necessary motion representation from temporal stacks of frames implicitly. In this paper, we show that for continuous control tasks learning an explicit representation of motion clearly improves the quality of the learned controller in dynamic scenarios. We demonstrate this on common benchmark tasks (Walker, Swimmer, Hopper), on target reaching and ball catching tasks with simulated robotic arms, and on a dynamic single ball juggling task. Moreover, we find that when equipped with an appropriate network architecture, the agent can, on some tasks, learn motion features also with pure reinforcement learning, without additional supervision. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/amiranashvili18a.html
  PDF: http://proceedings.mlr.press/v87/amiranashvili18a/amiranashvili18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-amiranashvili18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Artemij
    family: Amiranashvili
  - given: Alexey
    family: Dosovitskiy
  - given: Vladlen
    family: Koltun
  - given: Thomas
    family: Brox
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 156-168
  id: amiranashvili18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 156
  lastpage: 168
  published: 2018-10-23 00:00:00 +0000
- title: 'Particle Filter Networks with Application to Visual Localization'
  abstract: 'Particle filtering is a powerful approach to sequential state estimation and finds application in many domains, including robot localization, object tracking, etc. To apply particle filtering in practice, a critical challenge is to construct probabilistic system models, especially for systems with complex dynamics or rich sensory inputs such as camera images. This paper introduces the Particle Filter Network (PFnet), which encodes both a system model and a particle filter algorithm in a single neural network. The PF-net is fully differentiable and trained end-to-end from data. Instead of learning a generic system model, it learns a model optimized for the particle filter algorithm. We apply the PF-net to a visual localization task, in which a robot must localize in a rich 3-D world, using only a schematic 2-D floor map. In simulation experiments, PF-net consistently outperforms alternative learning architectures, as well as a traditional model-based method, under a variety of sensor inputs. Further, PF-net generalizes well to new, unseen environments. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/karkus18a.html
  PDF: http://proceedings.mlr.press/v87/karkus18a/karkus18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-karkus18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Peter
    family: Karkus
  - given: David
    family: Hsu
  - given: Wee Sun
    family: Lee
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 169-178
  id: karkus18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 169
  lastpage: 178
  published: 2018-10-23 00:00:00 +0000
- title: 'Sparse Gaussian Process Temporal Difference Learning for Marine Robot Navigation'
  abstract: 'We present a method for Temporal Difference (TD) learning that addresses several challenges faced by robots learning to navigate in a marine environment. For improved data efficiency, our method reduces TD updates to Gaussian Process regression. To make predictions amenable to online settings, we introduce a sparse approximation with improved quality over current rejection-based methods. We derive the predictive value function posterior and use the moments to obtain a new algorithm for model-free policy evaluation, SPGP-SARSA. With simple changes, we show SPGP-SARSA can be reduced to a model-based equivalent, SPGP-TD. We perform comprehensive simulation studies and also conduct physical learning trials with an underwater robot. Our results show SPGP-SARSA can outperform the state-of-the-art sparse method, replicate the prediction quality of its exact counterpart, and be applied to solve underwater navigation tasks. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/martin18a.html
  PDF: http://proceedings.mlr.press/v87/martin18a/martin18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-martin18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: John
    family: Martin
  - given: Jinkun
    family: Wang
  - given: Brendan
    family: Englot
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 179-189
  id: martin18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 179
  lastpage: 189
  published: 2018-10-23 00:00:00 +0000
- title: 'Fast 3D Modeling with Approximated Convolutional Kernels'
  abstract: 'This paper introduces a novel regression methodology for 3D reconstruction, with applications in robotics tasks such as terrain modeling and implicit surface calculation. The proposed methodology is based on projections into a high-dimensional space, that is able to fit arbitrarily complex data as a continuous function using a series of kernel evaluations within a linear regression model. We avoid direct kernel calculation by employing a novel sparse random Fourier feature vector, that approximates any shift-invariant kernel as a series of dot products relative to a set of inducing points placed throughout the input space. The varying properties of these inducing points produce non-stationarity in the resulting model, and can be jointly learned alongside linear regression weights. Furthermore, we show how convolution with arbitrary kernels can be performed directly in this high-dimensional continuous space, by training a neural network to learn the Fourier transform of the convolutional output based on information from the input kernels. Experimental results in terrain modeling and implicit surface calculation show that the proposed framework is able to outperform similar techniques in terms of computational speed without sacrificing accuracy, while enabling efficient convolution with arbitrary kernels for tasks such as global localization and template matching within these applications. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/guizilini18a.html
  PDF: http://proceedings.mlr.press/v87/guizilini18a/guizilini18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-guizilini18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Vitor
    family: Guizilini
  - given: Fabio
    family: Ramos
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 190-199
  id: guizilini18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 190
  lastpage: 199
  published: 2018-10-23 00:00:00 +0000
- title: 'Unpaired Learning of Dense Visual Depth Estimators for Urban Environments'
  abstract: 'This paper addresses the classical problem of learning-based monocular depth estimation in urban environments, in which a model is trained to directly map a single input image to its corresponding depth values. All currently available techniques treat monocular depth estimation as a regression problem, and thus require some sort of data pairing, either explicitly as input-output ground-truth pairs, using information from range sensors (i.e. laser), or as binocular stereo footage. We introduce a novel methodology that completely eliminates the need for data pairing, only requiring two unrelated datasets containing samples of input images and output depth values. A cycle-consistent generative adversarial network is used to learn a mapping between these two domains, based on a custom adversarial loss function specifically designed to improve performance on the task of monocular depth estimation, including local depth smoothness and boundary equilibrium. A wide range of experiments were conducted using a variety of well-known indoor and outdoor datasets, with depth estimates obtained from laser sensors, RGBD cameras and SLAM pointclouds. In all of them, the proposed CycleDepth framework reaches competitive results even under a more restricted training scenario. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/guizilini18b.html
  PDF: http://proceedings.mlr.press/v87/guizilini18b/guizilini18b.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-guizilini18b.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Vitor
    family: Guizilini
  - given: Fabio
    family: Ramos
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 200-212
  id: guizilini18b
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 200
  lastpage: 212
  published: 2018-10-23 00:00:00 +0000
- title: 'Learning over Subgoals for Efficient Navigation of Structured, Unknown Environments'
  abstract: ' We propose a novel technique for efficiently navigating unknown environments over long horizons by learning to predict properties of unknown space. We generate a dynamic action set defined by the current map, factor the Bellman Equation in terms of these actions, and estimate terms, such as the probability that navigating beyond a particular subgoal will lead to a dead-end, that are otherwise difficult to compute. Simulated agents navigating with our Learned Subgoal Planner in real-world floor plans demonstrate a 21% expected decrease in cost-to-go compared to standard optimistic planning techniques that rely on Dijkstra’s algorithm, and real-world agents show promising navigation performance as well. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/stein18a.html
  PDF: http://proceedings.mlr.press/v87/stein18a/stein18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-stein18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Gregory J.
    family: Stein
  - given: Christopher
    family: Bradley
  - given: Nicholas
    family: Roy
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 213-222
  id: stein18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 213
  lastpage: 222
  published: 2018-10-23 00:00:00 +0000
- title: 'Inferring geometric constraints in human demonstrations'
  abstract: 'This paper presents an approach for inferring geometric constraints in human demonstrations. In our method, geometric constraint models are built to create representations of kinematic constraints such as fixed point, axial rotation, prismatic motion, planar motion and others across multiple degrees of freedom. Our method infers geometric constraints using both kinematic and force/torque information. The approach first fits all the constraint models using kinematic information and evaluates them individually using position, force and moment criteria. Our approach does not require information about the constraint type or contact geometry; it can determine both simultaneously. We present experimental evaluations using instrumented tongs that show how constraints can be robustly inferred in recordings of human demonstrations. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/subramani18a.html
  PDF: http://proceedings.mlr.press/v87/subramani18a/subramani18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-subramani18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Guru
    family: Subramani
  - given: Michael
    family: Zinn
  - given: Michael
    family: Gleicher
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 223-236
  id: subramani18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 223
  lastpage: 236
  published: 2018-10-23 00:00:00 +0000
- title: 'Conditional Affordance Learning for Driving in Urban Environments'
  abstract: 'Most existing approaches to autonomous driving fall into one of two categories: modular pipelines, that build an extensive model of the environment, and imitation learning approaches, that map images directly to control outputs. A recently proposed third paradigm, direct perception, aims to combine the advantages of both by using a neural network to learn appropriate low-dimensional intermediate representations. However, existing direct perception approaches are restricted to simple highway situations, lacking the ability to navigate intersections, stop at traffic lights or respect speed limits. In this work, we propose a direct perception approach which maps video input to intermediate representations suitable for autonomous navigation in complex urban environments given high-level directional inputs. Compared to state-of-the-art reinforcement and conditional imitation learning approaches, we achieve an improvement of up to 68 % in goal-directed navigation on the challenging CARLA simulation benchmark. In addition, our approach is the first to handle traffic lights and speed signs by using image-level labels only, as well as smooth car-following, resulting in a significant reduction of traffic accidents in simulation. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/sauer18a.html
  PDF: http://proceedings.mlr.press/v87/sauer18a/sauer18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-sauer18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Axel
    family: Sauer
  - given: Nikolay
    family: Savinov
  - given: Andreas
    family: Geiger
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 237-252
  id: sauer18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 237
  lastpage: 252
  published: 2018-10-23 00:00:00 +0000
- title: 'Modular Vehicle Control for Transferring Semantic Information Between Weather Conditions Using GANs'
  abstract: 'Even though end-to-end supervised learning has shown promising results for sensorimotor control of self-driving cars, its performance is greatly affected by the weather conditions under which it was trained, showing poor generalization to unseen conditions. In this paper, we show how knowledge can be transferred using semantic maps to new weather conditions without the need to obtain new ground truth data. To this end, we propose to divide the task of vehicle control into two independent modules: a control module which is only trained on one weather condition for which labeled steering data is available, and a perception module which is used as an interface between new weather conditions and the fixed control module. To generate the semantic data needed to train the perception module, we propose to use a generative adversarial network (GAN)-based model to retrieve the semantic information for the new conditions in an unsupervised manner. We introduce a master-servant architecture, where the master model (semantic labels available) trains the servant model (semantic labels not available). We show that our proposed method trained with ground truth data for a single weather condition is capable of achieving similar results on the task of steering angle prediction as an end-to-end model trained with ground truth data of 15 different weather conditions. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/wenzel18a.html
  PDF: http://proceedings.mlr.press/v87/wenzel18a/wenzel18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-wenzel18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Patrick
    family: Wenzel
  - given: Qadeer
    family: Khan
  - given: Daniel
    family: Cremers
  - given: Laura
    family: Leal-Taixe
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 253-269
  id: wenzel18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 253
  lastpage: 269
  published: 2018-10-23 00:00:00 +0000
- title: 'GPU-Accelerated Robotic Simulation for Distributed Reinforcement Learning'
  abstract: 'Most Deep Reinforcement Learning (Deep RL) algorithms require a prohibitively large number of training samples for learning complex tasks. Many recent works on speeding up Deep RL have focused on distributed training and simulation. While distributed training is often done on the GPU, simulation is not. In this work, we propose using GPU-accelerated RL simulations as an alternative to CPU ones. Using NVIDIA Flex, a GPU-based physics engine, we show promising speed-ups of learning various continuous-control, locomotion tasks. With one GPU and CPU core, we are able to train the Humanoid running task in less than 20 minutes, using 10-1000x fewer CPU cores than previous works. We also demonstrate the scalability of our simulator to multi-GPU settings to train more challenging locomotion tasks. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/liang18a.html
  PDF: http://proceedings.mlr.press/v87/liang18a/liang18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-liang18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Jacky
    family: Liang
  - given: Viktor
    family: Makoviychuk
  - given: Ankur
    family: Handa
  - given: Nuttapong
    family: Chentanez
  - given: Miles
    family: Macklin
  - given: Dieter
    family: Fox
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 270-282
  id: liang18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 270
  lastpage: 282
  published: 2018-10-23 00:00:00 +0000
- title: 'Feature Learning for Scene Flow Estimation from LIDAR'
  abstract: 'To perform tasks in dynamic environments, many mobile robots must estimate the motion in the surrounding world. Recently, techniques have been developed to estimate scene flow directly from LIDAR scans, relying on hand-designed features. In this work, we build an encoding network to learn features from an occupancy grid. The network is trained so that these features are discriminative in finding matching or non-matching locations between successive timesteps. This learned feature space is then leveraged to estimate scene flow. We evaluate our method on the KITTI dataset and demonstrate performance that improves upon the accuracy of the current state-of-the-art. We provide an implementation of our method at https://github.com/aushani/flsf. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/ushani18a.html
  PDF: http://proceedings.mlr.press/v87/ushani18a/ushani18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-ushani18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Arash K.
    family: Ushani
  - given: Ryan M.
    family: Eustice
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 283-292
  id: ushani18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 283
  lastpage: 292
  published: 2018-10-23 00:00:00 +0000
- title: 'PAC-Bayes Control: Synthesizing Controllers that Provably Generalize to Novel Environments'
  abstract: 'Our goal is to synthesize controllers for robots that provably generalize well to novel environments given a dataset of example environments. The key technical idea behind our approach is to leverage tools from generalization theory in machine learning by exploiting a precise analogy (which we present in the form of a reduction) between robustness of controllers to novel environments and generalization of hypotheses in supervised learning. In particular, we utilize the Probably Approximately Correct (PAC)-Bayes framework, which allows us to obtain upper bounds (that hold with high probability) on the expected cost of (stochastic) controllers across novel environments. We propose control synthesis algorithms that explicitly seek to minimize this upper bound. The corresponding optimization problem can be solved efficiently using convex optimization (Relative Entropy Programming in particular) in the setting where we are optimizing over a finite control policy space. In the more general setting of continuously parameterized controllers, we minimize this upper bound using stochastic gradient descent. We present examples of our approach in the context of obstacle avoidance control with depth measurements. Our simulated examples demonstrate the potential of our approach to provide strong generalization guarantees on controllers for robotic systems with continuous state and action spaces, nonlinear dynamics, and partially observable state via sensor measurements.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/majumdar18a.html
  PDF: http://proceedings.mlr.press/v87/majumdar18a/majumdar18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-majumdar18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Anirudha
    family: Majumdar
  - given: Maxwell
    family: Goldstein
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 293-305
  id: majumdar18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 293
  lastpage: 305
  published: 2018-10-23 00:00:00 +0000
- title: 'Deep Object Pose Estimation for Semantic Robotic Grasping of Household Objects'
  abstract: 'Using synthetic data for training deep neural networks for robotic manipulation holds the promise of an almost unlimited amount of pre-labeled training data, generated safely out of harm’s way. One of the key challenges of synthetic data, to date, has been to bridge the so-called reality gap, so that networks trained on synthetic data operate correctly when exposed to real-world data. We explore the reality gap in the context of 6-DoF pose estimation of known objects from a single RGB image. We show that for this problem the reality gap can be successfully spanned by a simple combination of domain randomized and photorealistic data. Using synthetic data generated in this manner, we introduce a one-shot deep neural network that is able to perform competitively against a state-of-the-art network trained on a combination of real and synthetic data. To our knowledge, this is the first deep network trained only on synthetic data that is able to achieve state-of-the-art performance on 6-DoF object pose estimation. Our network also generalizes better to novel environments including extreme lighting conditions, for which we show qualitative results. Using this network we demonstrate a real-time system estimating object poses with sufficient accuracy for real-world semantic grasping of known household objects in clutter by a real robot.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/tremblay18a.html
  PDF: http://proceedings.mlr.press/v87/tremblay18a/tremblay18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-tremblay18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Jonathan
    family: Tremblay
  - given: Thang
    family: To
  - given: Balakumar
    family: Sundaralingam
  - given: Yu
    family: Xiang
  - given: Dieter
    family: Fox
  - given: Stan
    family: Birchfield
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 306-316
  id: tremblay18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 306
  lastpage: 316
  published: 2018-10-23 00:00:00 +0000
- title: 'SPNets: Differentiable Fluid Dynamics for Deep Neural Networks'
  abstract: 'In this paper we introduce Smooth Particle Networks (SPNets), a framework for integrating fluid dynamics with deep networks. SPNets adds two new layers to the neural network toolbox: ConvSP and ConvSDF, which enable computing physical interactions with unordered particle sets. We use these layers in combination with standard neural network layers to directly implement fluid dynamics inside a deep network, where the parameters of the network are the fluid parameters themselves (e.g., viscosity, cohesion, etc.). Because SPNets are implemented as a neural network, the resulting fluid dynamics are fully differentiable. We then show how this can be successfully used to learn fluid parameters from data, perform liquid control tasks, and learn policies to manipulate liquids. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/schenck18a.html
  PDF: http://proceedings.mlr.press/v87/schenck18a/schenck18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-schenck18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Connor
    family: Schenck
  - given: Dieter
    family: Fox
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 317-335
  id: schenck18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 317
  lastpage: 335
  published: 2018-10-23 00:00:00 +0000
- title: 'A Data-Efficient Approach to Precise and Controlled Pushing'
  abstract: 'Decades of research in control theory have shown that simple controllers, when provided with timely feedback, can control complex systems. Pushing is an example of a complex mechanical system that is difficult to model accurately due to unknown system parameters such as coefficients of friction and pressure distributions. In this paper, we explore the data-complexity required for controlling, rather than modeling, such a system. Results show that a model-based control approach, where the dynamical model is learned from data, is capable of performing complex pushing trajectories with a minimal amount of training data (<10 data points). The dynamics of pushing interactions are modeled using a Gaussian process (GP) and are leveraged within a model predictive control approach that linearizes the GP and imposes actuator and task constraints for a planar manipulation task. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/bauza18a.html
  PDF: http://proceedings.mlr.press/v87/bauza18a/bauza18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-bauza18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Maria
    family: Bauza
  - given: Francois R.
    family: Hogan
  - given: Alberto
    family: Rodriguez
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 336-345
  id: bauza18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 336
  lastpage: 345
  published: 2018-10-23 00:00:00 +0000
- title: 'Learning Deployable Navigation Policies at Kilometer Scale from a Single Traversal'
  abstract: 'Model-free reinforcement learning has recently been shown to be effective at learning navigation policies from complex image input. However, these algorithms tend to require large amounts of interaction with the environment, which can be prohibitively costly to obtain on robots in the real world. We present an approach for efficiently learning goal-directed navigation policies on a mobile robot, from only a single coverage traversal of recorded data. The navigation agent learns an effective policy over a diverse action space in a large heterogeneous environment consisting of more than 2km of travel, through buildings and outdoor regions that collectively exhibit large variations in visual appearance, self-similarity, and connectivity. We compare pretrained visual encoders that enable precomputation of visual embeddings to achieve a throughput of tens of thousands of transitions per second at training time on a commodity desktop computer, allowing agents to learn from millions of trajectories of experience in a matter of hours. We propose multiple forms of computationally efficient stochastic augmentation to enable the learned policy to generalise beyond these precomputed embeddings, and demonstrate successful deployment of the learned policy on the real robot without fine tuning, despite environmental appearance differences at test time. The dataset and code required to reproduce these results and apply the technique to other datasets and robots is made publicly available at rl-navigation.github.io/deployable. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/bruce18a.html
  PDF: http://proceedings.mlr.press/v87/bruce18a/bruce18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-bruce18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Jake
    family: Bruce
  - given: Niko
    family: Sunderhauf
  - given: Piotr
    family: Mirowski
  - given: Raia
    family: Hadsell
  - given: Michael
    family: Milford
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 346-361
  id: bruce18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 346
  lastpage: 361
  published: 2018-10-23 00:00:00 +0000
- title: 'Risk-Aware Active Inverse Reinforcement Learning'
  abstract: 'Active learning from demonstration allows a robot to query a human for specific types of input to achieve efficient learning. Existing work has explored a variety of active query strategies; however, to our knowledge, none of these strategies directly minimize the performance risk of the policy the robot is learning. Utilizing recent advances in performance bounds for inverse reinforcement learning, we propose a risk-aware active inverse reinforcement learning algorithm that focuses active queries on areas of the state space with the potential for large generalization error. We show that risk-aware active learning outperforms standard active IRL approaches on gridworld, simulated driving, and table setting tasks, while also providing a performance-based stopping criterion that allows a robot to know when it has received enough demonstrations to safely perform a task. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/brown18a.html
  PDF: http://proceedings.mlr.press/v87/brown18a/brown18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-brown18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Daniel S.
    family: Brown
  - given: Yuchen
    family: Cui
  - given: Scott
    family: Niekum
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 362-372
  id: brown18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 362
  lastpage: 372
  published: 2018-10-23 00:00:00 +0000
- title: 'Dense Object Nets: Learning Dense Visual Object Descriptors By and For Robotic Manipulation'
  abstract: 'What is the right object representation for manipulation? We would like robots to visually perceive scenes and learn an understanding of the objects in them that (i) is task-agnostic and can be used as a building block for a variety of manipulation tasks, (ii) is generally applicable to both rigid and non-rigid objects, (iii) takes advantage of the strong priors provided by 3D vision, and (iv) is entirely learned from self-supervision. This is hard to achieve with previous methods: much recent work in grasping does not extend to grasping specific objects or other tasks, whereas task-specific learning may require many trials to generalize well across object configurations or other tasks. In this paper we present Dense Object Nets, which build on recent developments in self-supervised dense descriptor learning, as a consistent object representation for visual understanding and manipulation. We demonstrate they can be trained quickly (approximately 20 minutes) for a wide variety of previously unseen and potentially non-rigid objects. We additionally present novel contributions to enable multi-object descriptor learning, and show that by modifying our training procedure, we can either acquire descriptors which generalize across classes of objects, or descriptors that are distinct for each object instance. Finally, we demonstrate the novel application of learned dense descriptors to robotic manipulation. We demonstrate grasping of specific points on an object across potentially deformed object configurations, and demonstrate using class general descriptors to transfer specific grasps across objects in a class. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/florence18a.html
  PDF: http://proceedings.mlr.press/v87/florence18a/florence18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-florence18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Peter R.
    family: Florence
  - given: Lucas
    family: Manuelli
  - given: Russ
    family: Tedrake
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 373-385
  id: florence18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 373
  lastpage: 385
  published: 2018-10-23 00:00:00 +0000
- title: 'Bayesian RL for Goal-Only Rewards'
  abstract: 'We address the challenging problem of reinforcement learning under goal-only rewards [1], where rewards are only non-zero when the goal is achieved. This reward definition alleviates the need for cumbersome reward engineering, making the reward formulation trivial. Classic exploration heuristics such as Boltzmann or epsilon-greedy exploration are highly inefficient in domains with goal-only rewards. We solve this problem by leveraging value function posterior variance information to direct exploration where uncertainty is higher. The proposed algorithm (EMU-Q) achieves data-efficient exploration, and balances exploration and exploitation explicitly at a policy level granting users more control over the learning process. We introduce general features approximating kernels, allowing to greatly reduce the algorithm complexity from O(N^3) in the number of transitions to O(M^2) in the number of features. We demonstrate EMU-Q is competitive with other exploration techniques on a variety of continuous control tasks and on a robotic manipulator. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/morere18a.html
  PDF: http://proceedings.mlr.press/v87/morere18a/morere18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-morere18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Philippe
    family: Morere
  - given: Fabio
    family: Ramos
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 386-398
  id: morere18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 386
  lastpage: 398
  published: 2018-10-23 00:00:00 +0000
- title: 'Benchmarks for reinforcement learning in mixed-autonomy traffic'
  abstract: 'We release new benchmarks in the use of deep reinforcement learning (RL) to create controllers for mixed-autonomy traffic, where connected and autonomous vehicles (CAVs) interact with human drivers and infrastructure. Benchmarks, such as Mujoco or the Arcade Learning Environment, have spurred new research by enabling researchers to effectively compare their results so that they can focus on algorithmic improvements and control techniques rather than system design. To promote similar advances in traffic control via RL, we propose four benchmarks, based on three new traffic scenarios, illustrating distinct reinforcement learning problems with applications to mixed-autonomy traffic. We provide an introduction to each control problem, an overview of their MDP structures, and preliminary performance results from commonly used RL algorithms. For the purpose of reproducibility, the benchmarks, reference implementations, and tutorials are available at https://github.com/flow-project/flow.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/vinitsky18a.html
  PDF: http://proceedings.mlr.press/v87/vinitsky18a/vinitsky18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-vinitsky18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Eugene
    family: Vinitsky
  - given: Aboudy
    family: Kreidieh
  - given: Luc Le
    family: Flem
  - given: Nishant
    family: Kheterpal
  - given: Kathy
    family: Jang
  - given: Cathy
    family: Wu
  - given: Fangyu
    family: Wu
  - given: Richard
    family: Liaw
  - given: Eric
    family: Liang
  - given: Alexandre M.
    family: Bayen
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 399-409
  id: vinitsky18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 399
  lastpage: 409
  published: 2018-10-23 00:00:00 +0000
- title: 'Intervention Aided Reinforcement Learning for Safe and Practical Policy Optimization in Navigation'
  abstract: 'Combining deep neural networks with reinforcement learning has shown great potential in the next-generation intelligent control. However, there are challenges in terms of safety and cost in practical applications. In this pa- per, we propose the Intervention Aided Reinforcement Learning (IARL) framework, which utilizes human intervened robot-environment interaction to improve the policy. We used the Unmanned Aerial Vehicle (UAV) as the test platform. We built neural networks as our policy to map sensor readings to control signals on the UAV. Our experiment scenarios cover both simulation and reality. We show that our approach substantially reduces the human intervention and improves the performance in autonomous navigation1, at the same time it ensures safety and keeps training cost acceptable. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/wang18a.html
  PDF: http://proceedings.mlr.press/v87/wang18a/wang18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-wang18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Fan
    family: Wang
  - given: Bo
    family: Zhou
  - given: Ke
    family: Chen
  - given: Tingxiang
    family: Fan
  - given: Xi
    family: Zhang
  - given: Jiangyong
    family: Li
  - given: Hao
    family: Tian
  - given: Jia
    family: Pan
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 410-421
  id: wang18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 410
  lastpage: 421
  published: 2018-10-23 00:00:00 +0000
- title: 'Reinforcement Learning of Active Vision for Manipulating Objects under Occlusions'
  abstract: 'We consider artificial agents that learn to jointly control their gripper and camera in order to reinforcement learn manipulation policies in the presence of occlusions from distractor objects. Distractors often occlude the object of interest and cause it to disappear from the field of view. We propose hand/eye controllers that learn to move the camera to keep the object within the field of view and visible, in coordination to manipulating it to achieve the desired goal, e.g., pushing it to a target location. We incorporate structural biases of object-centric attention within our actor-critic architectures, which our experiments suggest to be a key for good performance. Our results further highlight the importance of curriculum with regards to environment difficulty. The resulting active vision / manipulation policies outperform static camera setups for a variety of cluttered environments. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/cheng18a.html
  PDF: http://proceedings.mlr.press/v87/cheng18a/cheng18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-cheng18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Ricson
    family: Cheng
  - given: Arpit
    family: Agarwal
  - given: Katerina
    family: Fragkiadaki
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 422-431
  id: cheng18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 422
  lastpage: 431
  published: 2018-10-23 00:00:00 +0000
- title: 'Adaptable replanning with compressed linear action models for learning from demonstrations'
  abstract: 'We propose an adaptable and efficient model-based reinforcement learning approach well suited for continuous domains with sparse samples, a setting often encountered when learning from demonstrations. The flexibility of our method originates from the approximate transition models, estimated from data, and the online replanning approach proposed. Together, these components allow for immediate adaptation to a new task, given in the form of a reward function. The efficiency of our method comes from two approximations. First, rather than representing a complete distribution over the results of taking an action, which is difficult in continuous state spaces, it learns a linear model of the expected transition for each action. Second, it uses a novel strategy for compressing these linear action models, which significantly reduces space and time for learning models, and supports efficient online generation of open-loop plans. The effectiveness of these methods is demonstrated in a simulated driving domain with a 20-dimensional continuous input space. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/gehring18a.html
  PDF: http://proceedings.mlr.press/v87/gehring18a/gehring18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-gehring18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Clement
    family: Gehring
  - given: Leslie Pack
    family: Kaelbling
  - given: Tomas
    family: Lozano-Perez
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 432-442
  id: gehring18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 432
  lastpage: 442
  published: 2018-10-23 00:00:00 +0000
- title: 'Automorphing Kernels for Nonstationarity in Mapping Unstructured Environments'
  abstract: 'In order to deploy robots in previously unseen and unstructured environments, the robots should have the capacity to learn on their own and adapt to the changes in the environments. For instance, in mobile robotics, a robot should be able to learn a map of the environment from data itself without the intervention of a human to tune the parameters of the model. To this end, leveraging the latest developments in automatic machine learning (AutoML), probabilistic programming, and statistical sampling, under the Hilbert mapping framework which can represent the occupancy of the environment as a continuous function of locations, we formulate a Bayesian framework to learn all parameters of the map. Crucially, this way, the robot is capable of learning the optimal shapes and placement of the kernels in Hilbert maps by merely embedding high-level human knowledge of the problem by means of prior probability distributions. Since the proposed framework employs stochastic variational inference, the model learns tens of thousands of parameters within minutes in both big data and data-scarce regimes. Experiments conducted on simulated and real-world datasets in static and dynamic environments indicate the proposed method significantly outperforms existing stationary occupancy mapping techniques, verifying the importance of learning the interdependent position-shape relationship of kernels alongside other model parameters. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/senanayake18a.html
  PDF: http://proceedings.mlr.press/v87/senanayake18a/senanayake18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-senanayake18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Ransalu
    family: Senanayake
  - given: Anthony
    family: Tompkins
  - given: Fabio
    family: Ramos
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 443-455
  id: senanayake18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 443
  lastpage: 455
  published: 2018-10-23 00:00:00 +0000
- title: 'Leveraging Deep Visual Descriptors for Hierarchical Efficient Localization'
  abstract: 'Many robotics applications require precise pose estimates despite operating in large and changing environments. This can be addressed by visual localization, using a pre-computed 3D model of the surroundings. The pose estimation then amounts to finding correspondences between 2D keypoints in a query image and 3D points in the model using local descriptors. However, computational power is often limited on robotic platforms, making this task challenging in large-scale environments. Binary feature descriptors significantly speed up this 2D-3D matching, and have become popular in the robotics community, but also strongly impair the robustness to perceptual aliasing and changes in viewpoint, illumination and scene structure. In this work, we propose to leverage recent advances in deep learning to perform an efficient hierarchical localization. We first localize at the map level using learned image-wide global descriptors, and subsequently estimate a precise pose from 2D-3D matches computed in the candidate places only. This restricts the local search and thus allows to efficiently exploit powerful non-binary descriptors usually dismissed on resource-constrained devices. Our approach results in state-of-the-art localization performance while running in real-time on a popular mobile platform, enabling new prospects for robotics research.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/sarlin18a.html
  PDF: http://proceedings.mlr.press/v87/sarlin18a/sarlin18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-sarlin18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Paul-Edouard
    family: Sarlin
  - given: Frederic
    family: Debraine
  - given: Marcin
    family: Dymczyk
  - given: Roland
    family: Siegwart
  - given: Cesar
    family: Cadena
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 456-465
  id: sarlin18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 456
  lastpage: 465
  published: 2018-10-23 00:00:00 +0000
- title: 'The Lyapunov Neural Network: Adaptive Stability Certification for Safe Learning of Dynamical Systems'
  abstract: 'Learning algorithms have shown considerable prowess in simulation by allowing robots to adapt to uncertain environments and improve their performance. However, such algorithms are rarely used in practice on safety-critical systems, since the learned policy typically does not yield any safety guarantees. That is, the required exploration may cause physical harm to the robot or its environment. In this paper, we present a method to learn accurate safety certificates for nonlinear, closed-loop dynamical systems. Specifically, we construct a neural network Lyapunov function and a training algorithm that adapts it to the shape of the largest safe region in the state space. The algorithm relies only on knowledge of inputs and outputs of the dynamics, rather than on any specific model structure. We demonstrate our method by learning the safe region of attraction for a simulated inverted pendulum. Furthermore, we discuss how our method can be used in safe learning algorithms together with statistical models of dynamical systems. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/richards18a.html
  PDF: http://proceedings.mlr.press/v87/richards18a/richards18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-richards18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Spencer M.
    family: Richards
  - given: Felix
    family: Berkenkamp
  - given: Andreas
    family: Krause
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 466-476
  id: richards18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 466
  lastpage: 476
  published: 2018-10-23 00:00:00 +0000
- title: 'Learning 6-DoF Grasping and Pick-Place Using Attention Focus'
  abstract: 'We address a class of manipulation problems where the robot perceives the scene with a depth sensor and can move its end effector in a space with six degrees of freedom—3D position and orientation. Our approach is to formulate the problem as a Markov decision process (MDP) with abstract yet generally applicable state and action representations. Finding a good solution to the MDP requires adding constraints on the allowed actions. We develop a specific set of constraints called hierarchical SE(3) sampling (HSE3S) which causes the robot to learn a sequence of gazes to focus attention on the task-relevant parts of the scene. We demonstrate the effectiveness of our approach on three challenging pick-place tasks (with novel objects in clutter and nontrivial places) both in simulation and on a real robot, even though all training is done in simulation. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/gualtieri18a.html
  PDF: http://proceedings.mlr.press/v87/gualtieri18a/gualtieri18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-gualtieri18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Marcus
    family: Gualtieri
  - given: Robert
    family: Platt
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 477-486
  id: gualtieri18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 477
  lastpage: 486
  published: 2018-10-23 00:00:00 +0000
- title: 'Curiosity Driven Exploration of Learned Disentangled Goal Spaces'
  abstract: 'Intrinsically motivated goal exploration processes enable agents to explore efficiently complex environments with high-dimensional continuous actions. They have been applied successfully to real world robots to discover repertoires of policies producing a wide diversity of effects. Often these algorithms relied on engineered goal spaces but it was recently shown that one can use deep representation learning algorithms to learn an adequate goal space in simple environments. In this paper we show that using a disentangled goal space (i.e. a representation where each latent variable is sensitive to a single degree of freedom) leads to better exploration performances than an entangled one. We further show that when the representation is disentangled, one can leverage it by sampling goals that maximize learning progress in a modular manner. Finally, we show that the measure of learning progress, used to drive curiosity-driven exploration, can be used simultaneously to discover abstract independently controllable features of the environment. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/laversanne-finot18a.html
  PDF: http://proceedings.mlr.press/v87/laversanne-finot18a/laversanne-finot18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-laversanne-finot18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Adrien
    family: Laversanne-Finot
  - given: Alexandre
    family: Pere
  - given: Pierre-Yves
    family: Oudeyer
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 487-504
  id: laversanne-finot18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 487
  lastpage: 504
  published: 2018-10-23 00:00:00 +0000
- title: 'Mapping Navigation Instructions to Continuous Control Actions with Position-Visitation Prediction'
  abstract: 'We propose an approach for mapping natural language instructions and raw observations to continuous control of a quadcopter drone. Our model predicts interpretable position-visitation distributions indicating where the agent should go during execution and where it should stop, and uses the predicted distributions to select the actions to execute. This two-step model decomposition allows for simple and efficient training using a combination of supervised learning and imitation learning. We evaluate our approach with a realistic drone simulator, and demonstrate absolute task-completion accuracy improvements of 16.85% over two state-of-the-art instruction-following methods. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/blukis18a.html
  PDF: http://proceedings.mlr.press/v87/blukis18a/blukis18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-blukis18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Valts
    family: Blukis
  - given: Dipendra
    family: Misra
  - given: Ross A.
    family: Knepper
  - given: Yoav
    family: Artzi
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 505-518
  id: blukis18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 505
  lastpage: 518
  published: 2018-10-23 00:00:00 +0000
- title: 'Batch Active Preference-Based Learning of Reward Functions'
  abstract: 'Data generation and labeling are usually an expensive part of learning for robotics. While active learning methods are commonly used to tackle the former problem, preference-based learning is a concept that attempts to solve the latter by querying users with preference questions. In this paper, we will develop a new algorithm, batch active preference-based learning, that enables efficient learning of reward functions using as few data samples as possible while still having short query generation times. We introduce several approximations to the batch active learning problem, and provide theoretical guarantees for the convergence of our algorithms. Finally, we present our experimental results for a variety of robotics tasks in simulation. Our results suggest that our batch active learning algorithm requires only a few queries that are computed in a short amount of time. We then showcase our algorithm in a study to learn human users’ preferences. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/biyik18a.html
  PDF: http://proceedings.mlr.press/v87/biyik18a/biyik18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-biyik18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Erdem
    family: Biyik
  - given: Dorsa
    family: Sadigh
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 519-528
  id: biyik18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 519
  lastpage: 528
  published: 2018-10-23 00:00:00 +0000
- title: 'Learning Audio Feedback for Estimating Amount and Flow of Granular Material'
  abstract: 'Granular materials produce audio-frequency mechanical vibrations in air and structures when manipulated. These vibrations correlate with both the nature of the events and the intrinsic properties of the materials producing them. We therefore propose learning to use audio-frequency vibrations from contact events to estimate the flow and amount of granular materials during scooping and pouring tasks. We evaluated multiple deep and shallow learning frameworks on a dataset of 13,750 shaking and pouring samples across five different granular materials. Our results indicate that audio is an informative sensor modality for accurately estimating flow and amounts, with a mean RMSE of 2.8g across the five materials for pouring. We also demonstrate how the learned networks can be used to pour a desired amount of material. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/clarke18a.html
  PDF: http://proceedings.mlr.press/v87/clarke18a/clarke18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-clarke18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Samuel
    family: Clarke
  - given: Travers
    family: Rhodes
  - given: Christopher G.
    family: Atkeson
  - given: Oliver
    family: Kroemer
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 529-550
  id: clarke18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 529
  lastpage: 550
  published: 2018-10-23 00:00:00 +0000
- title: 'HybridNet: Integrating Model-based and Data-driven Learning to Predict Evolution of Dynamical Systems'
  abstract: 'The robotic systems continuously interact with complex dynamical systems in the physical world. Reliable predictions of spatiotemporal evolution of these dynamical systems, with limited knowledge of system dynamics, are crucial for autonomous operation. In this paper, we present HybridNet, a framework that integrates data-driven deep learning and model-driven computation to reliably predict spatiotemporal evolution of a dynamical systems even with in-exact knowledge of their parameters. A data-driven deep neural network (DNN) with Convolutional LSTM (ConvLSTM) as the backbone is employed to predict the time-varying evolution of the external forces/perturbations. On the other hand, the model-driven computation is performed using Cellular Neural Network (CeNN), a neuro-inspired algorithm to model dynamical systems defined by coupled partial differential equations (PDEs). CeNN converts the intricate numerical computation into a series of convolution operations, enabling a trainable PDE solver. With a feedback control loop, HybridNet can learn the physical parameters governing the system’s dynamics in real-time, and accordingly adapt the computation models to enhance prediction accuracy for time-evolving dynamical systems. The experimental results on two dynamical systems, namely, heat convection-diffusion system, and fluid dynamical system, demonstrate that the HybridNet produces higher accuracy than the state-of-the-art deep learning based approach. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/long18a.html
  PDF: http://proceedings.mlr.press/v87/long18a/long18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-long18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Yun
    family: Long
  - given: Xueyuan
    family: She
  - given: Saibal
    family: Mukhopadhyay
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 551-560
  id: long18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 551
  lastpage: 560
  published: 2018-10-23 00:00:00 +0000
- title: 'Benchmarking Reinforcement Learning Algorithms on Real-World Robots'
  abstract: ' Through many recent successes in simulation, model-free reinforcement learning has emerged as a promising approach to solving continuous control robotic tasks. The research community is now able to reproduce, analyze and build quickly on these results due to open source implementations of learning algorithms and simulated benchmark tasks. To carry forward these successes to real-world applications, it is crucial to withhold utilizing the unique advantages of simulations that do not transfer to the real world and experiment directly with physical robots. However, reinforcement learning research with physical robots faces substantial resistance due to the lack of benchmark tasks and supporting source code. In this work, we introduce several reinforcement learning tasks with multiple commercially available robots that present varying levels of learning difficulty, setup, and repeatability. On these tasks, we test the learning performance of off-the-shelf implementations of four reinforcement learning algorithms and analyze sensitivity to their hyper-parameters to determine their readiness for applications in various real-world tasks. Our results show that with a careful setup of the task interface and computations, some of these implementations can be readily applicable to physical robots. We find that state-of-the-art learning algorithms are highly sensitive to their hyper-parameters and their relative ordering does not transfer across tasks, indicating the necessity of re-tuning them for each task for best performance. On the other hand, the best hyper-parameter configuration from one task may often result in effective learning on held-out tasks even with different robots, providing a reasonable default. We make the benchmark tasks publicly available to enhance reproducibility in real-world reinforcement learning.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/mahmood18a.html
  PDF: http://proceedings.mlr.press/v87/mahmood18a/mahmood18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-mahmood18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: A. Rupam
    family: Mahmood
  - given: Dmytro
    family: Korenkevych
  - given: Gautham
    family: Vasan
  - given: William
    family: Ma
  - given: James
    family: Bergstra
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 561-591
  id: mahmood18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 561
  lastpage: 591
  published: 2018-10-23 00:00:00 +0000
- title: 'Learning Neural Parsers with Deterministic Differentiable Imitation Learning'
  abstract: ' We explore the problem of learning to decompose spatial tasks into segments, as exemplified by the problem of a painting robot covering a large object. Inspired by the ability of classical decision tree algorithms to construct structured parti- tions of their input spaces, we formulate the problem of decomposing objects into segments as a parsing approach. We make the insight that the derivation of a parse-tree that decomposes the object into segments closely resembles a decision tree constructed by ID3, which can be done when the ground-truth available. We learn to imitate an expert parsing oracle, such that our neural parser can generalize to parse natural images without ground truth. We introduce a novel deterministic policy gradient update, DRAG (i.e., DeteRministically AGgrevate) in the form of a deterministic actor-critic variant of AggreVaTeD [1], to train our neural parser. From another perspective, our approach is a variant of the Deterministic Policy Gradient [2, 3] suitable for the imitation learning setting. The deterministic policy representation offered by training our neural parser with DRAG allows it to outperform state of the art imitation and reinforcement learning approaches. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/shankar18a.html
  PDF: http://proceedings.mlr.press/v87/shankar18a/shankar18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-shankar18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Tanmay
    family: Shankar
  - given: Nicholas
    family: Rhinehart
  - given: Katharina
    family: Muelling
  - given: Kris M.
    family: Kitani
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 592-604
  id: shankar18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 592
  lastpage: 604
  published: 2018-10-23 00:00:00 +0000
- title: 'Learning to Localize Using a LiDAR Intensity Map'
  abstract: 'In this paper we propose a real-time, calibration-agnostic and effective localization system for self-driving cars. Our method learns to embed the online LiDAR sweeps and intensity map into a joint deep embedding space. Localization is then conducted through an efficient convolutional matching between the embeddings. Our full system can operate in real-time at 15Hz while achieving centimeter level accuracy across different LiDAR sensors and environments. Our experiments illustrate the performance of the proposed approach over a large-scale dataset consisting of over 4000km of driving. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/barsan18a.html
  PDF: http://proceedings.mlr.press/v87/barsan18a/barsan18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-barsan18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Ioan Andrei
    family: Barsan
  - given: Shenlong
    family: Wang
  - given: Andrei
    family: Pokrovsky
  - given: Raquel
    family: Urtasun
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 605-616
  id: barsan18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 605
  lastpage: 616
  published: 2018-10-23 00:00:00 +0000
- title: 'Model-Based Reinforcement Learning via Meta-Policy Optimization'
  abstract: 'Model-based reinforcement learning approaches carry the promise of being data efficient. However, due to challenges in learning dynamics models that sufficiently match the real-world dynamics, they struggle to achieve the same asymptotic performance as model-free methods. We propose Model-Based Meta-Policy-Optimization (MB-MPO), an approach that foregoes the strong reliance on accurate learned dynamics models. Using an ensemble of learned dynamic models, MB-MPO meta-learns a policy that can quickly adapt to any model in the ensemble with one policy gradient step. This steers the meta-policy towards internalizing consistent dynamics predictions among the ensemble while shifting the burden of behaving optimally w.r.t. the model discrepancies towards the adaptation step. Our experiments show that MB-MPO is more robust to model imperfections than previous model-based approaches. Finally, we demonstrate that our approach is able to match the asymptotic performance of model-free methods while requiring significantly less experience. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/clavera18a.html
  PDF: http://proceedings.mlr.press/v87/clavera18a/clavera18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-clavera18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Ignasi
    family: Clavera
  - given: Jonas
    family: Rothfuss
  - given: John
    family: Schulman
  - given: Yasuhiro
    family: Fujita
  - given: Tamim
    family: Asfour
  - given: Pieter
    family: Abbeel
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 617-629
  id: clavera18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 617
  lastpage: 629
  published: 2018-10-23 00:00:00 +0000
- title: 'Reinforcement Learning of Phase Oscillators for Fast Adaptation to Moving Targets'
  abstract: 'Online movement generation in tasks involving real humanoid robots interacting with fast-moving targets is extremely difficult. This paper approaches this problem via imitation and reinforcement learning using phase variables. Imitation learning is used to acquire primitive trajectories of the demonstrator interacting with the target. The temporal progress of the robot is represented as a function of the target’s phase. Using a phase oscillator formulation, reinforcement learning optimizes a temporal policy such that the robot can quickly react to large/unexpected changes in the target movement. The phase representation decouples the temporal and spatial problems allowing the use of fast online solutions. The methodology is applicable in both cyclic and single-stroke movements. We applied the proposed method on a real bi-manual humanoid upper body with 14 degrees-of-freedom where the robot had to repeatedly push a ball hanging in front of it. In simulation, we show a human-robot interaction scenario where the robot changed its role from giver to receiver as a function of the interaction reward. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/maeda18a.html
  PDF: http://proceedings.mlr.press/v87/maeda18a/maeda18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-maeda18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Guilherme
    family: Maeda
  - given: Okan
    family: Koc
  - given: Jun
    family: Morimoto
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 630-640
  id: maeda18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 630
  lastpage: 640
  published: 2018-10-23 00:00:00 +0000
- title: 'Global Search with Bernoulli Alternation Kernel for Task-oriented Grasping Informed by Simulation'
  abstract: 'We develop an approach that benefits from large simulated datasets and takes full advantage of the limited online data that is most relevant. We propose a variant of Bayesian optimization that alternates between using informed and uninformed kernels. With this Bernoulli Alternation Kernel we ensure that discrepancies between simulation and reality do not hinder adapting robot control policies online. The proposed approach is applied to a challenging real-world problem of task-oriented grasping with novel objects. Our further contribution is a neural network architecture and training pipeline that use experience from grasping objects in simulation to learn grasp stability scores. We learn task scores from a labeled dataset with a convolutional network, which is used to construct an informed kernel for our variant of Bayesian optimization. Experiments on an ABB Yumi robot with real sensor data demonstrate success of our approach, despite the challenge of fulfilling task requirements and high uncertainty over physical properties of objects. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/antonova18a.html
  PDF: http://proceedings.mlr.press/v87/antonova18a/antonova18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-antonova18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Rika
    family: Antonova
  - given: Mia
    family: Kokic
  - given: Johannes A.
    family: Stork
  - given: Danica
    family: Kragic
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 641-650
  id: antonova18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 641
  lastpage: 650
  published: 2018-10-23 00:00:00 +0000
- title: 'Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation'
  abstract: 'In this paper, we study the problem of learning vision-based dynamic manipulation skills using a scalable reinforcement learning approach. We study this problem in the context of grasping, a longstanding challenge in robotic manipulation. In contrast to static learning behaviors that choose a grasp point and then execute the desired grasp, our method enables closed-loop vision-based control, whereby the robot continuously updates its grasp strategy based on the most recent observations to optimize long-horizon grasp success. To that end, we introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function with over 1.2M parameters to perform closed-loop, real-world grasping that generalizes to 96% grasp success on unseen objects. Aside from attaining a very high success rate, our method exhibits behaviors that are quite distinct from more standard grasping systems: using only RGB vision-based perception from an over-the-shoulder camera, our method automatically learns regrasping strategies, probes objects to find the most effective grasps, learns to reposition objects and perform other non-prehensile pre-grasp manipulations, and responds dynamically to disturbances and perturbations. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/kalashnikov18a.html
  PDF: http://proceedings.mlr.press/v87/kalashnikov18a/kalashnikov18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-kalashnikov18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Dmitry
    family: Kalashnikov
  - given: Alex
    family: Irpan
  - given: Peter
    family: Pastor
  - given: Julian
    family: Ibarz
  - given: Alexander
    family: Herzog
  - given: Eric
    family: Jang
  - given: Deirdre
    family: Quillen
  - given: Ethan
    family: Holly
  - given: Mrinal
    family: Kalakrishnan
  - given: Vincent
    family: Vanhoucke
  - given: Sergey
    family: Levine
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 651-673
  id: kalashnikov18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 651
  lastpage: 673
  published: 2018-10-23 00:00:00 +0000
- title: 'Reward Estimation for Variance Reduction in Deep Reinforcement Learning'
  abstract: 'Reinforcement Learning (RL) agents require the specification of a reward signal for learning behaviours. However, introduction of corrupt or stochastic rewards can yield high variance in learning. Such corruption may be a direct result of goal misspecification, randomness in the reward signal, or correlation of the reward with external factors that are not known to the agent. Corruption or stochasticity of the reward signal can be especially problematic in robotics, where goal specification can be particularly difficult for complex tasks. While many variance reduction techniques have been studied to improve the robustness of the RL process, handling such stochastic or corrupted reward structures remains difficult. As an alternative for handling this scenario in model-free RL methods, we suggest using an estimator for both rewards and value functions. We demonstrate that this improves performance under corrupted stochastic rewards in both the tabular and non-linear function approximation settings for a variety of noise types and environments. The use of reward estimation is a robust and easy-to-implement improvement for handling corrupted reward signals in model-free RL. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/romoff18a.html
  PDF: http://proceedings.mlr.press/v87/romoff18a/romoff18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-romoff18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Joshua
    family: Romoff
  - given: Peter
    family: Henderson
  - given: Alexandre
    family: Piche
  - given: Vincent
    family: Francois-Lavet
  - given: Joelle
    family: Pineau
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 674-699
  id: romoff18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 674
  lastpage: 699
  published: 2018-10-23 00:00:00 +0000
- title: 'Domain Randomization for Simulation-Based Policy Optimization with Transferability Assessment'
  abstract: 'Exploration-based reinforcement learning on real robot systems is generally time-intensive and can lead to catastrophic robot failures. Therefore, simulation-based policy search appears to be an appealing alternative. Unfor- tunately, running policy search on a slightly faulty simulator can easily lead to the maximization of the ‘Simulation Optimization Bias’ (SOB), where the policy exploits modeling errors of the simulator such that the resulting behavior can potentially damage the robot. For this reason, much work in robot reinforcement learning has focused on model-free methods that learn on real-world systems. The resulting lack of safe simulation-based policy learning techniques imposes severe limitations on the application of robot reinforcement learning. In this paper, we explore how physics simulations can be utilized for a robust policy optimization by perturbing the simulator’s parameters and training from model ensembles. We propose a new algorithm called Simulation-based Policy Optimization with Transferability Assessment (SPOTA) that uses a biased estimator of the SOB to formulate a stopping criterion for training. We show that the new simulation-based policy search algorithm is able to learn a control policy exclusively from a randomized simulator that can be applied directly to a different system without using any data from the latter. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/muratore18a.html
  PDF: http://proceedings.mlr.press/v87/muratore18a/muratore18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-muratore18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Fabio
    family: Muratore
  - given: Felix
    family: Treede
  - given: Michael
    family: Gienger
  - given: Jan
    family: Peters
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 700-713
  id: muratore18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 700
  lastpage: 713
  published: 2018-10-23 00:00:00 +0000
- title: 'Grounding Robot Plans from Natural Language Instructions with Incomplete World Knowledge'
  abstract: 'Our goal is to enable robots to interpret and execute high-level tasks conveyed using natural language instructions. For example, consider tasking a household robot to, “prepare my breakfast”, “clear the boxes on the table” or “make me a fruit milkshake”. Interpreting such underspecified instructions requires environmental context and background knowledge about how to accomplish complex tasks. Further, the robot’s workspace knowledge may be incomplete: the environment may only be partially-observed or background knowledge may be missing causing a failure in plan synthesis. We introduce a probabilistic model that utilizes background knowledge to infer latent or missing plan constituents based on semantic co-associations learned from noisy textual corpora of task descriptions. The ability to infer missing plan constituents enables information-seeking actions such as visual exploration or dialogue with the human to acquire new knowledge to fill incomplete plans. Results indicate robust plan inference from under-specified instructions in partially-known worlds. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/nyga18a.html
  PDF: http://proceedings.mlr.press/v87/nyga18a/nyga18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-nyga18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Daniel
    family: Nyga
  - given: Subhro
    family: Roy
  - given: Rohan
    family: Paul
  - given: Daehyung
    family: Park
  - given: Mihai
    family: Pomarlan
  - given: Michael
    family: Beetz
  - given: Nicholas
    family: Roy
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 714-723
  id: nyga18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 714
  lastpage: 723
  published: 2018-10-23 00:00:00 +0000
- title: 'Learning What Information to Give in Partially Observed Domains'
  abstract: 'In many robotic applications, an autonomous agent must act within and explore a partially observed environment that is unobserved by its human team-mate. We consider such a setting in which the agent can, while acting, transmit declarative information to the human that helps them understand aspects of this unseen environment. In this work, we address the algorithmic question of how the agent should plan out what actions to take and what information to transmit. Naturally, one would expect the human to have preferences, which we model information-theoretically by scoring transmitted information based on the change it induces in weighted entropy of the human’s belief state. We formulate this setting as a belief MDP and give a tractable algorithm for solving it approximately. Then, we give an algorithm that allows the agent to learn the human’s preferences online, through exploration. We validate our approach experimentally in simulated discrete and continuous partially observed search-and-recover domains. Visit http://tinyurl.com/chitnis-corl-18 for a supplementary video.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/chitnis18a.html
  PDF: http://proceedings.mlr.press/v87/chitnis18a/chitnis18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-chitnis18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Rohan
    family: Chitnis
  - given: Leslie Pack
    family: Kaelbling
  - given: Tomas
    family: Lozano-Perez
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 724-733
  id: chitnis18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 724
  lastpage: 733
  published: 2018-10-23 00:00:00 +0000
- title: 'Sim-to-Real Reinforcement Learning for Deformable Object Manipulation'
  abstract: 'We have seen much recent progress in rigid object manipulation, but interaction with deformable objects has notably lagged behind. Due to the large configuration space of deformable objects, solutions using traditional modelling approaches require significant engineering work. Perhaps then, bypassing the need for explicit modelling and instead learning the control in an end-to-end manner serves as a better approach? Despite the growing interest in the use of end-to-end robot learning approaches, only a small amount of work has focused on their applicability to deformable object manipulation. Moreover, due to the large amount of data needed to learn these end-to-end solutions, an emerging trend is to learn control policies in simulation and then transfer them over to the real world. To date, no work has explored whether it is possible to learn and transfer deformable object policies. We believe that if sim-to-real methods are to be employed further, then it should be possible to learn to interact with a wide variety of objects, and not only rigid objects. In this work, we use a combination of state-of-the-art deep reinforcement learning algorithms to solve the problem of manipulating deformable objects (specifically cloth). We evaluate our approach on three tasks—folding a towel up to a mark, folding a face towel diagonally, and draping a piece of cloth over a hanger. Our agents are fully trained in simulation with domain randomisation, and then successfully deployed in the real world without having seen any real deformable objects.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/matas18a.html
  PDF: http://proceedings.mlr.press/v87/matas18a/matas18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-matas18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Jan
    family: Matas
  - given: Stephen
    family: James
  - given: Andrew J.
    family: Davison
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 734-743
  id: matas18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 734
  lastpage: 743
  published: 2018-10-23 00:00:00 +0000
- title: 'Expanding Motor Skills using Relay Networks'
  abstract: 'While recent advances in deep reinforcement learning have achieved impressive results in learning motor skills, many policies are only capable within a limited set of initial states. We propose an algorithm that sequentially decomposes a complex robotic task into simpler subtasks and trains a local policy for each subtask such that the robot can expand its existing skill set gradually. Our key idea is to build a directed graph of local control policies represented by neural networks, which we refer to as relay neural networks. Starting from the first policy that attempts to achieve the task from a small set of initial states, the algorithm iteratively discovers the next subtask with increasingly more difficult initial states until the last subtask matches the initial state distribution of the original task. The policy of each subtask aims to drive the robot to a state where the policy of its preceding subtask is able to handle. By taking advantage of many existing actor-critic style policy search algorithms, we utilize the optimized value function to define “good states” for the next policy to relay to. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/kumar18a.html
  PDF: http://proceedings.mlr.press/v87/kumar18a/kumar18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-kumar18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Visak CV
    family: Kumar
  - given: Sehoon
    family: Ha
  - given: C.Karen
    family: Liu
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 744-756
  id: kumar18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 744
  lastpage: 756
  published: 2018-10-23 00:00:00 +0000
- title: 'Efficient Hierarchical Robot Motion Planning Under Uncertainty and Hybrid Dynamics'
  abstract: 'Noisy observations coupled with nonlinear dynamics pose one of the biggestchallengesinrobotmotionplanning. Bydecomposingnonlineardynamics into a discrete set of local dynamics models, hybrid dynamics provide a natural way to model nonlinear dynamics, especially in systems with sudden discontinuities in dynamics due to factors such as contacts. We propose a hierarchical POMDP planner that develops cost-optimized motion plans for hybrid dynamics models. The hierarchical planner first develops a high-level motion plan to sequence the local dynamics models to be visited and then converts it into a detailed continuous state plan. This hierarchical planning approach results in a decomposition of the POMDP planning problem into smaller sub-parts that can be solved with significantly lower computational costs. The ability to sequence the visitation of local dynamics models also provides a powerful way to leverage the hybrid dynamics to reduce state uncertainty. We evaluate the proposed planner on a navigation task in the simulated domain and on an assembly task with a robotic manipulator, showing that our approach can solve tasks having high observation noise and nonlinear dynamics effectively with significantly lower computational costs compared to direct planning approaches. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/jain18a.html
  PDF: http://proceedings.mlr.press/v87/jain18a/jain18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-jain18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Ajinkya
    family: Jain
  - given: Scott
    family: Niekum
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 757-766
  id: jain18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 757
  lastpage: 766
  published: 2018-10-23 00:00:00 +0000
- title: 'SURREAL: Open-Source Reinforcement Learning Framework and Robot Manipulation Benchmark'
  abstract: 'Reproducibility has been a significant challenge in deep reinforcement learning and robotics research. Open-source frameworks and standardized benchmarks can serve an integral role in rigorous evaluation and reproducible research.  We introduce SURREAL, an open-source scalable framework that supports state-of-the-art distributed reinforcement learning algorithms. We design a principled distributed learning formulation that accommodates both on-policy and off-policy learning. We demonstrate that SURREAL algorithms outperform existing open-source implementations in both agent performance and learning efficiency. We also introduce SURREAL Robotics Suite, an accessible set of benchmarking tasks in physical simulation for reproducible robot manipulation research. We provide extensive evaluations of SURREAL algorithms and establish strong baseline results.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/fan18a.html
  PDF: http://proceedings.mlr.press/v87/fan18a/fan18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-fan18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Linxi
    family: Fan
  - given: Yuke
    family: Zhu
  - given: Jiren
    family: Zhu
  - given: Zihua
    family: Liu
  - given: Orien
    family: Zeng
  - given: Anchit
    family: Gupta
  - given: Joan
    family: Creus-Costa
  - given: Silvio
    family: Savarese
  - given: Li
    family: Fei-Fei
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 767-782
  id: fan18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 767
  lastpage: 782
  published: 2018-10-23 00:00:00 +0000
- title: 'Task-Embedded Control Networks for Few-Shot Imitation Learning'
  abstract: 'Much like humans, robots should have the ability to leverage knowledge from previously learned tasks in order to learn new tasks quickly in new and unfamiliar environments. Despite this, most robot learning approaches have focused on learning a single task, from scratch, with a limited notion of generalisation, and no way of leveraging the knowledge to learn other tasks more efficiently. One possible solution is meta-learning, but many of the related approaches are limited in their ability to scale to a large number of tasks and to learn further tasks without forgetting previously learned ones. With this in mind, we introduce Task-Embedded Control Networks, which employ ideas from metric learning in order to create a task embedding that can be used by a robot to learn new tasks from one or more demonstrations. In the area of visually-guided manipulation, we present simulation results in which we surpass the performance of a state-of-the-art method when using only visual information from each demonstration. Additionally, we demonstrate that our approach can also be used in conjunction with domain randomisation to train our few-shot learning ability in simulation and then deploy in the real world without any additional training. Once deployed, the robot can learn new tasks from a single real-world demonstration. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/james18a.html
  PDF: http://proceedings.mlr.press/v87/james18a/james18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-james18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Stephen
    family: James
  - given: Michael
    family: Bloesch
  - given: Andrew J.
    family: Davison
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 783-795
  id: james18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 783
  lastpage: 795
  published: 2018-10-23 00:00:00 +0000
- title: 'Learning under Misspecified Objective Spaces'
  abstract: 'Learning robot objective functions from human input has become increasingly important, but state-of-the-art techniques assume that the human’s desired objective lies within the robot’s hypothesis space. When this is not true, even methods that keep track of uncertainty over the objective fail because they reason about which hypothesis might be correct, and not whether any of the hypotheses are correct. We focus specifically on learning from physical human corrections during the robot’s task execution, where not having a rich enough hypothesis space leads to the robot updating its objective in ways that the person did not actually intend. We observe that such corrections appear irrelevant to the robot, because they are not the best way of achieving any of the candidate objectives. Instead of naively trusting and learning from every human interaction, we propose robots learn conservatively by reasoning in real time about how relevant the human’s correction is for the robot’s hypothesis space. We test our inference method in an experiment with human interaction data, and demonstrate that this alleviates unintended learning in an in-person user study with a robot manipulator. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/bobu18a.html
  PDF: http://proceedings.mlr.press/v87/bobu18a/bobu18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-bobu18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Andreea
    family: Bobu
  - given: Andrea
    family: Bajcsy
  - given: Jaime F.
    family: Fisac
  - given: Anca D.
    family: Dragan
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 796-805
  id: bobu18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 796
  lastpage: 805
  published: 2018-10-23 00:00:00 +0000
- title: 'Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation'
  abstract: 'A general-purpose intelligent robot must be able to learn autonomously and be able to accomplish multiple tasks in order to be deployed in the real world. However, standard reinforcement learning approaches learn separate task-specific policies and assume the reward function for each task is known a priori. We propose a framework that learns event cues from off-policy data, and can flexibly combine these event cues at test time to accomplish different tasks. These event cue labels are not assumed to be known a priori, but are instead labeled using learned models, such as computer vision detectors, and then “backed up” in time using an action-conditioned predictive model. We show that a simulated robotic car and a real-world RC car can gather data and train fully autonomously without any human-provided labels beyond those needed to train the detectors, and then at test-time be able to accomplish a variety of different tasks. Videos of the experiments and code can be found at github.com/gkahn13/CAPs '
  volume: 87
  URL: https://proceedings.mlr.press/v87/kahn18a.html
  PDF: http://proceedings.mlr.press/v87/kahn18a/kahn18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-kahn18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Gregory
    family: Kahn
  - given: Adam
    family: Villaflor
  - given: Pieter
    family: Abbeel
  - given: Sergey
    family: Levine
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 806-816
  id: kahn18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 806
  lastpage: 816
  published: 2018-10-23 00:00:00 +0000
- title: 'Sim-to-Real Transfer with Neural-Augmented Robot Simulation'
  abstract: 'Despite the recent successes of deep reinforcement learning, teaching complex motor skills to a physical robot remains a hard problem. While learning directly on a real system is usually impractical, doing so in simulation has proven to be fast and safe. Nevertheless, because of the "reality gap," policies trained in simulation often perform poorly when deployed on a real system. In this work, we introduce a method for training a recurrent neural network on the differences between simulated and real robot trajectories and then using this model to augment the simulator. This Neural-Augmented Simulation (NAS) can be used to learn control policies that transfer significantly better to real environments than policies learned on existing simulators. We demonstrate the potential of our approach through a set of experiments on the Mujoco simulator with added backlash and the Poppy Ergo Jr robot. NAS allows us to learn policies that are competitive with ones that would have been learned directly on the real robot.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/golemo18a.html
  PDF: http://proceedings.mlr.press/v87/golemo18a/golemo18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-golemo18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Florian
    family: Golemo
  - given: Adrien Ali
    family: Taiga
  - given: Aaron
    family: Courville
  - given: Pierre-Yves
    family: Oudeyer
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 817-828
  id: golemo18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 817
  lastpage: 828
  published: 2018-10-23 00:00:00 +0000
- title: 'Bayesian Generalized Kernel Inference for Terrain Traversability Mapping'
  abstract: 'We propose a new approach for traversability mapping with sparse lidar scans collected by ground vehicles, which leverages probabilistic inference to build descriptive terrain maps. Enabled by recent developments in sparse kernels, Bayesian generalized kernel inference is applied sequentially to the related problems of terrain elevation and traversability inference. The first inference step allows sparse data to support descriptive terrain modeling, and the second inference step relieves the burden typically associated with traversability computation. We explore the capabilities of the approach over a variety of data and terrain, demonstrating its suitability for online use in real-world applications. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/shan18a.html
  PDF: http://proceedings.mlr.press/v87/shan18a/shan18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-shan18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Tixiao
    family: Shan
  - given: Jinkun
    family: Wang
  - given: Brendan
    family: Englot
  - given: Kevin
    family: Doherty
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 829-838
  id: shan18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 829
  lastpage: 838
  published: 2018-10-23 00:00:00 +0000
- title: 'Multi-objective Model-based Policy Search for Data-efficient Learning with Sparse Rewards'
  abstract: 'The most data-efficient algorithms for reinforcement learning in robotics are model-based policy search algorithms, which alternate between learning a dynamical model of the robot and optimizing a policy to maximize the expected return given the model and its uncertainties. However, the current algorithms lack an effective exploration strategy to deal with sparse or misleading reward scenarios: if they do not experience any state with a positive reward during the initial random exploration, it is very unlikely to solve the problem. Here, we propose a novel model-based policy search algorithm, Multi-DEX, that leverages a learned dynamical model to efficiently explore the task space and solve tasks with sparse rewards in a few episodes. To achieve this, we frame the policy search problem as a multi-objective, model-based policy optimization problem with three objectives: (1) generate maximally novel state trajectories, (2) maximize the cumulative reward and (3) keep the system in state-space regions for which the model is as accurate as possible. We then optimize these objectives using a Pareto-based multi-objective optimization algorithm. The experiments show that Multi-DEX is able to solve sparse reward scenarios (with a simulated robotic arm) in much lower interaction time than VIME, TRPO, GEP-PG, CMA-ES and Black-DROPS. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/kaushik18a.html
  PDF: http://proceedings.mlr.press/v87/kaushik18a/kaushik18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-kaushik18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Rituraj
    family: Kaushik
  - given: Konstantinos
    family: Chatzilygeroudis
  - given: Jean-Baptiste
    family: Mouret
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 839-855
  id: kaushik18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 839
  lastpage: 855
  published: 2018-10-23 00:00:00 +0000
- title: 'Modular meta-learning'
  abstract: 'Many prediction problems, such as those that arise in the context of robotics, have a simplifying underlying structure that, if known, could accelerate learning. In this paper, we present a strategy for learning a set of neural network modules that can be combined in different ways. We train different modular structures on a set of related tasks and generalize to new tasks by composing the learned modules in new ways. By reusing modules to generalize we achieve combinatorial generalization, akin to the ”infinite use of finite means” displayed in language. Finally, we show this improves performance in two robotics-related problems.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/alet18a.html
  PDF: http://proceedings.mlr.press/v87/alet18a/alet18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-alet18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Ferran
    family: Alet
  - given: Tomas
    family: Lozano-Perez
  - given: Leslie P.
    family: Kaelbling
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 856-868
  id: alet18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 856
  lastpage: 868
  published: 2018-10-23 00:00:00 +0000
- title: 'Dyadic collaborative Manipulation through Hybrid Trajectory Optimization'
  abstract: 'This work provides a principled formalism to address the joint planning problem in dyadic collaborative manipulation (DcM) scenarios by representing the human’s intentions as task space forces and solving the joint problem holistically via model-based optimization. The proposed method is the first to empower robotic agents with the ability to plan in hybrid spaces—optimizing over discrete contact locations, continuous trajectory and force profiles, for co-manipulation tasks with varied dyadic objective goals. This ability is particularly important in large object manipulation scenarios that typically require change of grasp-holds. The task of finding the contact points, forces and the respective timing of grasp-hold changes are carried out by a joint optimization using non-linear solvers. We demonstrate the efficacy of the optimization method by investigating the effect of robot policy changes (trajectories, timings, grasp-holds) based on changes in collaborative partner policies using physically based dynamic simulations. We also realize, in hardware, effective co-manipulation of a large object by the human and the robot, including eminent grasp changes as well as optimal dyadic interactions to realize the joint task. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/stouraitis18a.html
  PDF: http://proceedings.mlr.press/v87/stouraitis18a/stouraitis18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-stouraitis18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Theodoros
    family: Stouraitis
  - given: Iordanis
    family: Chatzinikolaidis
  - given: Michael
    family: Gienger
  - given: Sethu
    family: Vijayakumar
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 869-878
  id: stouraitis18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 869
  lastpage: 878
  published: 2018-10-23 00:00:00 +0000
- title: 'ROBOTURK: A Crowdsourcing Platform for Robotic Skill Learning through Imitation'
  abstract: 'Imitation Learning has empowered recent advances in learning robotic manipulation tasks by addressing shortcomings of Reinforcement Learning such as exploration and reward specification. However, research in this area has been limited to modest-sized datasets due to the difficulty of collecting large quantities of task demonstrations through existing mechanisms. This work introduces ROBO-TURK to address this challenge. ROBOTURK is a crowdsourcing platform for high quality 6-DoF trajectory based teleoperation through the use of widely available mobile devices (e.g. iPhone). We evaluate ROBOTURK on three manipulation tasks of varying timescales (15-120s) and observe that our user interface is statistically similar to special purpose hardware such as virtual reality controllers in terms of task completion times. Furthermore, we observe that poor network conditions, such as low bandwidth and high delay links, do not substantially affect the remote users’ ability to perform task demonstrations successfully on ROBOTURK. Lastly, we demonstrate the efficacy of ROBOTURK through the collection of a pilot dataset; using ROBOTURK, we collected 137.5 hours of manipulation data from remote workers, amounting to over 2200 successful task demonstrations in 22 hours of total system usage. We show that the data obtained through ROBOTURK enables policy learning on multi-step manipulation tasks with sparse rewards and that using larger quantities of demonstrations during policy learning provides benefits in terms of both learning consistency and final performance. For additional results, videos, and to download our pilot dataset, visit roboturk.stanford.edu '
  volume: 87
  URL: https://proceedings.mlr.press/v87/mandlekar18a.html
  PDF: http://proceedings.mlr.press/v87/mandlekar18a/mandlekar18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-mandlekar18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Ajay
    family: Mandlekar
  - given: Yuke
    family: Zhu
  - given: Animesh
    family: Garg
  - given: Jonathan
    family: Booher
  - given: Max
    family: Spero
  - given: Albert
    family: Tung
  - given: Julian
    family: Gao
  - given: John
    family: Emmons
  - given: Anchit
    family: Gupta
  - given: Emre
    family: Orbay
  - given: Silvio
    family: Savarese
  - given: Li
    family: Fei-Fei
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 879-893
  id: mandlekar18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 879
  lastpage: 893
  published: 2018-10-23 00:00:00 +0000
- title: 'Integrating kinematics and environment context into deep inverse reinforcement learning for predicting off-road vehicle trajectories'
  abstract: 'Predicting the motion of a mobile agent from a third-person perspective is an important component for many robotics applications, such as autonomous navigation and tracking. With accurate motion prediction of other agents, robots can plan for more intelligent behaviors to achieve specified objectives, instead of acting in a purely reactive way. Previous work addresses motion prediction by either only filtering kinematics, or using hand-designed and learned representations of the environment. Instead of separating kinematic and environmental context, we propose a novel approach to integrate both into an inverse reinforcement learning (IRL) framework for trajectory prediction. Instead of exponentially increasing the state-space complexity with kinematics, we propose a two-stage neural network architecture that considers motion and environment together to recover the reward function. The first-stage network learns feature representations of the environment using low-level LiDAR statistics and the second-stage network combines those learned features with kinematics data. We collected over 30 km of off-road driving data and validated experimentally that our method can effectively extract useful environmental and kinematic features. We generate accurate predictions of the distribution of future trajectories of the vehicle, encoding complex behaviors such as multi-modal distributions at road intersections, and even show different predictions at the same intersection depending on the vehicle’s speed. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/zhang18a.html
  PDF: http://proceedings.mlr.press/v87/zhang18a/zhang18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-zhang18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Yanfu
    family: Zhang
  - given: Wenshan
    family: Wang
  - given: Rogerio
    family: Bonatti
  - given: Daniel
    family: Maturana
  - given: Sebastian
    family: Scherer
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 894-905
  id: zhang18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 894
  lastpage: 905
  published: 2018-10-23 00:00:00 +0000
- title: 'Multiple Interactions Made Easy (MIME): Large Scale Demonstrations Data for Imitation'
  abstract: 'In recent years, we have seen an emergence of data-driven approaches in robotics. However, most existing efforts and datasets are either in simulation or focus on a single task in isolation such as grasping, pushing or poking. In order to make progress and capture the space of manipulation, we would need to collect a large-scale dataset of diverse tasks such as pouring, opening bottles, stacking objects etc. But how does one collect such a dataset? In this paper, we present the largest available robotic-demonstration dataset (MIME) that contains 8260 human-robot demonstrations over 20 different robotic tasks2. These tasks range from the simple task of pushing objects to the difficult task of stacking household objects. Our dataset consists of videos of human demonstrations and kinesthetic trajectories of robot demonstrations. We also propose to use this dataset for the task of mapping 3rd person video features to robot trajectories. Furthermore, we present two different approaches using this dataset and evaluate the predicted robot trajectories against ground-truth trajectories. We hope our dataset inspires research in multiple areas including visual imitation, trajectory prediction and multi-task robotic learning. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/sharma18a.html
  PDF: http://proceedings.mlr.press/v87/sharma18a/sharma18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-sharma18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Pratyusha
    family: Sharma
  - given: Lekha
    family: Mohan
  - given: Lerrel
    family: Pinto
  - given: Abhinav
    family: Gupta
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 906-915
  id: sharma18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 906
  lastpage: 915
  published: 2018-10-23 00:00:00 +0000
- title: 'Policies Modulating Trajectory Generators'
  abstract: 'We propose an architecture for learning complex controllable behaviors by having simple Policies Modulate Trajectory Generators (PMTG), a powerful combination that can provide both memory and prior knowledge to the controller. The result is a flexible architecture that is applicable to a class of problems with periodic motion for which one has an insight into the class of trajectories that might lead to a desired behavior. We illustrate the basics of our architecture using a synthetic control problem, then go on to learn speed-controlled locomotion for a quadrupedal robot by using Deep Reinforcement Learning and Evolutionary Strategies. We demonstrate that a simple linear policy, when paired with a parametric Trajectory Generator for quadrupedal gaits, can induce walking behaviors with controllable speed from 4-dimensional IMU observations alone, and can be learned in under 1000 rollouts. We also transfer these policies to a real robot and show locomotion with controllable forward velocity. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/iscen18a.html
  PDF: http://proceedings.mlr.press/v87/iscen18a/iscen18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-iscen18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Atil
    family: Iscen
  - given: Ken
    family: Caluwaerts
  - given: Jie
    family: Tan
  - given: Tingnan
    family: Zhang
  - given: Erwin
    family: Coumans
  - given: Vikas
    family: Sindhwani
  - given: Vincent
    family: Vanhoucke
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 916-926
  id: iscen18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 916
  lastpage: 926
  published: 2018-10-23 00:00:00 +0000
- title: 'A Physically-Consistent Bayesian Non-Parametric Mixture Model for Dynamical System Learning'
  abstract: 'We propose a physically-consistent Bayesian non-parametric approach for fitting Gaussian Mixture Models (GMM) to trajectory data. Physical-consistency of the GMM is ensured by imposing a prior on the component assignments biased by a novel similarity metric that leverages locality and directionality. The resulting GMM is then used to learn globally asymptotically stable Dynamical Systems (DS) via a Linear Parameter Varying (LPV) re-formulation. The proposed DS learning scheme accurately encodes challenging nonlinear motions automatically. Finally, a data-efficient incremental learning framework is introduced that encodes a DS from batches of trajectories, while preserving global stability. Our contributions are validated on 2D datasets and a variety of tasks that involve single-target complex motions with a KUKA LWR 4+ robot arm. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/figueroa18a.html
  PDF: http://proceedings.mlr.press/v87/figueroa18a/figueroa18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-figueroa18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Nadia
    family: Figueroa
  - given: Aude
    family: Billard
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 927-946
  id: figueroa18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 927
  lastpage: 946
  published: 2018-10-23 00:00:00 +0000
- title: 'IntentNet: Learning to Predict Intention from Raw Sensor Data'
  abstract: 'In order to plan a safe maneuver, self-driving vehicles need to understand the intent of other traffic participants. We define intent as a combination of discrete high level behaviors as well as continuous trajectories describing future motion. In this paper we develop a one-stage detector and forecaster that exploits both 3D point clouds produced by a LiDAR sensor as well as dynamic maps of the environment. Our multi-task model achieves better accuracy than the respective separate modules while saving computation, which is critical to reduce reaction time in self-driving applications. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/casas18a.html
  PDF: http://proceedings.mlr.press/v87/casas18a/casas18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-casas18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Sergio
    family: Casas
  - given: Wenjie
    family: Luo
  - given: Raquel
    family: Urtasun
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 947-956
  id: casas18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 947
  lastpage: 956
  published: 2018-10-23 00:00:00 +0000
- title: 'Interpretable Latent Spaces for Learning from Demonstration'
  abstract: 'Effective human-robot interaction, such as in robot learning from human demonstration, requires the learning agent to be able to ground abstract concepts (such as those contained within instructions) in a corresponding high-dimensional sensory input stream from the world. Models such as deep neural networks, with high capacity through their large parameter spaces, can be used to compress the high-dimensional sensory data to lower dimensional representations. These low-dimensional representations facilitate symbol grounding, but may not guarantee that the representation would be human-interpretable. We propose a method which utilises the grouping of user-defined symbols and their corresponding sensory observations in order to align the learnt compressed latent representation with the semantic notions contained in the abstract labels. We demonstrate this through experiments with both simulated and real-world object data, showing that such alignment can be achieved in a process of physical symbol grounding. '
  volume: 87
  URL: https://proceedings.mlr.press/v87/hristov18a.html
  PDF: http://proceedings.mlr.press/v87/hristov18a/hristov18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-hristov18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Yordan
    family: Hristov
  - given: Alex
    family: Lascarides
  - given: Subramanian
    family: Ramamoorthy
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 957-968
  id: hristov18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 957
  lastpage: 968
  published: 2018-10-23 00:00:00 +0000
- title: 'ESIM: an Open Event Camera Simulator'
  abstract: 'Event cameras are revolutionary sensors that work radically differently from standard cameras. Instead of capturing intensity images at a fixed rate, event cameras measure changes of intensity asynchronously, in the form of a stream of events, which encode per-pixel brightness changes. In the last few years, their outstanding properties (asynchronous sensing, no motion blur, high dynamic range) have led to exciting vision applications, with very low-latency and high robustness. However, these sensors are still scarce and expensive to get, slowing down progress of the research community. To address these issues, there is a huge demand for cheap, high-quality synthetic, labeled event for algorithm prototyping, deep learning and algorithm benchmarking. The development of such a simulator, however, is not trivial since event cameras work fundamentally differently from frame-based cameras. We present the first event camera simulator that can generate a large amount of reliable event data. The key component of our simulator is a theoretically sound, adaptive rendering scheme that only samples frames when necessary, through a tight coupling between the rendering engine and the event simulator. We release an open source implementation of our simulator.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/rebecq18a.html
  PDF: http://proceedings.mlr.press/v87/rebecq18a/rebecq18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-rebecq18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Henri
    family: Rebecq
  - given: Daniel
    family: Gehrig
  - given: Davide
    family: Scaramuzza
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 969-982
  id: rebecq18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 969
  lastpage: 982
  published: 2018-10-23 00:00:00 +0000
- title: 'Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning'
  abstract: 'Prediction is an appealing objective for self-supervised learning of behavioral skills, particularly for autonomous robots. However, effectively utilizing predictive models for control, especially with raw image inputs, poses a number of major challenges. How should the predictions be used? What happens when they are inaccurate? In this paper, we tackle these questions by proposing a method for learning robotic skills from raw image observations, using only autonomously collected experience. We show that even an imperfect model can complete complex tasks if it can continuously retry, but this requires the model to not lose track of the objective (e.g., the object of interest). To enable a robot to continuously retry a task, we devise a self-supervised algorithm for learning image registration, which can keep track of objects of interest for the duration of the trial. We demonstrate that this idea can be combined with a video-prediction based controller to enable complex behaviors to be learned from scratch using only raw visual inputs, including grasping, repositioning objects, and non-prehensile manipulation. Our real-world experiments demonstrate that a model trained with 160 robot hours of autonomously collected, unlabeled data is able to successfully perform complex manipulation tasks with a wide range of objects not seen during training.'
  volume: 87
  URL: https://proceedings.mlr.press/v87/ebert18a.html
  PDF: http://proceedings.mlr.press/v87/ebert18a/ebert18a.pdf
  edit: https://github.com/mlresearch//v87/edit/gh-pages/_posts/2018-10-23-ebert18a.md
  series: 'Proceedings of Machine Learning Research'
  container-title: 'Proceedings of The 2nd Conference on Robot Learning'
  publisher: 'PMLR'
  author: 
  - given: Frederik
    family: Ebert
  - given: Sudeep
    family: Dasari
  - given: Alex X.
    family: Lee
  - given: Sergey
    family: Levine
  - given: Chelsea
    family: Finn
  editor: 
  - given: Aude
    family: Billard
  - given: Anca
    family: Dragan
  - given: Jan
    family: Peters
  - given: Jun
    family: Morimoto
  page: 983-993
  id: ebert18a
  issued:
    date-parts: 
      - 2018
      - 10
      - 23
  firstpage: 983
  lastpage: 993
  published: 2018-10-23 00:00:00 +0000
