# ml-services

This project is in its infancy, and I haven't scoped it enough to write anything here that is both meaningful and precise. Thank you for your interest, and check back in some time to (hopefully) see some progress. Regardless, a brief description of the repository as it stands would probably not be amiss. Broadly, this project aims to use concepts from the field of [Information Science](https://en.wikipedia.org/wiki/Information_science/#) to *extract*, *organize*, *manage*, *extend*, and *synthesize* [knowledge](https://en.wikipedia.org/wiki/Knowledge), within the scope of research in [Machine Learning](https://en.wikipedia.org/wiki/Machine_learning).

## Current Structure

### Scripts
Scripts for wrangling data:
- `scripts/mloss.pl`: wrangles the `BibTeX` entries for everything ever to have appeared in [JMLR Machine Learning Open Source Software (MLOSS)](https://www.jmlr.org/mloss/),
- `scripts/tlmr.pl`: wrangles the `BibTeX` entries for everything ever to have appeared in [Transactions on Machine Learning Research (TLMR)](https://jmlr.org/tmlr/),
- `scripts/jmlr.pl`: wrangles the `BibTeX` entries for everything ever to have appeared in [Journal of Machine Learning Research (JLMR)](https://www.jmlr.org/),
- `scripts/neurips.pl`: wrangles the `BibTeX` entries for everything ever to have appeared in [Advances in Neural Information Processing Systems (NeurIPS)](https://proceedings.neurips.cc/),
- `scripts/pmlr.pl`: wrangles the `BibTeX` entries for everything ever to have appeared in [Proceedings of Machine Learning Research (PMLR)](http://proceedings.mlr.press/).

### Data
Harvests generated by the wranglers:
- `data/mloss/bibliography/mloss.bib`: generated using `scripts/mloss.pl`. A single `mloss.bib` holds `BibTeX` entries for entries for [JMLR Machine Learning Open Source Software (MLOSS)](https://www.jmlr.org/mloss/).
- `data/tmlr/bibliography/tmlr.bib`: generated using `scripts/tmlr.pl`. A single `tmlr.bib` holds about 850 odd entries from the recently introduced [Transactions on Machine Learning Research (TLMR)](https://jmlr.org/tmlr/).
- `data/jmlr/bibliography`: generated using `scripts/jmlr.pl`. Contains files `v6.bib`, `v7.bib`, ..., `v24.bib`, `v25.bib`, each holding the `BibTeX` entries for all papers from that year (`v1.bib` through `v5.bib` are missing because the `.bib` files of the individual papers are not available. These will be compiled via other means soon).
- `data/neurips/bibliography`: generated using `scripts/neurips.pl`. Contains files `1987.bib`, `1988.bib`, ..., `2022.bib`, `2023.bib`, each holding the `BibTeX` entries for all papers from that year,
- `data/pmlr/bibliography`: generated using `scripts/pmlr.pl`. Contains files `v1.bib`, `v2.bib`, ..., `v237.bib`, `v238.bib`, each holding the `BibTeX` entries for all papers from that volume,
- `data/pmlr/citeproc`: same data as `data/pmlr/bibliography` but in `YAML` format.

## Resources

Working list of tools on which future development, more probably than not, going to depend on:

1. [The Open Cognition Project](https://wiki.opencog.org/w/The_Open_Cognition_Project):  OpenCog is a unique and ambitious open-source software project taking a serious effort to build a thinking machine. It aims to create an open source framework for Artificial General Intelligence, intended to one day express general intelligence at the human level and beyond.
2. [OpenAlex](https://openalex.org/): OpenAlex is a free and open catalog of the global research system. It's named after the ancient Library of Alexandria and made by the nonprofit OurResearch. `OpenAlex` is replacement for the retired  [Microsoft Academic Graph](https://www.microsoft.com/en-us/research/project/microsoft-academic-graph/) project.
3. [GROBID](https://github.com/kermitt2/grobid): GROBID is a machine learning library for extracting, parsing and re-structuring raw documents such as PDF into structured XML/TEI encoded documents with a particular focus on technical and scientific publications.
4. [Apache Solr](https://solr.apache.org/): Solr is the popular, blazing-fast, open source enterprise search platform built on Apache Lucene™.
4. [Crossref](https://www.crossref.org/): Crossref is a not-for-profit membership organization that exists to make scholarly communications better. It makes research objects easy to find, cite, link, assess, and reuse.
5. [Semantic Scholar](https://www.semanticscholar.org/): A free, AI-powered research tool for scientific literature.

Resources related to the tools above:

1. [Atomspace](https://wiki.opencog.org/w/AtomSpace): The OpenCog AtomSpace is a [knowledge representation](https://wiki.opencog.org/w/Knowledge_representation) (KR) database and the associated query/reasoning engine to fetch and manipulate that data, and perform reasoning on it. 
2. [Graphs, Metagraphs, RAM, CPU](https://github.com/opencog/atomspace/blob/master/opencog/sheaf/docs/ram-cpu.pdf): A technical exposition on the Atomspace.
3. [OpenAlex API Documentation](https://docs.openalex.org/): documentation for the OpenAlex API.
4. [ICML Conference Analytics](https://www.microsoft.com/en-us/research/project/academic/articles/icml-conference-analytics/): [Microsoft Academic Graph](https://www.microsoft.com/en-us/research/project/microsoft-academic-graph/) demonstration.
5. [Semantic Scholar API Overview](https://www.semanticscholar.org/product/api): overview of the Semantic Scholar API, in particular the [Academic Graph API](https://api.semanticscholar.org/api-docs/graph) and the [Recommendations API](https://api.semanticscholar.org/api-docs/recommendations). Both pages have [OpenAPI specifications (OAS)](https://swagger.io/specification/) which can be used as inputs to a tool like [Swagger Codegen](https://swagger.io/tools/swagger-codegen/) for automatic client SDK code generation.
6. [GROBID Documentation](https://grobid.readthedocs.io/en/latest/): Documentation for GROBID. Particularly relevant and of immediate interest are the sections [GROBID Service API](https://grobid.readthedocs.io/en/latest/Grobid-service/), [How GROBID works](https://grobid.readthedocs.io/en/latest/Principles/), [TEI encoding of results](https://grobid.readthedocs.io/en/latest/TEI-encoding-of-results/), and [Coordinates of structures in PDF](https://grobid.readthedocs.io/en/latest/Coordinates-in-PDF/).

Working list of resources that serve as foundational reading relevant to this project (for each page, scroll down and explore the `See also` section and the `Navigation templates`):

1. [Information science](https://en.wikipedia.org/wiki/Information_science): A field focused on the systematic study and management of data and information across systems and processes.
2. [Library and Information Science](https://en.wikipedia.org/wiki/Library_and_information_science): An interdisciplinary field that applies the practices, perspectives, and tools of management, information technology, education, and other areas to libraries.
3. [Natural Language Processing](https://en.wikipedia.org/wiki/Natural_language_processing): The technology used to aid computers to understand the human’s natural language.
4. [Text Mining](https://en.wikipedia.org/wiki/Text_mining): The process of deriving high-quality information from text through computational means.
5. [Knowledge Management](https://en.wikipedia.org/wiki/Knowledge_management): Strategies and processes to manage organizational knowledge effectively.
6. [Bibliometrics](https://en.wikipedia.org/wiki/Bibliometrics): Analyzes scientific and technological literature quantitatively.
7. [Information Extraction](https://en.wikipedia.org/wiki/Information_extraction): Techniques for automatically extracting structured information from unstructured/semi-structured data sources.
8. [Information Retrieval](https://en.wikipedia.org/wiki/Information_retrieval): The science of searching for information in documents, searching for documents themselves, and also searching for metadata which describes documents.
9. [Automatic Summarization](https://en.wikipedia.org/wiki/Automatic_summarization): The process of reducing a text document with a computer program to create a summary that retains the most important points of the original document.
10. [Distributional Semantics](https://en.wikipedia.org/wiki/Distributional_semantics): Approaches to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of language data.
11. [Topic Model](https://en.wikipedia.org/wiki/Topic_model): Statistical models to discover abstract topics that occur in a collection of documents.
12. [Computer-assisted Reviewing](https://en.wikipedia.org/wiki/Computer-assisted_reviewing): The use of automated processes to aid in the review of documents and data.
13. [Automated Reasoning](https://en.wikipedia.org/wiki/Automated_reasoning): The use of computers to emulate human reasoning, typically within the realm of mathematics or logic.
14. [Language Resource](https://en.wikipedia.org/wiki/Language_resource): Operational datasets in various forms used to build, improve, or evaluate natural language processing applications. In particular, see [Text Encoding Initiative](https://tei-c.org/): a comprehensive encoding standard for machine-readable texts. [A Gentle Introduction to XML](https://tei-c.org/release/doc/tei-p5-doc/en/html/SG.html) is also a useful read.

Working list of relevant books:

1. [Designing Data-Intensive Applications](https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/).
2. [Taming Text](https://www.manning.com/books/taming-text).
3. [Solr in Action](https://www.manning.com/books/solr-in-action).

